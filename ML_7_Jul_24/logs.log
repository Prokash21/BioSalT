2024-07-07 05:03:14,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 05:03:14,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 05:03:14,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 05:03:14,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 05:03:15,500:INFO:PyCaret ClassificationExperiment
2024-07-07 05:03:15,501:INFO:Logging name: clf-default-name
2024-07-07 05:03:15,502:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-07 05:03:15,503:INFO:version 3.3.2
2024-07-07 05:03:15,503:INFO:Initializing setup()
2024-07-07 05:03:15,503:INFO:self.USI: 7f14
2024-07-07 05:03:15,503:INFO:self._variable_keys: {'logging_param', 'data', '_ml_usecase', 'y_train', 'fold_groups_param', 'n_jobs_param', 'y_test', 'y', 'idx', 'fold_generator', 'fix_imbalance', 'USI', 'log_plots_param', 'is_multiclass', '_available_plots', 'exp_id', 'X_test', 'fold_shuffle_param', 'X', 'pipeline', 'gpu_param', 'X_train', 'html_param', 'memory', 'gpu_n_jobs_param', 'target_param', 'seed', 'exp_name_log'}
2024-07-07 05:03:15,503:INFO:Checking environment
2024-07-07 05:03:15,503:INFO:python_version: 3.10.12
2024-07-07 05:03:15,503:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-07 05:03:15,503:INFO:machine: x86_64
2024-07-07 05:03:15,503:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 05:03:15,504:INFO:Memory: svmem(total=13609431040, available=12101373952, percent=11.1, used=1171886080, free=5645815808, active=805367808, inactive=6763692032, buffers=429973504, cached=6361755648, shared=2936832, slab=310542336)
2024-07-07 05:03:15,504:INFO:Physical Core: 1
2024-07-07 05:03:15,504:INFO:Logical Core: 2
2024-07-07 05:03:15,505:INFO:Checking libraries
2024-07-07 05:03:15,505:INFO:System:
2024-07-07 05:03:15,505:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-07 05:03:15,505:INFO:executable: /usr/bin/python3
2024-07-07 05:03:15,505:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 05:03:15,505:INFO:PyCaret required dependencies:
2024-07-07 05:03:16,397:INFO:                 pip: 23.1.2
2024-07-07 05:03:16,397:INFO:          setuptools: 67.7.2
2024-07-07 05:03:16,397:INFO:             pycaret: 3.3.2
2024-07-07 05:03:16,397:INFO:             IPython: 7.34.0
2024-07-07 05:03:16,397:INFO:          ipywidgets: 7.7.1
2024-07-07 05:03:16,398:INFO:                tqdm: 4.66.4
2024-07-07 05:03:16,398:INFO:               numpy: 1.25.2
2024-07-07 05:03:16,398:INFO:              pandas: 2.0.3
2024-07-07 05:03:16,398:INFO:              jinja2: 3.1.4
2024-07-07 05:03:16,398:INFO:               scipy: 1.11.4
2024-07-07 05:03:16,398:INFO:              joblib: 1.3.2
2024-07-07 05:03:16,398:INFO:             sklearn: 1.4.2
2024-07-07 05:03:16,399:INFO:                pyod: 2.0.1
2024-07-07 05:03:16,399:INFO:            imblearn: 0.12.3
2024-07-07 05:03:16,399:INFO:   category_encoders: 2.6.3
2024-07-07 05:03:16,399:INFO:            lightgbm: 4.1.0
2024-07-07 05:03:16,399:INFO:               numba: 0.58.1
2024-07-07 05:03:16,399:INFO:            requests: 2.31.0
2024-07-07 05:03:16,399:INFO:          matplotlib: 3.7.1
2024-07-07 05:03:16,400:INFO:          scikitplot: 0.3.7
2024-07-07 05:03:16,400:INFO:         yellowbrick: 1.5
2024-07-07 05:03:16,400:INFO:              plotly: 5.15.0
2024-07-07 05:03:16,400:INFO:    plotly-resampler: Not installed
2024-07-07 05:03:16,400:INFO:             kaleido: 0.2.1
2024-07-07 05:03:16,400:INFO:           schemdraw: 0.15
2024-07-07 05:03:16,400:INFO:         statsmodels: 0.14.2
2024-07-07 05:03:16,400:INFO:              sktime: 0.26.0
2024-07-07 05:03:16,401:INFO:               tbats: 1.1.3
2024-07-07 05:03:16,401:INFO:            pmdarima: 2.0.4
2024-07-07 05:03:16,401:INFO:              psutil: 5.9.5
2024-07-07 05:03:16,401:INFO:          markupsafe: 2.1.5
2024-07-07 05:03:16,401:INFO:             pickle5: Not installed
2024-07-07 05:03:16,401:INFO:         cloudpickle: 2.2.1
2024-07-07 05:03:16,401:INFO:         deprecation: 2.1.0
2024-07-07 05:03:16,402:INFO:              xxhash: 3.4.1
2024-07-07 05:03:16,402:INFO:           wurlitzer: 3.1.1
2024-07-07 05:03:16,402:INFO:PyCaret optional dependencies:
2024-07-07 05:03:16,609:INFO:                shap: Not installed
2024-07-07 05:03:16,609:INFO:           interpret: Not installed
2024-07-07 05:03:16,609:INFO:                umap: Not installed
2024-07-07 05:03:16,610:INFO:     ydata_profiling: Not installed
2024-07-07 05:03:16,610:INFO:  explainerdashboard: Not installed
2024-07-07 05:03:16,610:INFO:             autoviz: Not installed
2024-07-07 05:03:16,610:INFO:           fairlearn: Not installed
2024-07-07 05:03:16,610:INFO:          deepchecks: Not installed
2024-07-07 05:03:16,610:INFO:             xgboost: 2.0.3
2024-07-07 05:03:16,611:INFO:            catboost: Not installed
2024-07-07 05:03:16,611:INFO:              kmodes: Not installed
2024-07-07 05:03:16,611:INFO:             mlxtend: 0.22.0
2024-07-07 05:03:16,611:INFO:       statsforecast: Not installed
2024-07-07 05:03:16,611:INFO:        tune_sklearn: Not installed
2024-07-07 05:03:16,611:INFO:                 ray: Not installed
2024-07-07 05:03:16,611:INFO:            hyperopt: 0.2.7
2024-07-07 05:03:16,612:INFO:              optuna: Not installed
2024-07-07 05:03:16,612:INFO:               skopt: Not installed
2024-07-07 05:03:16,612:INFO:              mlflow: Not installed
2024-07-07 05:03:16,612:INFO:              gradio: Not installed
2024-07-07 05:03:16,612:INFO:             fastapi: Not installed
2024-07-07 05:03:16,612:INFO:             uvicorn: Not installed
2024-07-07 05:03:16,612:INFO:              m2cgen: Not installed
2024-07-07 05:03:16,612:INFO:           evidently: Not installed
2024-07-07 05:03:16,613:INFO:               fugue: Not installed
2024-07-07 05:03:16,613:INFO:           streamlit: Not installed
2024-07-07 05:03:16,613:INFO:             prophet: 1.1.5
2024-07-07 05:03:16,613:INFO:None
2024-07-07 05:03:16,613:INFO:Set up data.
2024-07-07 05:03:16,627:INFO:Set up folding strategy.
2024-07-07 05:03:16,628:INFO:Set up train/test split.
2024-07-07 05:03:16,635:INFO:Set up index.
2024-07-07 05:03:16,635:INFO:Assigning column types.
2024-07-07 05:03:16,644:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-07 05:03:16,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 05:03:16,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 05:03:16,753:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:16,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:16,815:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 05:03:16,817:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 05:03:16,848:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:16,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:16,853:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-07 05:03:16,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 05:03:16,939:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:16,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:16,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 05:03:17,028:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:17,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:17,032:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-07 05:03:17,119:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:17,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:17,207:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:17,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:17,212:INFO:Preparing preprocessing pipeline...
2024-07-07 05:03:17,215:INFO:Set up simple imputation.
2024-07-07 05:03:17,253:INFO:Finished creating preprocessing pipeline.
2024-07-07 05:03:17,258:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Solyc02g084850', 'Solyc03g116390',
                                             'Solyc04g081900', 'Solyc01g087180',
                                             'Solyc07g063410', 'Solyc03g007230',
                                             'Solyc10g081980', 'Solyc12g098900',
                                             'Solyc03g019820', 'Solyc10g078770',
                                             'Solyc06g068620', 'Solyc04g005250',
                                             'Solyc08g075280', 'Solyc09g07...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-07 05:03:17,259:INFO:Creating final display dataframe.
2024-07-07 05:03:17,374:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         condition
2                   Target type            Binary
3           Original data shape          (66, 23)
4        Transformed data shape          (66, 23)
5   Transformed train set shape          (52, 23)
6    Transformed test set shape          (14, 23)
7              Numeric features                22
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7f14
2024-07-07 05:03:17,471:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:17,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:17,558:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 05:03:17,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 05:03:17,565:INFO:setup() successfully completed in 2.07s...............
2024-07-07 05:03:41,386:INFO:Initializing compare_models()
2024-07-07 05:03:41,387:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-07 05:03:41,387:INFO:Checking exceptions
2024-07-07 05:03:41,397:INFO:Preparing display monitor
2024-07-07 05:03:41,486:INFO:Initializing Logistic Regression
2024-07-07 05:03:41,489:INFO:Total runtime is 4.869699478149414e-05 minutes
2024-07-07 05:03:41,507:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:41,509:INFO:Initializing create_model()
2024-07-07 05:03:41,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:41,509:INFO:Checking exceptions
2024-07-07 05:03:41,509:INFO:Importing libraries
2024-07-07 05:03:41,509:INFO:Copying training dataset
2024-07-07 05:03:41,522:INFO:Defining folds
2024-07-07 05:03:41,523:INFO:Declaring metric variables
2024-07-07 05:03:41,535:INFO:Importing untrained model
2024-07-07 05:03:41,550:INFO:Logistic Regression Imported successfully
2024-07-07 05:03:41,574:INFO:Starting cross validation
2024-07-07 05:03:41,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:47,492:INFO:Calculating mean and std
2024-07-07 05:03:47,495:INFO:Creating metrics dataframe
2024-07-07 05:03:47,503:INFO:Uploading results into container
2024-07-07 05:03:47,504:INFO:Uploading model into container now
2024-07-07 05:03:47,505:INFO:_master_model_container: 1
2024-07-07 05:03:47,505:INFO:_display_container: 2
2024-07-07 05:03:47,506:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 05:03:47,506:INFO:create_model() successfully completed......................................
2024-07-07 05:03:47,661:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:47,661:INFO:Creating metrics dataframe
2024-07-07 05:03:47,671:INFO:Initializing K Neighbors Classifier
2024-07-07 05:03:47,672:INFO:Total runtime is 0.10309356848398844 minutes
2024-07-07 05:03:47,683:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:47,683:INFO:Initializing create_model()
2024-07-07 05:03:47,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:47,684:INFO:Checking exceptions
2024-07-07 05:03:47,684:INFO:Importing libraries
2024-07-07 05:03:47,684:INFO:Copying training dataset
2024-07-07 05:03:47,696:INFO:Defining folds
2024-07-07 05:03:47,696:INFO:Declaring metric variables
2024-07-07 05:03:47,711:INFO:Importing untrained model
2024-07-07 05:03:47,722:INFO:K Neighbors Classifier Imported successfully
2024-07-07 05:03:47,748:INFO:Starting cross validation
2024-07-07 05:03:47,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:48,343:INFO:Calculating mean and std
2024-07-07 05:03:48,345:INFO:Creating metrics dataframe
2024-07-07 05:03:48,350:INFO:Uploading results into container
2024-07-07 05:03:48,360:INFO:Uploading model into container now
2024-07-07 05:03:48,362:INFO:_master_model_container: 2
2024-07-07 05:03:48,362:INFO:_display_container: 2
2024-07-07 05:03:48,363:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-07 05:03:48,363:INFO:create_model() successfully completed......................................
2024-07-07 05:03:48,522:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:48,523:INFO:Creating metrics dataframe
2024-07-07 05:03:48,537:INFO:Initializing Naive Bayes
2024-07-07 05:03:48,538:INFO:Total runtime is 0.11752261718114217 minutes
2024-07-07 05:03:48,550:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:48,551:INFO:Initializing create_model()
2024-07-07 05:03:48,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:48,551:INFO:Checking exceptions
2024-07-07 05:03:48,552:INFO:Importing libraries
2024-07-07 05:03:48,552:INFO:Copying training dataset
2024-07-07 05:03:48,569:INFO:Defining folds
2024-07-07 05:03:48,570:INFO:Declaring metric variables
2024-07-07 05:03:48,585:INFO:Importing untrained model
2024-07-07 05:03:48,603:INFO:Naive Bayes Imported successfully
2024-07-07 05:03:48,641:INFO:Starting cross validation
2024-07-07 05:03:48,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:49,189:INFO:Calculating mean and std
2024-07-07 05:03:49,192:INFO:Creating metrics dataframe
2024-07-07 05:03:49,198:INFO:Uploading results into container
2024-07-07 05:03:49,203:INFO:Uploading model into container now
2024-07-07 05:03:49,204:INFO:_master_model_container: 3
2024-07-07 05:03:49,204:INFO:_display_container: 2
2024-07-07 05:03:49,204:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-07 05:03:49,205:INFO:create_model() successfully completed......................................
2024-07-07 05:03:49,405:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:49,406:INFO:Creating metrics dataframe
2024-07-07 05:03:49,424:INFO:Initializing Decision Tree Classifier
2024-07-07 05:03:49,424:INFO:Total runtime is 0.13229726950327556 minutes
2024-07-07 05:03:49,438:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:49,439:INFO:Initializing create_model()
2024-07-07 05:03:49,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:49,441:INFO:Checking exceptions
2024-07-07 05:03:49,441:INFO:Importing libraries
2024-07-07 05:03:49,441:INFO:Copying training dataset
2024-07-07 05:03:49,455:INFO:Defining folds
2024-07-07 05:03:49,461:INFO:Declaring metric variables
2024-07-07 05:03:49,476:INFO:Importing untrained model
2024-07-07 05:03:49,492:INFO:Decision Tree Classifier Imported successfully
2024-07-07 05:03:49,526:INFO:Starting cross validation
2024-07-07 05:03:49,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:50,039:INFO:Calculating mean and std
2024-07-07 05:03:50,041:INFO:Creating metrics dataframe
2024-07-07 05:03:50,053:INFO:Uploading results into container
2024-07-07 05:03:50,054:INFO:Uploading model into container now
2024-07-07 05:03:50,055:INFO:_master_model_container: 4
2024-07-07 05:03:50,055:INFO:_display_container: 2
2024-07-07 05:03:50,056:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-07-07 05:03:50,056:INFO:create_model() successfully completed......................................
2024-07-07 05:03:50,218:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:50,219:INFO:Creating metrics dataframe
2024-07-07 05:03:50,237:INFO:Initializing SVM - Linear Kernel
2024-07-07 05:03:50,242:INFO:Total runtime is 0.14593213001887004 minutes
2024-07-07 05:03:50,260:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:50,261:INFO:Initializing create_model()
2024-07-07 05:03:50,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:50,262:INFO:Checking exceptions
2024-07-07 05:03:50,262:INFO:Importing libraries
2024-07-07 05:03:50,262:INFO:Copying training dataset
2024-07-07 05:03:50,282:INFO:Defining folds
2024-07-07 05:03:50,283:INFO:Declaring metric variables
2024-07-07 05:03:50,303:INFO:Importing untrained model
2024-07-07 05:03:50,319:INFO:SVM - Linear Kernel Imported successfully
2024-07-07 05:03:50,350:INFO:Starting cross validation
2024-07-07 05:03:50,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:50,934:INFO:Calculating mean and std
2024-07-07 05:03:50,942:INFO:Creating metrics dataframe
2024-07-07 05:03:50,951:INFO:Uploading results into container
2024-07-07 05:03:50,952:INFO:Uploading model into container now
2024-07-07 05:03:50,953:INFO:_master_model_container: 5
2024-07-07 05:03:50,953:INFO:_display_container: 2
2024-07-07 05:03:50,954:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-07 05:03:50,954:INFO:create_model() successfully completed......................................
2024-07-07 05:03:51,117:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:51,117:INFO:Creating metrics dataframe
2024-07-07 05:03:51,140:INFO:Initializing Ridge Classifier
2024-07-07 05:03:51,142:INFO:Total runtime is 0.16092705726623535 minutes
2024-07-07 05:03:51,162:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:51,162:INFO:Initializing create_model()
2024-07-07 05:03:51,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:51,163:INFO:Checking exceptions
2024-07-07 05:03:51,163:INFO:Importing libraries
2024-07-07 05:03:51,163:INFO:Copying training dataset
2024-07-07 05:03:51,181:INFO:Defining folds
2024-07-07 05:03:51,182:INFO:Declaring metric variables
2024-07-07 05:03:51,198:INFO:Importing untrained model
2024-07-07 05:03:51,219:INFO:Ridge Classifier Imported successfully
2024-07-07 05:03:51,252:INFO:Starting cross validation
2024-07-07 05:03:51,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:51,763:INFO:Calculating mean and std
2024-07-07 05:03:51,767:INFO:Creating metrics dataframe
2024-07-07 05:03:51,775:INFO:Uploading results into container
2024-07-07 05:03:51,776:INFO:Uploading model into container now
2024-07-07 05:03:51,777:INFO:_master_model_container: 6
2024-07-07 05:03:51,777:INFO:_display_container: 2
2024-07-07 05:03:51,778:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-07-07 05:03:51,778:INFO:create_model() successfully completed......................................
2024-07-07 05:03:51,950:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:51,950:INFO:Creating metrics dataframe
2024-07-07 05:03:51,968:INFO:Initializing Random Forest Classifier
2024-07-07 05:03:51,969:INFO:Total runtime is 0.17470411459604898 minutes
2024-07-07 05:03:51,982:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:51,983:INFO:Initializing create_model()
2024-07-07 05:03:51,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:51,983:INFO:Checking exceptions
2024-07-07 05:03:51,984:INFO:Importing libraries
2024-07-07 05:03:51,984:INFO:Copying training dataset
2024-07-07 05:03:51,999:INFO:Defining folds
2024-07-07 05:03:51,999:INFO:Declaring metric variables
2024-07-07 05:03:52,018:INFO:Importing untrained model
2024-07-07 05:03:52,033:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:03:52,059:INFO:Starting cross validation
2024-07-07 05:03:52,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:54,977:INFO:Calculating mean and std
2024-07-07 05:03:54,979:INFO:Creating metrics dataframe
2024-07-07 05:03:54,987:INFO:Uploading results into container
2024-07-07 05:03:54,988:INFO:Uploading model into container now
2024-07-07 05:03:54,990:INFO:_master_model_container: 7
2024-07-07 05:03:54,993:INFO:_display_container: 2
2024-07-07 05:03:54,994:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:03:54,994:INFO:create_model() successfully completed......................................
2024-07-07 05:03:55,123:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:55,124:INFO:Creating metrics dataframe
2024-07-07 05:03:55,137:INFO:Initializing Quadratic Discriminant Analysis
2024-07-07 05:03:55,138:INFO:Total runtime is 0.2275249679883321 minutes
2024-07-07 05:03:55,150:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:55,150:INFO:Initializing create_model()
2024-07-07 05:03:55,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:55,151:INFO:Checking exceptions
2024-07-07 05:03:55,151:INFO:Importing libraries
2024-07-07 05:03:55,151:INFO:Copying training dataset
2024-07-07 05:03:55,162:INFO:Defining folds
2024-07-07 05:03:55,162:INFO:Declaring metric variables
2024-07-07 05:03:55,176:INFO:Importing untrained model
2024-07-07 05:03:55,187:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-07 05:03:55,211:INFO:Starting cross validation
2024-07-07 05:03:55,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:55,274:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,274:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,336:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,338:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,401:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,413:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,452:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,463:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,506:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,515:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 05:03:55,550:INFO:Calculating mean and std
2024-07-07 05:03:55,552:INFO:Creating metrics dataframe
2024-07-07 05:03:55,557:INFO:Uploading results into container
2024-07-07 05:03:55,560:INFO:Uploading model into container now
2024-07-07 05:03:55,561:INFO:_master_model_container: 8
2024-07-07 05:03:55,561:INFO:_display_container: 2
2024-07-07 05:03:55,562:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-07 05:03:55,562:INFO:create_model() successfully completed......................................
2024-07-07 05:03:55,693:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:55,693:INFO:Creating metrics dataframe
2024-07-07 05:03:55,706:INFO:Initializing Ada Boost Classifier
2024-07-07 05:03:55,706:INFO:Total runtime is 0.23699938058853148 minutes
2024-07-07 05:03:55,718:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:55,718:INFO:Initializing create_model()
2024-07-07 05:03:55,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:55,719:INFO:Checking exceptions
2024-07-07 05:03:55,719:INFO:Importing libraries
2024-07-07 05:03:55,719:INFO:Copying training dataset
2024-07-07 05:03:55,730:INFO:Defining folds
2024-07-07 05:03:55,731:INFO:Declaring metric variables
2024-07-07 05:03:55,744:INFO:Importing untrained model
2024-07-07 05:03:55,757:INFO:Ada Boost Classifier Imported successfully
2024-07-07 05:03:55,777:INFO:Starting cross validation
2024-07-07 05:03:55,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:55,817:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:55,818:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,071:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,071:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,307:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,330:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,525:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,565:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,758:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 05:03:56,979:INFO:Calculating mean and std
2024-07-07 05:03:56,980:INFO:Creating metrics dataframe
2024-07-07 05:03:56,983:INFO:Uploading results into container
2024-07-07 05:03:56,987:INFO:Uploading model into container now
2024-07-07 05:03:56,992:INFO:_master_model_container: 9
2024-07-07 05:03:56,992:INFO:_display_container: 2
2024-07-07 05:03:56,992:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-07-07 05:03:56,993:INFO:create_model() successfully completed......................................
2024-07-07 05:03:57,135:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:57,135:INFO:Creating metrics dataframe
2024-07-07 05:03:57,150:INFO:Initializing Gradient Boosting Classifier
2024-07-07 05:03:57,151:INFO:Total runtime is 0.2610770026842753 minutes
2024-07-07 05:03:57,163:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:57,164:INFO:Initializing create_model()
2024-07-07 05:03:57,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:57,164:INFO:Checking exceptions
2024-07-07 05:03:57,164:INFO:Importing libraries
2024-07-07 05:03:57,165:INFO:Copying training dataset
2024-07-07 05:03:57,174:INFO:Defining folds
2024-07-07 05:03:57,175:INFO:Declaring metric variables
2024-07-07 05:03:57,189:INFO:Importing untrained model
2024-07-07 05:03:57,201:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:03:57,226:INFO:Starting cross validation
2024-07-07 05:03:57,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:58,536:INFO:Calculating mean and std
2024-07-07 05:03:58,537:INFO:Creating metrics dataframe
2024-07-07 05:03:58,544:INFO:Uploading results into container
2024-07-07 05:03:58,547:INFO:Uploading model into container now
2024-07-07 05:03:58,548:INFO:_master_model_container: 10
2024-07-07 05:03:58,548:INFO:_display_container: 2
2024-07-07 05:03:58,549:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:03:58,549:INFO:create_model() successfully completed......................................
2024-07-07 05:03:58,683:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:58,684:INFO:Creating metrics dataframe
2024-07-07 05:03:58,698:INFO:Initializing Linear Discriminant Analysis
2024-07-07 05:03:58,700:INFO:Total runtime is 0.28689866065979003 minutes
2024-07-07 05:03:58,711:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:58,711:INFO:Initializing create_model()
2024-07-07 05:03:58,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:58,712:INFO:Checking exceptions
2024-07-07 05:03:58,712:INFO:Importing libraries
2024-07-07 05:03:58,712:INFO:Copying training dataset
2024-07-07 05:03:58,723:INFO:Defining folds
2024-07-07 05:03:58,724:INFO:Declaring metric variables
2024-07-07 05:03:58,738:INFO:Importing untrained model
2024-07-07 05:03:58,750:INFO:Linear Discriminant Analysis Imported successfully
2024-07-07 05:03:58,771:INFO:Starting cross validation
2024-07-07 05:03:58,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:03:59,095:INFO:Calculating mean and std
2024-07-07 05:03:59,096:INFO:Creating metrics dataframe
2024-07-07 05:03:59,107:INFO:Uploading results into container
2024-07-07 05:03:59,108:INFO:Uploading model into container now
2024-07-07 05:03:59,111:INFO:_master_model_container: 11
2024-07-07 05:03:59,112:INFO:_display_container: 2
2024-07-07 05:03:59,112:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-07 05:03:59,112:INFO:create_model() successfully completed......................................
2024-07-07 05:03:59,250:INFO:SubProcess create_model() end ==================================
2024-07-07 05:03:59,251:INFO:Creating metrics dataframe
2024-07-07 05:03:59,270:INFO:Initializing Extra Trees Classifier
2024-07-07 05:03:59,270:INFO:Total runtime is 0.29640185038248695 minutes
2024-07-07 05:03:59,282:INFO:SubProcess create_model() called ==================================
2024-07-07 05:03:59,283:INFO:Initializing create_model()
2024-07-07 05:03:59,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:03:59,285:INFO:Checking exceptions
2024-07-07 05:03:59,285:INFO:Importing libraries
2024-07-07 05:03:59,285:INFO:Copying training dataset
2024-07-07 05:03:59,299:INFO:Defining folds
2024-07-07 05:03:59,300:INFO:Declaring metric variables
2024-07-07 05:03:59,318:INFO:Importing untrained model
2024-07-07 05:03:59,335:INFO:Extra Trees Classifier Imported successfully
2024-07-07 05:03:59,361:INFO:Starting cross validation
2024-07-07 05:03:59,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:04:00,891:INFO:Calculating mean and std
2024-07-07 05:04:00,893:INFO:Creating metrics dataframe
2024-07-07 05:04:00,898:INFO:Uploading results into container
2024-07-07 05:04:00,900:INFO:Uploading model into container now
2024-07-07 05:04:00,901:INFO:_master_model_container: 12
2024-07-07 05:04:00,901:INFO:_display_container: 2
2024-07-07 05:04:00,902:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-07 05:04:00,902:INFO:create_model() successfully completed......................................
2024-07-07 05:04:01,033:INFO:SubProcess create_model() end ==================================
2024-07-07 05:04:01,033:INFO:Creating metrics dataframe
2024-07-07 05:04:01,048:INFO:Initializing Extreme Gradient Boosting
2024-07-07 05:04:01,048:INFO:Total runtime is 0.3260325908660888 minutes
2024-07-07 05:04:01,060:INFO:SubProcess create_model() called ==================================
2024-07-07 05:04:01,061:INFO:Initializing create_model()
2024-07-07 05:04:01,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:04:01,062:INFO:Checking exceptions
2024-07-07 05:04:01,062:INFO:Importing libraries
2024-07-07 05:04:01,062:INFO:Copying training dataset
2024-07-07 05:04:01,072:INFO:Defining folds
2024-07-07 05:04:01,073:INFO:Declaring metric variables
2024-07-07 05:04:01,088:INFO:Importing untrained model
2024-07-07 05:04:01,099:INFO:Extreme Gradient Boosting Imported successfully
2024-07-07 05:04:01,123:INFO:Starting cross validation
2024-07-07 05:04:01,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:04:01,807:INFO:Calculating mean and std
2024-07-07 05:04:01,808:INFO:Creating metrics dataframe
2024-07-07 05:04:01,817:INFO:Uploading results into container
2024-07-07 05:04:01,819:INFO:Uploading model into container now
2024-07-07 05:04:01,820:INFO:_master_model_container: 13
2024-07-07 05:04:01,820:INFO:_display_container: 2
2024-07-07 05:04:01,821:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-07 05:04:01,821:INFO:create_model() successfully completed......................................
2024-07-07 05:04:01,951:INFO:SubProcess create_model() end ==================================
2024-07-07 05:04:01,952:INFO:Creating metrics dataframe
2024-07-07 05:04:01,965:INFO:Initializing Light Gradient Boosting Machine
2024-07-07 05:04:01,966:INFO:Total runtime is 0.34132693608601883 minutes
2024-07-07 05:04:01,977:INFO:SubProcess create_model() called ==================================
2024-07-07 05:04:01,978:INFO:Initializing create_model()
2024-07-07 05:04:01,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:04:01,978:INFO:Checking exceptions
2024-07-07 05:04:01,979:INFO:Importing libraries
2024-07-07 05:04:01,979:INFO:Copying training dataset
2024-07-07 05:04:01,989:INFO:Defining folds
2024-07-07 05:04:01,989:INFO:Declaring metric variables
2024-07-07 05:04:02,003:INFO:Importing untrained model
2024-07-07 05:04:02,016:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-07 05:04:02,039:INFO:Starting cross validation
2024-07-07 05:04:02,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:04:02,786:INFO:Calculating mean and std
2024-07-07 05:04:02,788:INFO:Creating metrics dataframe
2024-07-07 05:04:02,798:INFO:Uploading results into container
2024-07-07 05:04:02,799:INFO:Uploading model into container now
2024-07-07 05:04:02,799:INFO:_master_model_container: 14
2024-07-07 05:04:02,799:INFO:_display_container: 2
2024-07-07 05:04:02,800:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-07 05:04:02,800:INFO:create_model() successfully completed......................................
2024-07-07 05:04:02,932:INFO:SubProcess create_model() end ==================================
2024-07-07 05:04:02,932:INFO:Creating metrics dataframe
2024-07-07 05:04:02,947:INFO:Initializing Dummy Classifier
2024-07-07 05:04:02,948:INFO:Total runtime is 0.3576875567436218 minutes
2024-07-07 05:04:02,960:INFO:SubProcess create_model() called ==================================
2024-07-07 05:04:02,961:INFO:Initializing create_model()
2024-07-07 05:04:02,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78aa0cbe4b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:04:02,961:INFO:Checking exceptions
2024-07-07 05:04:02,962:INFO:Importing libraries
2024-07-07 05:04:02,962:INFO:Copying training dataset
2024-07-07 05:04:02,972:INFO:Defining folds
2024-07-07 05:04:02,973:INFO:Declaring metric variables
2024-07-07 05:04:02,988:INFO:Importing untrained model
2024-07-07 05:04:02,998:INFO:Dummy Classifier Imported successfully
2024-07-07 05:04:03,024:INFO:Starting cross validation
2024-07-07 05:04:03,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:04:03,342:INFO:Calculating mean and std
2024-07-07 05:04:03,344:INFO:Creating metrics dataframe
2024-07-07 05:04:03,351:INFO:Uploading results into container
2024-07-07 05:04:03,354:INFO:Uploading model into container now
2024-07-07 05:04:03,355:INFO:_master_model_container: 15
2024-07-07 05:04:03,355:INFO:_display_container: 2
2024-07-07 05:04:03,355:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-07-07 05:04:03,356:INFO:create_model() successfully completed......................................
2024-07-07 05:04:03,492:INFO:SubProcess create_model() end ==================================
2024-07-07 05:04:03,493:INFO:Creating metrics dataframe
2024-07-07 05:04:03,547:INFO:Initializing create_model()
2024-07-07 05:04:03,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:04:03,548:INFO:Checking exceptions
2024-07-07 05:04:03,551:INFO:Importing libraries
2024-07-07 05:04:03,552:INFO:Copying training dataset
2024-07-07 05:04:03,560:INFO:Defining folds
2024-07-07 05:04:03,560:INFO:Declaring metric variables
2024-07-07 05:04:03,561:INFO:Importing untrained model
2024-07-07 05:04:03,561:INFO:Declaring custom model
2024-07-07 05:04:03,562:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:04:03,563:INFO:Cross validation set to False
2024-07-07 05:04:03,563:INFO:Fitting Model
2024-07-07 05:04:03,697:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:04:03,697:INFO:create_model() successfully completed......................................
2024-07-07 05:04:03,882:INFO:_master_model_container: 15
2024-07-07 05:04:03,882:INFO:_display_container: 2
2024-07-07 05:04:03,884:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:04:03,884:INFO:compare_models() successfully completed......................................
2024-07-07 05:06:14,243:INFO:Initializing create_model()
2024-07-07 05:06:14,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:06:14,244:INFO:Checking exceptions
2024-07-07 05:06:14,280:INFO:Importing libraries
2024-07-07 05:06:14,280:INFO:Copying training dataset
2024-07-07 05:06:14,298:INFO:Defining folds
2024-07-07 05:06:14,300:INFO:Declaring metric variables
2024-07-07 05:06:14,313:INFO:Importing untrained model
2024-07-07 05:06:14,324:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:06:14,349:INFO:Starting cross validation
2024-07-07 05:06:14,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:06:15,661:INFO:Calculating mean and std
2024-07-07 05:06:15,663:INFO:Creating metrics dataframe
2024-07-07 05:06:15,680:INFO:Finalizing model
2024-07-07 05:06:15,831:INFO:Uploading results into container
2024-07-07 05:06:15,834:INFO:Uploading model into container now
2024-07-07 05:06:15,848:INFO:_master_model_container: 16
2024-07-07 05:06:15,848:INFO:_display_container: 3
2024-07-07 05:06:15,850:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:06:15,850:INFO:create_model() successfully completed......................................
2024-07-07 05:06:25,433:INFO:Initializing tune_model()
2024-07-07 05:06:25,434:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>)
2024-07-07 05:06:25,434:INFO:Checking exceptions
2024-07-07 05:06:25,490:INFO:Copying training dataset
2024-07-07 05:06:25,501:INFO:Checking base model
2024-07-07 05:06:25,502:INFO:Base model : Gradient Boosting Classifier
2024-07-07 05:06:25,511:INFO:Declaring metric variables
2024-07-07 05:06:25,523:INFO:Defining Hyperparameters
2024-07-07 05:06:25,654:INFO:Tuning with n_jobs=-1
2024-07-07 05:06:25,654:INFO:Initializing RandomizedSearchCV
2024-07-07 05:06:41,636:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-07-07 05:06:41,644:INFO:Hyperparameter search completed
2024-07-07 05:06:41,647:INFO:SubProcess create_model() called ==================================
2024-07-07 05:06:41,650:INFO:Initializing create_model()
2024-07-07 05:06:41,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78a9ca96be20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-07-07 05:06:41,650:INFO:Checking exceptions
2024-07-07 05:06:41,650:INFO:Importing libraries
2024-07-07 05:06:41,651:INFO:Copying training dataset
2024-07-07 05:06:41,679:INFO:Defining folds
2024-07-07 05:06:41,680:INFO:Declaring metric variables
2024-07-07 05:06:41,710:INFO:Importing untrained model
2024-07-07 05:06:41,710:INFO:Declaring custom model
2024-07-07 05:06:41,727:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:06:41,767:INFO:Starting cross validation
2024-07-07 05:06:41,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:06:44,214:INFO:Calculating mean and std
2024-07-07 05:06:44,216:INFO:Creating metrics dataframe
2024-07-07 05:06:44,233:INFO:Finalizing model
2024-07-07 05:06:44,472:INFO:Uploading results into container
2024-07-07 05:06:44,475:INFO:Uploading model into container now
2024-07-07 05:06:44,476:INFO:_master_model_container: 17
2024-07-07 05:06:44,477:INFO:_display_container: 4
2024-07-07 05:06:44,478:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:06:44,478:INFO:create_model() successfully completed......................................
2024-07-07 05:06:44,717:INFO:SubProcess create_model() end ==================================
2024-07-07 05:06:44,718:INFO:choose_better activated
2024-07-07 05:06:44,727:INFO:SubProcess create_model() called ==================================
2024-07-07 05:06:44,729:INFO:Initializing create_model()
2024-07-07 05:06:44,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:06:44,731:INFO:Checking exceptions
2024-07-07 05:06:44,734:INFO:Importing libraries
2024-07-07 05:06:44,735:INFO:Copying training dataset
2024-07-07 05:06:44,744:INFO:Defining folds
2024-07-07 05:06:44,744:INFO:Declaring metric variables
2024-07-07 05:06:44,745:INFO:Importing untrained model
2024-07-07 05:06:44,745:INFO:Declaring custom model
2024-07-07 05:06:44,746:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:06:44,747:INFO:Starting cross validation
2024-07-07 05:06:44,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:06:46,023:INFO:Calculating mean and std
2024-07-07 05:06:46,024:INFO:Creating metrics dataframe
2024-07-07 05:06:46,027:INFO:Finalizing model
2024-07-07 05:06:46,166:INFO:Uploading results into container
2024-07-07 05:06:46,167:INFO:Uploading model into container now
2024-07-07 05:06:46,168:INFO:_master_model_container: 18
2024-07-07 05:06:46,168:INFO:_display_container: 5
2024-07-07 05:06:46,169:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:06:46,169:INFO:create_model() successfully completed......................................
2024-07-07 05:06:46,299:INFO:SubProcess create_model() end ==================================
2024-07-07 05:06:46,301:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 05:06:46,302:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8633
2024-07-07 05:06:46,302:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-07 05:06:46,302:INFO:choose_better completed
2024-07-07 05:06:46,303:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 05:06:46,322:INFO:_master_model_container: 18
2024-07-07 05:06:46,323:INFO:_display_container: 4
2024-07-07 05:06:46,324:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:06:46,324:INFO:tune_model() successfully completed......................................
2024-07-07 05:07:17,826:INFO:Initializing tune_model()
2024-07-07 05:07:17,828:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>)
2024-07-07 05:07:17,828:INFO:Checking exceptions
2024-07-07 05:07:17,894:INFO:Copying training dataset
2024-07-07 05:07:17,905:INFO:Checking base model
2024-07-07 05:07:17,905:INFO:Base model : Gradient Boosting Classifier
2024-07-07 05:07:17,923:INFO:Declaring metric variables
2024-07-07 05:07:17,938:INFO:Defining Hyperparameters
2024-07-07 05:07:18,140:INFO:Tuning with n_jobs=-1
2024-07-07 05:07:18,141:INFO:Initializing RandomizedSearchCV
2024-07-07 05:07:31,188:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-07-07 05:07:31,189:INFO:Hyperparameter search completed
2024-07-07 05:07:31,190:INFO:SubProcess create_model() called ==================================
2024-07-07 05:07:31,193:INFO:Initializing create_model()
2024-07-07 05:07:31,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78a9a0a575b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-07-07 05:07:31,198:INFO:Checking exceptions
2024-07-07 05:07:31,198:INFO:Importing libraries
2024-07-07 05:07:31,199:INFO:Copying training dataset
2024-07-07 05:07:31,209:INFO:Defining folds
2024-07-07 05:07:31,209:INFO:Declaring metric variables
2024-07-07 05:07:31,221:INFO:Importing untrained model
2024-07-07 05:07:31,222:INFO:Declaring custom model
2024-07-07 05:07:31,236:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:07:31,258:INFO:Starting cross validation
2024-07-07 05:07:31,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:07:33,968:INFO:Calculating mean and std
2024-07-07 05:07:33,972:INFO:Creating metrics dataframe
2024-07-07 05:07:33,991:INFO:Finalizing model
2024-07-07 05:07:34,309:INFO:Uploading results into container
2024-07-07 05:07:34,311:INFO:Uploading model into container now
2024-07-07 05:07:34,312:INFO:_master_model_container: 19
2024-07-07 05:07:34,312:INFO:_display_container: 5
2024-07-07 05:07:34,313:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:07:34,314:INFO:create_model() successfully completed......................................
2024-07-07 05:07:34,480:INFO:SubProcess create_model() end ==================================
2024-07-07 05:07:34,480:INFO:choose_better activated
2024-07-07 05:07:34,492:INFO:SubProcess create_model() called ==================================
2024-07-07 05:07:34,494:INFO:Initializing create_model()
2024-07-07 05:07:34,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:07:34,494:INFO:Checking exceptions
2024-07-07 05:07:34,498:INFO:Importing libraries
2024-07-07 05:07:34,498:INFO:Copying training dataset
2024-07-07 05:07:34,508:INFO:Defining folds
2024-07-07 05:07:34,508:INFO:Declaring metric variables
2024-07-07 05:07:34,508:INFO:Importing untrained model
2024-07-07 05:07:34,509:INFO:Declaring custom model
2024-07-07 05:07:34,510:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 05:07:34,510:INFO:Starting cross validation
2024-07-07 05:07:34,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:07:36,672:INFO:Calculating mean and std
2024-07-07 05:07:36,673:INFO:Creating metrics dataframe
2024-07-07 05:07:36,678:INFO:Finalizing model
2024-07-07 05:07:36,887:INFO:Uploading results into container
2024-07-07 05:07:36,889:INFO:Uploading model into container now
2024-07-07 05:07:36,892:INFO:_master_model_container: 20
2024-07-07 05:07:36,893:INFO:_display_container: 6
2024-07-07 05:07:36,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:07:36,894:INFO:create_model() successfully completed......................................
2024-07-07 05:07:37,056:INFO:SubProcess create_model() end ==================================
2024-07-07 05:07:37,058:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 05:07:37,059:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8633
2024-07-07 05:07:37,060:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-07 05:07:37,060:INFO:choose_better completed
2024-07-07 05:07:37,061:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 05:07:37,082:INFO:_master_model_container: 20
2024-07-07 05:07:37,083:INFO:_display_container: 5
2024-07-07 05:07:37,084:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 05:07:37,084:INFO:tune_model() successfully completed......................................
2024-07-07 05:07:47,077:INFO:Initializing plot_model()
2024-07-07 05:07:47,079:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:07:47,079:INFO:Checking exceptions
2024-07-07 05:07:47,091:INFO:Preloading libraries
2024-07-07 05:07:47,111:INFO:Copying training dataset
2024-07-07 05:07:47,111:INFO:Plot type: error
2024-07-07 05:07:47,232:INFO:Fitting Model
2024-07-07 05:07:47,233:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-07 05:07:47,234:INFO:Scoring test/hold-out set
2024-07-07 05:07:47,586:INFO:Visual Rendered Successfully
2024-07-07 05:07:47,719:INFO:plot_model() successfully completed......................................
2024-07-07 05:07:58,972:INFO:Initializing plot_model()
2024-07-07 05:07:58,973:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:07:58,973:INFO:Checking exceptions
2024-07-07 05:07:58,982:INFO:Preloading libraries
2024-07-07 05:07:58,991:INFO:Copying training dataset
2024-07-07 05:07:58,992:INFO:Plot type: learning
2024-07-07 05:07:59,119:INFO:Fitting Model
2024-07-07 05:08:11,789:INFO:Visual Rendered Successfully
2024-07-07 05:08:11,931:INFO:plot_model() successfully completed......................................
2024-07-07 05:08:15,792:INFO:Initializing plot_model()
2024-07-07 05:08:15,792:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:08:15,792:INFO:Checking exceptions
2024-07-07 05:08:15,802:INFO:Preloading libraries
2024-07-07 05:08:15,812:INFO:Copying training dataset
2024-07-07 05:08:15,813:INFO:Plot type: vc
2024-07-07 05:08:15,814:INFO:Determining param_name
2024-07-07 05:08:15,814:INFO:param_name: max_depth
2024-07-07 05:08:15,930:INFO:Fitting Model
2024-07-07 05:08:29,409:INFO:Visual Rendered Successfully
2024-07-07 05:08:29,545:INFO:plot_model() successfully completed......................................
2024-07-07 05:09:10,086:INFO:Initializing plot_model()
2024-07-07 05:09:10,087:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:09:10,088:INFO:Checking exceptions
2024-07-07 05:09:10,098:INFO:Preloading libraries
2024-07-07 05:09:10,110:INFO:Copying training dataset
2024-07-07 05:09:10,111:INFO:Plot type: feature
2024-07-07 05:09:10,112:WARNING:No coef_ found. Trying feature_importances_
2024-07-07 05:09:10,379:INFO:Visual Rendered Successfully
2024-07-07 05:09:10,530:INFO:plot_model() successfully completed......................................
2024-07-07 05:15:20,726:INFO:Initializing create_model()
2024-07-07 05:15:20,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:15:20,727:INFO:Checking exceptions
2024-07-07 05:15:20,787:INFO:Importing libraries
2024-07-07 05:15:20,788:INFO:Copying training dataset
2024-07-07 05:15:20,810:INFO:Defining folds
2024-07-07 05:15:20,810:INFO:Declaring metric variables
2024-07-07 05:15:20,820:INFO:Importing untrained model
2024-07-07 05:15:20,831:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:15:20,853:INFO:Starting cross validation
2024-07-07 05:15:20,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:15:29,194:INFO:Calculating mean and std
2024-07-07 05:15:29,204:INFO:Creating metrics dataframe
2024-07-07 05:15:29,235:INFO:Finalizing model
2024-07-07 05:15:29,518:INFO:Uploading results into container
2024-07-07 05:15:29,525:INFO:Uploading model into container now
2024-07-07 05:15:29,551:INFO:_master_model_container: 21
2024-07-07 05:15:29,552:INFO:_display_container: 6
2024-07-07 05:15:29,553:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:15:29,553:INFO:create_model() successfully completed......................................
2024-07-07 05:15:37,362:INFO:Initializing tune_model()
2024-07-07 05:15:37,363:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>)
2024-07-07 05:15:37,364:INFO:Checking exceptions
2024-07-07 05:15:37,415:INFO:Copying training dataset
2024-07-07 05:15:37,427:INFO:Checking base model
2024-07-07 05:15:37,427:INFO:Base model : Random Forest Classifier
2024-07-07 05:15:37,439:INFO:Declaring metric variables
2024-07-07 05:15:37,452:INFO:Defining Hyperparameters
2024-07-07 05:15:37,588:INFO:Tuning with n_jobs=-1
2024-07-07 05:15:37,589:INFO:Initializing RandomizedSearchCV
2024-07-07 05:16:02,738:INFO:best_params: {'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-07 05:16:02,740:INFO:Hyperparameter search completed
2024-07-07 05:16:02,744:INFO:SubProcess create_model() called ==================================
2024-07-07 05:16:02,745:INFO:Initializing create_model()
2024-07-07 05:16:02,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78a9ffe43190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-07 05:16:02,745:INFO:Checking exceptions
2024-07-07 05:16:02,745:INFO:Importing libraries
2024-07-07 05:16:02,746:INFO:Copying training dataset
2024-07-07 05:16:02,765:INFO:Defining folds
2024-07-07 05:16:02,766:INFO:Declaring metric variables
2024-07-07 05:16:02,780:INFO:Importing untrained model
2024-07-07 05:16:02,780:INFO:Declaring custom model
2024-07-07 05:16:02,795:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:16:02,822:INFO:Starting cross validation
2024-07-07 05:16:02,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:16:07,957:INFO:Calculating mean and std
2024-07-07 05:16:07,959:INFO:Creating metrics dataframe
2024-07-07 05:16:07,979:INFO:Finalizing model
2024-07-07 05:16:08,397:INFO:Uploading results into container
2024-07-07 05:16:08,400:INFO:Uploading model into container now
2024-07-07 05:16:08,402:INFO:_master_model_container: 22
2024-07-07 05:16:08,402:INFO:_display_container: 7
2024-07-07 05:16:08,403:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=260, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-07-07 05:16:08,403:INFO:create_model() successfully completed......................................
2024-07-07 05:16:08,540:INFO:SubProcess create_model() end ==================================
2024-07-07 05:16:08,541:INFO:choose_better activated
2024-07-07 05:16:08,551:INFO:SubProcess create_model() called ==================================
2024-07-07 05:16:08,553:INFO:Initializing create_model()
2024-07-07 05:16:08,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:16:08,554:INFO:Checking exceptions
2024-07-07 05:16:08,557:INFO:Importing libraries
2024-07-07 05:16:08,558:INFO:Copying training dataset
2024-07-07 05:16:08,566:INFO:Defining folds
2024-07-07 05:16:08,566:INFO:Declaring metric variables
2024-07-07 05:16:08,566:INFO:Importing untrained model
2024-07-07 05:16:08,567:INFO:Declaring custom model
2024-07-07 05:16:08,568:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:16:08,568:INFO:Starting cross validation
2024-07-07 05:16:08,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:16:10,471:INFO:Calculating mean and std
2024-07-07 05:16:10,472:INFO:Creating metrics dataframe
2024-07-07 05:16:10,475:INFO:Finalizing model
2024-07-07 05:16:10,676:INFO:Uploading results into container
2024-07-07 05:16:10,678:INFO:Uploading model into container now
2024-07-07 05:16:10,678:INFO:_master_model_container: 23
2024-07-07 05:16:10,679:INFO:_display_container: 8
2024-07-07 05:16:10,680:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:16:10,680:INFO:create_model() successfully completed......................................
2024-07-07 05:16:10,826:INFO:SubProcess create_model() end ==================================
2024-07-07 05:16:10,827:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9833
2024-07-07 05:16:10,828:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=260, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9633
2024-07-07 05:16:10,829:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-07 05:16:10,829:INFO:choose_better completed
2024-07-07 05:16:10,830:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 05:16:10,847:INFO:_master_model_container: 23
2024-07-07 05:16:10,848:INFO:_display_container: 7
2024-07-07 05:16:10,848:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:16:10,849:INFO:tune_model() successfully completed......................................
2024-07-07 05:17:17,118:INFO:Initializing tune_model()
2024-07-07 05:17:17,119:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>)
2024-07-07 05:17:17,120:INFO:Checking exceptions
2024-07-07 05:17:17,170:INFO:Copying training dataset
2024-07-07 05:17:17,189:INFO:Checking base model
2024-07-07 05:17:17,191:INFO:Base model : Random Forest Classifier
2024-07-07 05:17:17,213:INFO:Declaring metric variables
2024-07-07 05:17:17,231:INFO:Defining Hyperparameters
2024-07-07 05:17:17,399:INFO:Tuning with n_jobs=-1
2024-07-07 05:17:17,399:INFO:Initializing RandomizedSearchCV
2024-07-07 05:17:42,973:INFO:best_params: {'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-07 05:17:42,980:INFO:Hyperparameter search completed
2024-07-07 05:17:42,980:INFO:SubProcess create_model() called ==================================
2024-07-07 05:17:42,981:INFO:Initializing create_model()
2024-07-07 05:17:42,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78a9cd5eec20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-07 05:17:42,982:INFO:Checking exceptions
2024-07-07 05:17:42,982:INFO:Importing libraries
2024-07-07 05:17:42,982:INFO:Copying training dataset
2024-07-07 05:17:43,001:INFO:Defining folds
2024-07-07 05:17:43,001:INFO:Declaring metric variables
2024-07-07 05:17:43,015:INFO:Importing untrained model
2024-07-07 05:17:43,016:INFO:Declaring custom model
2024-07-07 05:17:43,033:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:17:43,070:INFO:Starting cross validation
2024-07-07 05:17:43,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:17:47,839:INFO:Calculating mean and std
2024-07-07 05:17:47,841:INFO:Creating metrics dataframe
2024-07-07 05:17:47,856:INFO:Finalizing model
2024-07-07 05:17:48,274:INFO:Uploading results into container
2024-07-07 05:17:48,278:INFO:Uploading model into container now
2024-07-07 05:17:48,280:INFO:_master_model_container: 24
2024-07-07 05:17:48,280:INFO:_display_container: 8
2024-07-07 05:17:48,281:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=260, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-07-07 05:17:48,281:INFO:create_model() successfully completed......................................
2024-07-07 05:17:48,421:INFO:SubProcess create_model() end ==================================
2024-07-07 05:17:48,422:INFO:choose_better activated
2024-07-07 05:17:48,431:INFO:SubProcess create_model() called ==================================
2024-07-07 05:17:48,432:INFO:Initializing create_model()
2024-07-07 05:17:48,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 05:17:48,433:INFO:Checking exceptions
2024-07-07 05:17:48,436:INFO:Importing libraries
2024-07-07 05:17:48,436:INFO:Copying training dataset
2024-07-07 05:17:48,444:INFO:Defining folds
2024-07-07 05:17:48,445:INFO:Declaring metric variables
2024-07-07 05:17:48,445:INFO:Importing untrained model
2024-07-07 05:17:48,445:INFO:Declaring custom model
2024-07-07 05:17:48,446:INFO:Random Forest Classifier Imported successfully
2024-07-07 05:17:48,447:INFO:Starting cross validation
2024-07-07 05:17:48,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 05:17:50,351:INFO:Calculating mean and std
2024-07-07 05:17:50,352:INFO:Creating metrics dataframe
2024-07-07 05:17:50,354:INFO:Finalizing model
2024-07-07 05:17:50,551:INFO:Uploading results into container
2024-07-07 05:17:50,552:INFO:Uploading model into container now
2024-07-07 05:17:50,553:INFO:_master_model_container: 25
2024-07-07 05:17:50,553:INFO:_display_container: 9
2024-07-07 05:17:50,554:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:17:50,554:INFO:create_model() successfully completed......................................
2024-07-07 05:17:50,689:INFO:SubProcess create_model() end ==================================
2024-07-07 05:17:50,691:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9833
2024-07-07 05:17:50,692:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=260, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9633
2024-07-07 05:17:50,693:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-07 05:17:50,693:INFO:choose_better completed
2024-07-07 05:17:50,693:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 05:17:50,713:INFO:_master_model_container: 25
2024-07-07 05:17:50,713:INFO:_display_container: 8
2024-07-07 05:17:50,714:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 05:17:50,715:INFO:tune_model() successfully completed......................................
2024-07-07 05:17:56,479:INFO:Initializing plot_model()
2024-07-07 05:17:56,480:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:17:56,480:INFO:Checking exceptions
2024-07-07 05:17:56,520:INFO:Preloading libraries
2024-07-07 05:17:56,535:INFO:Copying training dataset
2024-07-07 05:17:56,535:INFO:Plot type: error
2024-07-07 05:17:56,696:INFO:Fitting Model
2024-07-07 05:17:56,696:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-07 05:17:56,697:INFO:Scoring test/hold-out set
2024-07-07 05:17:57,221:INFO:Visual Rendered Successfully
2024-07-07 05:17:57,401:INFO:plot_model() successfully completed......................................
2024-07-07 05:18:01,894:INFO:Initializing plot_model()
2024-07-07 05:18:01,894:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:18:01,895:INFO:Checking exceptions
2024-07-07 05:18:01,925:INFO:Preloading libraries
2024-07-07 05:18:01,936:INFO:Copying training dataset
2024-07-07 05:18:01,936:INFO:Plot type: learning
2024-07-07 05:18:02,058:INFO:Fitting Model
2024-07-07 05:18:24,221:INFO:Visual Rendered Successfully
2024-07-07 05:18:24,375:INFO:plot_model() successfully completed......................................
2024-07-07 05:18:24,385:INFO:Initializing plot_model()
2024-07-07 05:18:24,386:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:18:24,386:INFO:Checking exceptions
2024-07-07 05:18:24,416:INFO:Preloading libraries
2024-07-07 05:18:24,427:INFO:Copying training dataset
2024-07-07 05:18:24,428:INFO:Plot type: vc
2024-07-07 05:18:24,429:INFO:Determining param_name
2024-07-07 05:18:24,429:INFO:param_name: max_depth
2024-07-07 05:18:24,531:INFO:Fitting Model
2024-07-07 05:18:50,224:INFO:Visual Rendered Successfully
2024-07-07 05:18:50,370:INFO:plot_model() successfully completed......................................
2024-07-07 05:18:58,443:INFO:Initializing plot_model()
2024-07-07 05:18:58,444:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x78a9cc7ec190>, system=True)
2024-07-07 05:18:58,445:INFO:Checking exceptions
2024-07-07 05:18:58,476:INFO:Preloading libraries
2024-07-07 05:18:58,489:INFO:Copying training dataset
2024-07-07 05:18:58,489:INFO:Plot type: feature
2024-07-07 05:18:58,490:WARNING:No coef_ found. Trying feature_importances_
2024-07-07 05:18:58,780:INFO:Visual Rendered Successfully
2024-07-07 05:18:58,928:INFO:plot_model() successfully completed......................................
2024-07-07 17:05:17,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 17:05:17,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 17:05:17,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 17:05:17,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-07 17:05:18,564:INFO:PyCaret ClassificationExperiment
2024-07-07 17:05:18,565:INFO:Logging name: clf-default-name
2024-07-07 17:05:18,565:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-07 17:05:18,565:INFO:version 3.3.2
2024-07-07 17:05:18,566:INFO:Initializing setup()
2024-07-07 17:05:18,566:INFO:self.USI: 12f4
2024-07-07 17:05:18,566:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'html_param', 'gpu_param', 'X_test', 'X_train', 'gpu_n_jobs_param', 'USI', 'X', 'fix_imbalance', 'logging_param', 'memory', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'data', 'fold_groups_param', 'target_param', 'n_jobs_param', 'y_train', 'seed', 'y', 'y_test', 'is_multiclass', 'idx', '_available_plots', 'exp_id', 'exp_name_log'}
2024-07-07 17:05:18,566:INFO:Checking environment
2024-07-07 17:05:18,566:INFO:python_version: 3.10.12
2024-07-07 17:05:18,567:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-07 17:05:18,567:INFO:machine: x86_64
2024-07-07 17:05:18,567:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 17:05:18,567:INFO:Memory: svmem(total=13609431040, available=12387311616, percent=9.0, used=886300672, free=5879361536, active=799068160, inactive=6537965568, buffers=425406464, cached=6418362368, shared=2576384, slab=305258496)
2024-07-07 17:05:18,568:INFO:Physical Core: 1
2024-07-07 17:05:18,569:INFO:Logical Core: 2
2024-07-07 17:05:18,569:INFO:Checking libraries
2024-07-07 17:05:18,569:INFO:System:
2024-07-07 17:05:18,569:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-07 17:05:18,569:INFO:executable: /usr/bin/python3
2024-07-07 17:05:18,570:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 17:05:18,570:INFO:PyCaret required dependencies:
2024-07-07 17:05:20,004:INFO:                 pip: 23.1.2
2024-07-07 17:05:20,005:INFO:          setuptools: 67.7.2
2024-07-07 17:05:20,005:INFO:             pycaret: 3.3.2
2024-07-07 17:05:20,005:INFO:             IPython: 7.34.0
2024-07-07 17:05:20,005:INFO:          ipywidgets: 7.7.1
2024-07-07 17:05:20,005:INFO:                tqdm: 4.66.4
2024-07-07 17:05:20,006:INFO:               numpy: 1.25.2
2024-07-07 17:05:20,006:INFO:              pandas: 2.0.3
2024-07-07 17:05:20,006:INFO:              jinja2: 3.1.4
2024-07-07 17:05:20,006:INFO:               scipy: 1.11.4
2024-07-07 17:05:20,006:INFO:              joblib: 1.3.2
2024-07-07 17:05:20,006:INFO:             sklearn: 1.4.2
2024-07-07 17:05:20,006:INFO:                pyod: 2.0.1
2024-07-07 17:05:20,006:INFO:            imblearn: 0.12.3
2024-07-07 17:05:20,007:INFO:   category_encoders: 2.6.3
2024-07-07 17:05:20,007:INFO:            lightgbm: 4.1.0
2024-07-07 17:05:20,007:INFO:               numba: 0.58.1
2024-07-07 17:05:20,007:INFO:            requests: 2.31.0
2024-07-07 17:05:20,007:INFO:          matplotlib: 3.7.1
2024-07-07 17:05:20,007:INFO:          scikitplot: 0.3.7
2024-07-07 17:05:20,007:INFO:         yellowbrick: 1.5
2024-07-07 17:05:20,007:INFO:              plotly: 5.15.0
2024-07-07 17:05:20,008:INFO:    plotly-resampler: Not installed
2024-07-07 17:05:20,008:INFO:             kaleido: 0.2.1
2024-07-07 17:05:20,008:INFO:           schemdraw: 0.15
2024-07-07 17:05:20,008:INFO:         statsmodels: 0.14.2
2024-07-07 17:05:20,008:INFO:              sktime: 0.26.0
2024-07-07 17:05:20,008:INFO:               tbats: 1.1.3
2024-07-07 17:05:20,008:INFO:            pmdarima: 2.0.4
2024-07-07 17:05:20,008:INFO:              psutil: 5.9.5
2024-07-07 17:05:20,009:INFO:          markupsafe: 2.1.5
2024-07-07 17:05:20,009:INFO:             pickle5: Not installed
2024-07-07 17:05:20,009:INFO:         cloudpickle: 2.2.1
2024-07-07 17:05:20,009:INFO:         deprecation: 2.1.0
2024-07-07 17:05:20,009:INFO:              xxhash: 3.4.1
2024-07-07 17:05:20,009:INFO:           wurlitzer: 3.1.1
2024-07-07 17:05:20,009:INFO:PyCaret optional dependencies:
2024-07-07 17:05:20,600:INFO:                shap: Not installed
2024-07-07 17:05:20,601:INFO:           interpret: Not installed
2024-07-07 17:05:20,601:INFO:                umap: Not installed
2024-07-07 17:05:20,601:INFO:     ydata_profiling: Not installed
2024-07-07 17:05:20,601:INFO:  explainerdashboard: Not installed
2024-07-07 17:05:20,602:INFO:             autoviz: Not installed
2024-07-07 17:05:20,602:INFO:           fairlearn: Not installed
2024-07-07 17:05:20,602:INFO:          deepchecks: Not installed
2024-07-07 17:05:20,603:INFO:             xgboost: 2.0.3
2024-07-07 17:05:20,603:INFO:            catboost: Not installed
2024-07-07 17:05:20,603:INFO:              kmodes: Not installed
2024-07-07 17:05:20,603:INFO:             mlxtend: 0.22.0
2024-07-07 17:05:20,603:INFO:       statsforecast: Not installed
2024-07-07 17:05:20,603:INFO:        tune_sklearn: Not installed
2024-07-07 17:05:20,603:INFO:                 ray: Not installed
2024-07-07 17:05:20,603:INFO:            hyperopt: 0.2.7
2024-07-07 17:05:20,604:INFO:              optuna: Not installed
2024-07-07 17:05:20,604:INFO:               skopt: Not installed
2024-07-07 17:05:20,604:INFO:              mlflow: Not installed
2024-07-07 17:05:20,604:INFO:              gradio: Not installed
2024-07-07 17:05:20,604:INFO:             fastapi: Not installed
2024-07-07 17:05:20,604:INFO:             uvicorn: Not installed
2024-07-07 17:05:20,604:INFO:              m2cgen: Not installed
2024-07-07 17:05:20,604:INFO:           evidently: Not installed
2024-07-07 17:05:20,604:INFO:               fugue: Not installed
2024-07-07 17:05:20,605:INFO:           streamlit: Not installed
2024-07-07 17:05:20,605:INFO:             prophet: 1.1.5
2024-07-07 17:05:20,605:INFO:None
2024-07-07 17:05:20,605:INFO:Set up data.
2024-07-07 17:05:20,631:INFO:Set up folding strategy.
2024-07-07 17:05:20,632:INFO:Set up train/test split.
2024-07-07 17:05:20,667:INFO:Set up index.
2024-07-07 17:05:20,669:INFO:Assigning column types.
2024-07-07 17:05:20,694:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-07 17:05:21,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 17:05:21,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:05:21,210:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:21,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:21,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 17:05:21,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:05:21,678:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:21,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:21,699:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-07 17:05:21,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:05:22,123:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:22,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:22,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:05:22,575:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:22,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:22,598:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-07 17:05:22,989:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:23,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:23,655:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:23,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:23,689:INFO:Preparing preprocessing pipeline...
2024-07-07 17:05:23,706:INFO:Set up simple imputation.
2024-07-07 17:05:23,959:INFO:Finished creating preprocessing pipeline.
2024-07-07 17:05:23,975:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Solyc01g105660', 'Solyc02g061770',
                                             'Solyc02g062040', 'Solyc02g084850',
                                             'Solyc03g098100', 'Solyc03g098240',
                                             'Solyc03g121880', 'Solyc04g071780',
                                             'Solyc04g081900', 'Solyc04g005250',
                                             'Solyc04g009860', 'Solyc06g074940',
                                             'Solyc06g050130', 'Solyc06g06...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-07 17:05:23,981:INFO:Creating final display dataframe.
2024-07-07 17:05:25,005:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         condition
2                   Target type            Binary
3           Original data shape          (24, 27)
4        Transformed data shape          (24, 27)
5   Transformed train set shape          (19, 27)
6    Transformed test set shape           (5, 27)
7              Numeric features                26
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              12f4
2024-07-07 17:05:25,559:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:25,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:25,736:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:05:25,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:05:25,746:INFO:setup() successfully completed in 7.19s...............
2024-07-07 17:05:31,848:INFO:Initializing compare_models()
2024-07-07 17:05:31,849:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-07 17:05:31,849:INFO:Checking exceptions
2024-07-07 17:05:31,913:INFO:Preparing display monitor
2024-07-07 17:05:32,233:INFO:Initializing Logistic Regression
2024-07-07 17:05:32,238:INFO:Total runtime is 8.509953816731771e-05 minutes
2024-07-07 17:05:32,260:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:32,262:INFO:Initializing create_model()
2024-07-07 17:05:32,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:32,263:INFO:Checking exceptions
2024-07-07 17:05:32,263:INFO:Importing libraries
2024-07-07 17:05:32,263:INFO:Copying training dataset
2024-07-07 17:05:32,292:INFO:Defining folds
2024-07-07 17:05:32,308:INFO:Declaring metric variables
2024-07-07 17:05:32,363:INFO:Importing untrained model
2024-07-07 17:05:32,407:INFO:Logistic Regression Imported successfully
2024-07-07 17:05:32,523:INFO:Starting cross validation
2024-07-07 17:05:32,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:32,659:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:47,244:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:47,266:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,278:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,291:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,294:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:47,300:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:47,305:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:47,784:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:47,790:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,797:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,804:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,808:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:47,808:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:47,812:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:47,869:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:47,875:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,885:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,899:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:47,909:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:47,914:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:47,918:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:48,100:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:48,116:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,136:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,143:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,153:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:48,161:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:48,165:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:48,819:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,874:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:48,881:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,892:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,899:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:48,903:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:48,903:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:48,907:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:48,912:INFO:Calculating mean and std
2024-07-07 17:05:48,916:INFO:Creating metrics dataframe
2024-07-07 17:05:48,953:INFO:Uploading results into container
2024-07-07 17:05:48,963:INFO:Uploading model into container now
2024-07-07 17:05:48,968:INFO:_master_model_container: 1
2024-07-07 17:05:48,972:INFO:_display_container: 2
2024-07-07 17:05:48,974:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:05:48,974:INFO:create_model() successfully completed......................................
2024-07-07 17:05:49,340:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:49,341:INFO:Creating metrics dataframe
2024-07-07 17:05:49,360:INFO:Initializing K Neighbors Classifier
2024-07-07 17:05:49,365:INFO:Total runtime is 0.2855204184850057 minutes
2024-07-07 17:05:49,385:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:49,391:INFO:Initializing create_model()
2024-07-07 17:05:49,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:49,392:INFO:Checking exceptions
2024-07-07 17:05:49,393:INFO:Importing libraries
2024-07-07 17:05:49,393:INFO:Copying training dataset
2024-07-07 17:05:49,423:INFO:Defining folds
2024-07-07 17:05:49,425:INFO:Declaring metric variables
2024-07-07 17:05:49,449:INFO:Importing untrained model
2024-07-07 17:05:49,475:INFO:K Neighbors Classifier Imported successfully
2024-07-07 17:05:49,520:INFO:Starting cross validation
2024-07-07 17:05:49,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:49,531:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:49,826:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:49,837:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,831:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:49,843:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,849:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,865:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,868:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,871:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:49,872:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:49,875:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:49,892:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,895:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:49,902:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:49,906:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:49,930:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:49,935:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,941:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,955:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:49,958:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:49,959:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:49,963:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:50,018:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:50,025:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:50,230:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:50,298:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:50,314:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:50,356:INFO:Calculating mean and std
2024-07-07 17:05:50,359:INFO:Creating metrics dataframe
2024-07-07 17:05:50,364:INFO:Uploading results into container
2024-07-07 17:05:50,367:INFO:Uploading model into container now
2024-07-07 17:05:50,369:INFO:_master_model_container: 2
2024-07-07 17:05:50,370:INFO:_display_container: 2
2024-07-07 17:05:50,371:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-07 17:05:50,371:INFO:create_model() successfully completed......................................
2024-07-07 17:05:50,714:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:50,720:INFO:Creating metrics dataframe
2024-07-07 17:05:50,754:INFO:Initializing Naive Bayes
2024-07-07 17:05:50,761:INFO:Total runtime is 0.30879231293996173 minutes
2024-07-07 17:05:50,786:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:50,787:INFO:Initializing create_model()
2024-07-07 17:05:50,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:50,787:INFO:Checking exceptions
2024-07-07 17:05:50,787:INFO:Importing libraries
2024-07-07 17:05:50,787:INFO:Copying training dataset
2024-07-07 17:05:50,808:INFO:Defining folds
2024-07-07 17:05:50,809:INFO:Declaring metric variables
2024-07-07 17:05:50,826:INFO:Importing untrained model
2024-07-07 17:05:50,845:INFO:Naive Bayes Imported successfully
2024-07-07 17:05:50,884:INFO:Starting cross validation
2024-07-07 17:05:50,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:50,898:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:51,027:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:51,039:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,047:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:51,052:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,053:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,062:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,067:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,083:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,091:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:51,096:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,098:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,105:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,106:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:51,115:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,214:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:51,224:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,226:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:51,233:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,241:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,246:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,247:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,250:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,250:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:51,255:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,260:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,260:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:51,262:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,264:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,398:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,431:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,690:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:51,699:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,706:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,714:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:51,728:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,734:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:51,747:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:51,761:INFO:Calculating mean and std
2024-07-07 17:05:51,774:INFO:Creating metrics dataframe
2024-07-07 17:05:51,787:INFO:Uploading results into container
2024-07-07 17:05:51,792:INFO:Uploading model into container now
2024-07-07 17:05:51,795:INFO:_master_model_container: 3
2024-07-07 17:05:51,796:INFO:_display_container: 2
2024-07-07 17:05:51,796:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-07 17:05:51,796:INFO:create_model() successfully completed......................................
2024-07-07 17:05:52,286:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:52,286:INFO:Creating metrics dataframe
2024-07-07 17:05:52,323:INFO:Initializing Decision Tree Classifier
2024-07-07 17:05:52,335:INFO:Total runtime is 0.33502574761708576 minutes
2024-07-07 17:05:52,358:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:52,361:INFO:Initializing create_model()
2024-07-07 17:05:52,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:52,363:INFO:Checking exceptions
2024-07-07 17:05:52,363:INFO:Importing libraries
2024-07-07 17:05:52,364:INFO:Copying training dataset
2024-07-07 17:05:52,384:INFO:Defining folds
2024-07-07 17:05:52,397:INFO:Declaring metric variables
2024-07-07 17:05:52,428:INFO:Importing untrained model
2024-07-07 17:05:52,463:INFO:Decision Tree Classifier Imported successfully
2024-07-07 17:05:52,535:INFO:Starting cross validation
2024-07-07 17:05:52,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:52,563:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:52,700:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:52,706:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,710:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:52,713:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,717:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,720:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,723:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,723:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,723:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:52,727:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,729:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,731:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,732:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:52,736:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,815:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:52,815:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:52,820:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,826:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,829:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,832:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,835:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,839:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,840:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:52,840:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:52,843:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,843:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:52,844:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,847:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:52,975:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,037:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,043:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,049:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,056:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,059:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,060:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:53,062:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,065:INFO:Calculating mean and std
2024-07-07 17:05:53,068:INFO:Creating metrics dataframe
2024-07-07 17:05:53,078:INFO:Uploading results into container
2024-07-07 17:05:53,081:INFO:Uploading model into container now
2024-07-07 17:05:53,082:INFO:_master_model_container: 4
2024-07-07 17:05:53,083:INFO:_display_container: 2
2024-07-07 17:05:53,084:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-07-07 17:05:53,084:INFO:create_model() successfully completed......................................
2024-07-07 17:05:53,295:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:53,295:INFO:Creating metrics dataframe
2024-07-07 17:05:53,309:INFO:Initializing SVM - Linear Kernel
2024-07-07 17:05:53,310:INFO:Total runtime is 0.351276429494222 minutes
2024-07-07 17:05:53,329:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:53,330:INFO:Initializing create_model()
2024-07-07 17:05:53,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:53,331:INFO:Checking exceptions
2024-07-07 17:05:53,331:INFO:Importing libraries
2024-07-07 17:05:53,331:INFO:Copying training dataset
2024-07-07 17:05:53,346:INFO:Defining folds
2024-07-07 17:05:53,348:INFO:Declaring metric variables
2024-07-07 17:05:53,364:INFO:Importing untrained model
2024-07-07 17:05:53,379:INFO:SVM - Linear Kernel Imported successfully
2024-07-07 17:05:53,407:INFO:Starting cross validation
2024-07-07 17:05:53,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:53,417:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:53,470:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,475:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,481:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,481:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,486:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,486:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,489:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,490:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:53,493:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,544:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,549:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,554:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,556:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,560:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,561:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,564:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,566:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:53,567:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,570:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,573:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,578:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,581:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:53,587:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,694:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,754:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,799:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:53,802:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,806:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,810:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:53,812:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,812:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:53,815:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:53,828:INFO:Calculating mean and std
2024-07-07 17:05:53,835:INFO:Creating metrics dataframe
2024-07-07 17:05:53,848:INFO:Uploading results into container
2024-07-07 17:05:53,851:INFO:Uploading model into container now
2024-07-07 17:05:53,852:INFO:_master_model_container: 5
2024-07-07 17:05:53,854:INFO:_display_container: 2
2024-07-07 17:05:53,857:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-07 17:05:53,860:INFO:create_model() successfully completed......................................
2024-07-07 17:05:54,136:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:54,137:INFO:Creating metrics dataframe
2024-07-07 17:05:54,157:INFO:Initializing Ridge Classifier
2024-07-07 17:05:54,158:INFO:Total runtime is 0.36541096766789755 minutes
2024-07-07 17:05:54,178:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:54,179:INFO:Initializing create_model()
2024-07-07 17:05:54,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:54,180:INFO:Checking exceptions
2024-07-07 17:05:54,180:INFO:Importing libraries
2024-07-07 17:05:54,180:INFO:Copying training dataset
2024-07-07 17:05:54,198:INFO:Defining folds
2024-07-07 17:05:54,199:INFO:Declaring metric variables
2024-07-07 17:05:54,221:INFO:Importing untrained model
2024-07-07 17:05:54,238:INFO:Ridge Classifier Imported successfully
2024-07-07 17:05:54,277:INFO:Starting cross validation
2024-07-07 17:05:54,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:54,286:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:54,406:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:54,406:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:54,411:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,424:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,428:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,438:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,441:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,449:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,450:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:54,455:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,451:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,458:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,470:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:54,477:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,523:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:54,527:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,545:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,550:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,559:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,560:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:54,564:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,590:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:54,604:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,620:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,640:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,649:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,649:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:54,661:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,819:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,956:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:54,961:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,966:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,971:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:54,973:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,974:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:54,977:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:54,987:INFO:Calculating mean and std
2024-07-07 17:05:54,996:INFO:Creating metrics dataframe
2024-07-07 17:05:55,004:INFO:Uploading results into container
2024-07-07 17:05:55,007:INFO:Uploading model into container now
2024-07-07 17:05:55,008:INFO:_master_model_container: 6
2024-07-07 17:05:55,009:INFO:_display_container: 2
2024-07-07 17:05:55,010:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-07-07 17:05:55,011:INFO:create_model() successfully completed......................................
2024-07-07 17:05:55,280:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:55,281:INFO:Creating metrics dataframe
2024-07-07 17:05:55,305:INFO:Initializing Random Forest Classifier
2024-07-07 17:05:55,307:INFO:Total runtime is 0.3845578908920288 minutes
2024-07-07 17:05:55,330:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:55,333:INFO:Initializing create_model()
2024-07-07 17:05:55,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:55,334:INFO:Checking exceptions
2024-07-07 17:05:55,335:INFO:Importing libraries
2024-07-07 17:05:55,335:INFO:Copying training dataset
2024-07-07 17:05:55,356:INFO:Defining folds
2024-07-07 17:05:55,356:INFO:Declaring metric variables
2024-07-07 17:05:55,383:INFO:Importing untrained model
2024-07-07 17:05:55,405:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:05:55,437:INFO:Starting cross validation
2024-07-07 17:05:55,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:55,446:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:05:56,064:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:56,083:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,098:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,115:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,119:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,121:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:56,127:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,172:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:56,186:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,205:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,213:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,218:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:56,222:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,907:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:56,914:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,933:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,955:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,960:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,966:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:56,965:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:56,972:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:56,977:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:56,992:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:57,007:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:57,017:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:57,017:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:57,026:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:58,664:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:59,479:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:05:59,485:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:59,491:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:59,496:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:05:59,499:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:59,500:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:05:59,503:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:05:59,511:INFO:Calculating mean and std
2024-07-07 17:05:59,514:INFO:Creating metrics dataframe
2024-07-07 17:05:59,527:INFO:Uploading results into container
2024-07-07 17:05:59,531:INFO:Uploading model into container now
2024-07-07 17:05:59,532:INFO:_master_model_container: 7
2024-07-07 17:05:59,532:INFO:_display_container: 2
2024-07-07 17:05:59,533:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:05:59,534:INFO:create_model() successfully completed......................................
2024-07-07 17:05:59,801:INFO:SubProcess create_model() end ==================================
2024-07-07 17:05:59,804:INFO:Creating metrics dataframe
2024-07-07 17:05:59,830:INFO:Initializing Quadratic Discriminant Analysis
2024-07-07 17:05:59,832:INFO:Total runtime is 0.4599765300750732 minutes
2024-07-07 17:05:59,854:INFO:SubProcess create_model() called ==================================
2024-07-07 17:05:59,855:INFO:Initializing create_model()
2024-07-07 17:05:59,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:05:59,856:INFO:Checking exceptions
2024-07-07 17:05:59,856:INFO:Importing libraries
2024-07-07 17:05:59,856:INFO:Copying training dataset
2024-07-07 17:05:59,879:INFO:Defining folds
2024-07-07 17:05:59,880:INFO:Declaring metric variables
2024-07-07 17:05:59,896:INFO:Importing untrained model
2024-07-07 17:05:59,914:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-07 17:05:59,947:INFO:Starting cross validation
2024-07-07 17:05:59,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:05:59,955:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:00,029:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,059:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,070:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:00,080:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,098:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,112:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,113:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:00,120:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,122:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:00,128:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,124:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,151:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,167:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,177:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,178:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:00,182:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,214:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,254:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,256:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:00,270:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,290:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,306:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,316:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,317:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:00,312:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:00,321:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,324:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,346:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,357:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,363:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,368:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,369:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:00,374:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:00,440:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,523:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,562:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,571:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,600:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,612:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,665:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:06:00,676:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:00,680:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:00,701:INFO:Calculating mean and std
2024-07-07 17:06:00,704:INFO:Creating metrics dataframe
2024-07-07 17:06:00,709:INFO:Uploading results into container
2024-07-07 17:06:00,714:INFO:Uploading model into container now
2024-07-07 17:06:00,716:INFO:_master_model_container: 8
2024-07-07 17:06:00,717:INFO:_display_container: 2
2024-07-07 17:06:00,718:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-07 17:06:00,720:INFO:create_model() successfully completed......................................
2024-07-07 17:06:00,935:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:00,936:INFO:Creating metrics dataframe
2024-07-07 17:06:00,956:INFO:Initializing Ada Boost Classifier
2024-07-07 17:06:00,956:INFO:Total runtime is 0.4787177284558614 minutes
2024-07-07 17:06:00,971:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:00,971:INFO:Initializing create_model()
2024-07-07 17:06:00,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:00,972:INFO:Checking exceptions
2024-07-07 17:06:00,972:INFO:Importing libraries
2024-07-07 17:06:00,972:INFO:Copying training dataset
2024-07-07 17:06:00,987:INFO:Defining folds
2024-07-07 17:06:00,988:INFO:Declaring metric variables
2024-07-07 17:06:01,006:INFO:Importing untrained model
2024-07-07 17:06:01,020:INFO:Ada Boost Classifier Imported successfully
2024-07-07 17:06:01,045:INFO:Starting cross validation
2024-07-07 17:06:01,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:01,057:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:01,101:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,101:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,312:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:01,318:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,318:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:01,324:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,325:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,335:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,342:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,336:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,345:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,346:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:01,348:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,351:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:01,354:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,350:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,394:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,396:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,602:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:01,609:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,611:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:01,615:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,620:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,625:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,631:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,631:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,633:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:01,637:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:01,644:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,645:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:01,641:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,658:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:01,693:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,710:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:01,773:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:02,001:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:02,033:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,043:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:02,073:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:06:02,205:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:02,209:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,213:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,217:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,220:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:02,220:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:02,223:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:02,227:INFO:Calculating mean and std
2024-07-07 17:06:02,230:INFO:Creating metrics dataframe
2024-07-07 17:06:02,237:INFO:Uploading results into container
2024-07-07 17:06:02,239:INFO:Uploading model into container now
2024-07-07 17:06:02,242:INFO:_master_model_container: 9
2024-07-07 17:06:02,242:INFO:_display_container: 2
2024-07-07 17:06:02,243:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-07-07 17:06:02,243:INFO:create_model() successfully completed......................................
2024-07-07 17:06:02,461:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:02,461:INFO:Creating metrics dataframe
2024-07-07 17:06:02,476:INFO:Initializing Gradient Boosting Classifier
2024-07-07 17:06:02,476:INFO:Total runtime is 0.504051144917806 minutes
2024-07-07 17:06:02,491:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:02,492:INFO:Initializing create_model()
2024-07-07 17:06:02,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:02,493:INFO:Checking exceptions
2024-07-07 17:06:02,493:INFO:Importing libraries
2024-07-07 17:06:02,493:INFO:Copying training dataset
2024-07-07 17:06:02,507:INFO:Defining folds
2024-07-07 17:06:02,508:INFO:Declaring metric variables
2024-07-07 17:06:02,526:INFO:Importing untrained model
2024-07-07 17:06:02,541:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:06:02,569:INFO:Starting cross validation
2024-07-07 17:06:02,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:02,581:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:02,777:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:02,784:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,790:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,797:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,800:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:02,800:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:02,804:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:02,849:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:02,854:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,860:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,866:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:02,869:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:02,870:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:02,874:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,016:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:03,021:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,027:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,033:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,037:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,037:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:03,042:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,057:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:03,063:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,069:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,077:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,080:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,081:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:03,086:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,522:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,700:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:03,703:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,707:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,710:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:03,712:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,713:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:03,715:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:03,720:INFO:Calculating mean and std
2024-07-07 17:06:03,723:INFO:Creating metrics dataframe
2024-07-07 17:06:03,727:INFO:Uploading results into container
2024-07-07 17:06:03,729:INFO:Uploading model into container now
2024-07-07 17:06:03,733:INFO:_master_model_container: 10
2024-07-07 17:06:03,733:INFO:_display_container: 2
2024-07-07 17:06:03,737:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:06:03,739:INFO:create_model() successfully completed......................................
2024-07-07 17:06:03,954:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:03,955:INFO:Creating metrics dataframe
2024-07-07 17:06:03,972:INFO:Initializing Linear Discriminant Analysis
2024-07-07 17:06:03,973:INFO:Total runtime is 0.5289928197860718 minutes
2024-07-07 17:06:03,990:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:03,995:INFO:Initializing create_model()
2024-07-07 17:06:03,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:03,996:INFO:Checking exceptions
2024-07-07 17:06:03,996:INFO:Importing libraries
2024-07-07 17:06:03,996:INFO:Copying training dataset
2024-07-07 17:06:04,010:INFO:Defining folds
2024-07-07 17:06:04,011:INFO:Declaring metric variables
2024-07-07 17:06:04,029:INFO:Importing untrained model
2024-07-07 17:06:04,042:INFO:Linear Discriminant Analysis Imported successfully
2024-07-07 17:06:04,071:INFO:Starting cross validation
2024-07-07 17:06:04,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:04,084:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:04,142:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:04,143:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:04,148:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,148:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,153:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,159:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,162:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,163:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:04,172:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,222:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:04,227:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,233:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,237:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:04,241:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,242:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,244:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,244:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:04,248:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,389:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,444:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:04,450:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,456:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,463:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:04,467:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,468:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:04,471:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:04,485:INFO:Calculating mean and std
2024-07-07 17:06:04,488:INFO:Creating metrics dataframe
2024-07-07 17:06:04,495:INFO:Uploading results into container
2024-07-07 17:06:04,499:INFO:Uploading model into container now
2024-07-07 17:06:04,501:INFO:_master_model_container: 11
2024-07-07 17:06:04,501:INFO:_display_container: 2
2024-07-07 17:06:04,502:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-07 17:06:04,502:INFO:create_model() successfully completed......................................
2024-07-07 17:06:04,731:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:04,732:INFO:Creating metrics dataframe
2024-07-07 17:06:04,749:INFO:Initializing Extra Trees Classifier
2024-07-07 17:06:04,752:INFO:Total runtime is 0.5419793804486593 minutes
2024-07-07 17:06:04,767:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:04,768:INFO:Initializing create_model()
2024-07-07 17:06:04,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:04,768:INFO:Checking exceptions
2024-07-07 17:06:04,769:INFO:Importing libraries
2024-07-07 17:06:04,769:INFO:Copying training dataset
2024-07-07 17:06:04,782:INFO:Defining folds
2024-07-07 17:06:04,783:INFO:Declaring metric variables
2024-07-07 17:06:04,801:INFO:Importing untrained model
2024-07-07 17:06:04,821:INFO:Extra Trees Classifier Imported successfully
2024-07-07 17:06:04,855:INFO:Starting cross validation
2024-07-07 17:06:04,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:04,865:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:05,177:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:05,184:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,186:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:05,190:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,197:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,198:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,200:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,200:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:05,204:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,204:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,207:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,211:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:05,220:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,541:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:05,543:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:05,549:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,550:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,555:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,556:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,561:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,562:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:05,564:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,565:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:05,565:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,566:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:05,569:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:05,570:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:06,266:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:06,581:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:06,586:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:06,590:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:06,594:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:06,597:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:06,597:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:06,600:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:06,605:INFO:Calculating mean and std
2024-07-07 17:06:06,608:INFO:Creating metrics dataframe
2024-07-07 17:06:06,615:INFO:Uploading results into container
2024-07-07 17:06:06,617:INFO:Uploading model into container now
2024-07-07 17:06:06,618:INFO:_master_model_container: 12
2024-07-07 17:06:06,618:INFO:_display_container: 2
2024-07-07 17:06:06,620:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-07 17:06:06,620:INFO:create_model() successfully completed......................................
2024-07-07 17:06:06,829:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:06,829:INFO:Creating metrics dataframe
2024-07-07 17:06:06,851:INFO:Initializing Extreme Gradient Boosting
2024-07-07 17:06:06,851:INFO:Total runtime is 0.5769678513209026 minutes
2024-07-07 17:06:06,870:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:06,871:INFO:Initializing create_model()
2024-07-07 17:06:06,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:06,872:INFO:Checking exceptions
2024-07-07 17:06:06,873:INFO:Importing libraries
2024-07-07 17:06:06,877:INFO:Copying training dataset
2024-07-07 17:06:06,890:INFO:Defining folds
2024-07-07 17:06:06,891:INFO:Declaring metric variables
2024-07-07 17:06:06,917:INFO:Importing untrained model
2024-07-07 17:06:06,933:INFO:Extreme Gradient Boosting Imported successfully
2024-07-07 17:06:06,963:INFO:Starting cross validation
2024-07-07 17:06:06,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:06,973:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:07,169:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:07,169:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:07,175:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,176:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,182:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,182:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,188:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,188:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,191:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:07,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:07,196:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,196:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,297:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:07,303:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,309:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,312:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:07,316:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,319:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,323:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,324:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:07,325:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,328:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,331:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,337:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,340:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:07,343:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,440:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,583:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,739:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:07,744:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,751:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,757:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:07,760:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,760:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:07,764:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:07,770:INFO:Calculating mean and std
2024-07-07 17:06:07,772:INFO:Creating metrics dataframe
2024-07-07 17:06:07,777:INFO:Uploading results into container
2024-07-07 17:06:07,780:INFO:Uploading model into container now
2024-07-07 17:06:07,781:INFO:_master_model_container: 13
2024-07-07 17:06:07,782:INFO:_display_container: 2
2024-07-07 17:06:07,784:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-07 17:06:07,784:INFO:create_model() successfully completed......................................
2024-07-07 17:06:08,009:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:08,010:INFO:Creating metrics dataframe
2024-07-07 17:06:08,026:INFO:Initializing Light Gradient Boosting Machine
2024-07-07 17:06:08,027:INFO:Total runtime is 0.5965579509735108 minutes
2024-07-07 17:06:08,041:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:08,042:INFO:Initializing create_model()
2024-07-07 17:06:08,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:08,043:INFO:Checking exceptions
2024-07-07 17:06:08,043:INFO:Importing libraries
2024-07-07 17:06:08,043:INFO:Copying training dataset
2024-07-07 17:06:08,057:INFO:Defining folds
2024-07-07 17:06:08,058:INFO:Declaring metric variables
2024-07-07 17:06:08,079:INFO:Importing untrained model
2024-07-07 17:06:08,099:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-07 17:06:08,129:INFO:Starting cross validation
2024-07-07 17:06:08,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:08,139:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:08,515:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:08,535:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,540:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,545:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,554:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,554:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:08,557:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,551:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:08,562:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,575:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,581:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,586:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,589:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:08,596:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,723:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:08,728:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,732:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,736:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,739:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,740:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:08,742:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,886:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:08,898:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,910:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,922:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:08,930:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,931:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:08,935:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:08,940:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,010:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,044:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,126:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,369:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:09,376:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,385:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,396:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,404:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,405:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:09,401:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,408:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,426:INFO:Calculating mean and std
2024-07-07 17:06:09,430:INFO:Creating metrics dataframe
2024-07-07 17:06:09,439:INFO:Uploading results into container
2024-07-07 17:06:09,440:INFO:Uploading model into container now
2024-07-07 17:06:09,441:INFO:_master_model_container: 14
2024-07-07 17:06:09,441:INFO:_display_container: 2
2024-07-07 17:06:09,442:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-07 17:06:09,443:INFO:create_model() successfully completed......................................
2024-07-07 17:06:09,662:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:09,663:INFO:Creating metrics dataframe
2024-07-07 17:06:09,682:INFO:Initializing Dummy Classifier
2024-07-07 17:06:09,685:INFO:Total runtime is 0.6241972247759502 minutes
2024-07-07 17:06:09,699:INFO:SubProcess create_model() called ==================================
2024-07-07 17:06:09,699:INFO:Initializing create_model()
2024-07-07 17:06:09,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a3982260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:09,700:INFO:Checking exceptions
2024-07-07 17:06:09,700:INFO:Importing libraries
2024-07-07 17:06:09,700:INFO:Copying training dataset
2024-07-07 17:06:09,720:INFO:Defining folds
2024-07-07 17:06:09,721:INFO:Declaring metric variables
2024-07-07 17:06:09,745:INFO:Importing untrained model
2024-07-07 17:06:09,763:INFO:Dummy Classifier Imported successfully
2024-07-07 17:06:09,793:INFO:Starting cross validation
2024-07-07 17:06:09,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:06:09,802:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:06:09,845:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:09,853:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,862:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,862:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:09,868:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,868:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,871:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,871:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:09,873:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,875:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,884:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,890:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,890:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:09,894:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,915:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:09,920:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,925:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,931:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,934:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,934:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:09,934:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:09,938:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,940:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,953:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,959:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:09,962:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,963:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:09,966:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:09,988:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,025:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,046:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,090:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,110:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,133:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:06:10,137:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,141:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,145:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:06:10,147:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:10,148:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:06:10,150:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:06:10,158:INFO:Calculating mean and std
2024-07-07 17:06:10,160:INFO:Creating metrics dataframe
2024-07-07 17:06:10,168:INFO:Uploading results into container
2024-07-07 17:06:10,171:INFO:Uploading model into container now
2024-07-07 17:06:10,172:INFO:_master_model_container: 15
2024-07-07 17:06:10,173:INFO:_display_container: 2
2024-07-07 17:06:10,174:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-07-07 17:06:10,174:INFO:create_model() successfully completed......................................
2024-07-07 17:06:10,391:INFO:SubProcess create_model() end ==================================
2024-07-07 17:06:10,392:INFO:Creating metrics dataframe
2024-07-07 17:06:10,453:INFO:Initializing create_model()
2024-07-07 17:06:10,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0d998d270>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:06:10,455:INFO:Checking exceptions
2024-07-07 17:06:10,460:INFO:Importing libraries
2024-07-07 17:06:10,460:INFO:Copying training dataset
2024-07-07 17:06:10,470:INFO:Defining folds
2024-07-07 17:06:10,471:INFO:Declaring metric variables
2024-07-07 17:06:10,471:INFO:Importing untrained model
2024-07-07 17:06:10,472:INFO:Declaring custom model
2024-07-07 17:06:10,473:INFO:Logistic Regression Imported successfully
2024-07-07 17:06:10,474:INFO:Cross validation set to False
2024-07-07 17:06:10,474:INFO:Fitting Model
2024-07-07 17:06:10,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:06:10,498:INFO:create_model() successfully completed......................................
2024-07-07 17:06:10,905:INFO:_master_model_container: 15
2024-07-07 17:06:10,909:INFO:_display_container: 2
2024-07-07 17:06:10,910:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:06:10,910:INFO:compare_models() successfully completed......................................
2024-07-07 17:17:54,138:INFO:PyCaret ClassificationExperiment
2024-07-07 17:17:54,141:INFO:Logging name: clf-default-name
2024-07-07 17:17:54,141:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-07 17:17:54,141:INFO:version 3.3.2
2024-07-07 17:17:54,141:INFO:Initializing setup()
2024-07-07 17:17:54,142:INFO:self.USI: c7fd
2024-07-07 17:17:54,142:INFO:self._variable_keys: {'log_plots_param', 'pipeline', 'html_param', 'gpu_param', 'X_test', 'X_train', 'gpu_n_jobs_param', 'USI', 'X', 'fix_imbalance', 'logging_param', 'memory', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'data', 'fold_groups_param', 'target_param', 'n_jobs_param', 'y_train', 'seed', 'y', 'y_test', 'is_multiclass', 'idx', '_available_plots', 'exp_id', 'exp_name_log'}
2024-07-07 17:17:54,143:INFO:Checking environment
2024-07-07 17:17:54,143:INFO:python_version: 3.10.12
2024-07-07 17:17:54,144:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-07 17:17:54,144:INFO:machine: x86_64
2024-07-07 17:17:54,144:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 17:17:54,145:INFO:Memory: svmem(total=13609431040, available=12356386816, percent=9.2, used=917151744, free=7447842816, active=999415808, inactive=4766089216, buffers=431538176, cached=4812898304, shared=2666496, slab=288550912)
2024-07-07 17:17:54,146:INFO:Physical Core: 1
2024-07-07 17:17:54,147:INFO:Logical Core: 2
2024-07-07 17:17:54,147:INFO:Checking libraries
2024-07-07 17:17:54,147:INFO:System:
2024-07-07 17:17:54,147:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-07 17:17:54,147:INFO:executable: /usr/bin/python3
2024-07-07 17:17:54,148:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-07 17:17:54,148:INFO:PyCaret required dependencies:
2024-07-07 17:17:54,148:INFO:                 pip: 23.1.2
2024-07-07 17:17:54,149:INFO:          setuptools: 67.7.2
2024-07-07 17:17:54,149:INFO:             pycaret: 3.3.2
2024-07-07 17:17:54,149:INFO:             IPython: 7.34.0
2024-07-07 17:17:54,149:INFO:          ipywidgets: 7.7.1
2024-07-07 17:17:54,149:INFO:                tqdm: 4.66.4
2024-07-07 17:17:54,149:INFO:               numpy: 1.25.2
2024-07-07 17:17:54,149:INFO:              pandas: 2.0.3
2024-07-07 17:17:54,150:INFO:              jinja2: 3.1.4
2024-07-07 17:17:54,150:INFO:               scipy: 1.11.4
2024-07-07 17:17:54,150:INFO:              joblib: 1.3.2
2024-07-07 17:17:54,150:INFO:             sklearn: 1.4.2
2024-07-07 17:17:54,150:INFO:                pyod: 2.0.1
2024-07-07 17:17:54,150:INFO:            imblearn: 0.12.3
2024-07-07 17:17:54,150:INFO:   category_encoders: 2.6.3
2024-07-07 17:17:54,151:INFO:            lightgbm: 4.1.0
2024-07-07 17:17:54,151:INFO:               numba: 0.58.1
2024-07-07 17:17:54,151:INFO:            requests: 2.31.0
2024-07-07 17:17:54,151:INFO:          matplotlib: 3.7.1
2024-07-07 17:17:54,151:INFO:          scikitplot: 0.3.7
2024-07-07 17:17:54,151:INFO:         yellowbrick: 1.5
2024-07-07 17:17:54,151:INFO:              plotly: 5.15.0
2024-07-07 17:17:54,151:INFO:    plotly-resampler: Not installed
2024-07-07 17:17:54,152:INFO:             kaleido: 0.2.1
2024-07-07 17:17:54,152:INFO:           schemdraw: 0.15
2024-07-07 17:17:54,152:INFO:         statsmodels: 0.14.2
2024-07-07 17:17:54,152:INFO:              sktime: 0.26.0
2024-07-07 17:17:54,152:INFO:               tbats: 1.1.3
2024-07-07 17:17:54,152:INFO:            pmdarima: 2.0.4
2024-07-07 17:17:54,152:INFO:              psutil: 5.9.5
2024-07-07 17:17:54,153:INFO:          markupsafe: 2.1.5
2024-07-07 17:17:54,153:INFO:             pickle5: Not installed
2024-07-07 17:17:54,153:INFO:         cloudpickle: 2.2.1
2024-07-07 17:17:54,153:INFO:         deprecation: 2.1.0
2024-07-07 17:17:54,153:INFO:              xxhash: 3.4.1
2024-07-07 17:17:54,153:INFO:           wurlitzer: 3.1.1
2024-07-07 17:17:54,153:INFO:PyCaret optional dependencies:
2024-07-07 17:17:54,154:INFO:                shap: Not installed
2024-07-07 17:17:54,154:INFO:           interpret: Not installed
2024-07-07 17:17:54,154:INFO:                umap: Not installed
2024-07-07 17:17:54,154:INFO:     ydata_profiling: Not installed
2024-07-07 17:17:54,154:INFO:  explainerdashboard: Not installed
2024-07-07 17:17:54,154:INFO:             autoviz: Not installed
2024-07-07 17:17:54,154:INFO:           fairlearn: Not installed
2024-07-07 17:17:54,154:INFO:          deepchecks: Not installed
2024-07-07 17:17:54,155:INFO:             xgboost: 2.0.3
2024-07-07 17:17:54,155:INFO:            catboost: Not installed
2024-07-07 17:17:54,155:INFO:              kmodes: Not installed
2024-07-07 17:17:54,155:INFO:             mlxtend: 0.22.0
2024-07-07 17:17:54,155:INFO:       statsforecast: Not installed
2024-07-07 17:17:54,156:INFO:        tune_sklearn: Not installed
2024-07-07 17:17:54,156:INFO:                 ray: Not installed
2024-07-07 17:17:54,156:INFO:            hyperopt: 0.2.7
2024-07-07 17:17:54,156:INFO:              optuna: Not installed
2024-07-07 17:17:54,156:INFO:               skopt: Not installed
2024-07-07 17:17:54,156:INFO:              mlflow: Not installed
2024-07-07 17:17:54,156:INFO:              gradio: Not installed
2024-07-07 17:17:54,156:INFO:             fastapi: Not installed
2024-07-07 17:17:54,156:INFO:             uvicorn: Not installed
2024-07-07 17:17:54,157:INFO:              m2cgen: Not installed
2024-07-07 17:17:54,157:INFO:           evidently: Not installed
2024-07-07 17:17:54,157:INFO:               fugue: Not installed
2024-07-07 17:17:54,157:INFO:           streamlit: Not installed
2024-07-07 17:17:54,157:INFO:             prophet: 1.1.5
2024-07-07 17:17:54,157:INFO:None
2024-07-07 17:17:54,157:INFO:Set up data.
2024-07-07 17:17:54,174:INFO:Set up folding strategy.
2024-07-07 17:17:54,174:INFO:Set up train/test split.
2024-07-07 17:17:54,185:INFO:Set up index.
2024-07-07 17:17:54,186:INFO:Assigning column types.
2024-07-07 17:17:54,196:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-07 17:17:54,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,254:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,288:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:54,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:54,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,382:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:54,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:54,387:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-07 17:17:54,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,477:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:54,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:54,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-07 17:17:54,665:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:54,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:54,672:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-07 17:17:54,849:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:54,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:55,091:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:55,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:55,105:INFO:Preparing preprocessing pipeline...
2024-07-07 17:17:55,111:INFO:Set up simple imputation.
2024-07-07 17:17:55,187:INFO:Finished creating preprocessing pipeline.
2024-07-07 17:17:55,200:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Solyc01g105660', 'Solyc02g061770',
                                             'Solyc02g062040', 'Solyc02g084850',
                                             'Solyc03g098100', 'Solyc03g098240',
                                             'Solyc03g121880', 'Solyc04g071780',
                                             'Solyc04g081900', 'Solyc04g005250',
                                             'Solyc04g009860', 'Solyc06g074940',
                                             'Solyc06g050130', 'Solyc06g06...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-07 17:17:55,201:INFO:Creating final display dataframe.
2024-07-07 17:17:55,454:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         condition
2                   Target type            Binary
3           Original data shape          (24, 27)
4        Transformed data shape          (24, 27)
5   Transformed train set shape          (19, 27)
6    Transformed test set shape           (5, 27)
7              Numeric features                26
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c7fd
2024-07-07 17:17:55,639:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:55,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:55,889:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-07 17:17:55,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-07 17:17:55,913:INFO:setup() successfully completed in 1.79s...............
2024-07-07 17:18:00,790:INFO:Initializing compare_models()
2024-07-07 17:18:00,792:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-07 17:18:00,793:INFO:Checking exceptions
2024-07-07 17:18:00,817:INFO:Preparing display monitor
2024-07-07 17:18:01,004:INFO:Initializing Logistic Regression
2024-07-07 17:18:01,008:INFO:Total runtime is 7.21136728922526e-05 minutes
2024-07-07 17:18:01,030:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:01,037:INFO:Initializing create_model()
2024-07-07 17:18:01,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:01,038:INFO:Checking exceptions
2024-07-07 17:18:01,038:INFO:Importing libraries
2024-07-07 17:18:01,038:INFO:Copying training dataset
2024-07-07 17:18:01,060:INFO:Defining folds
2024-07-07 17:18:01,065:INFO:Declaring metric variables
2024-07-07 17:18:01,084:INFO:Importing untrained model
2024-07-07 17:18:01,104:INFO:Logistic Regression Imported successfully
2024-07-07 17:18:01,207:INFO:Starting cross validation
2024-07-07 17:18:01,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:01,222:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:14,119:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:14,185:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:14,189:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:14,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:14,205:INFO:Calculating mean and std
2024-07-07 17:18:14,213:INFO:Creating metrics dataframe
2024-07-07 17:18:14,239:INFO:Uploading results into container
2024-07-07 17:18:14,247:INFO:Uploading model into container now
2024-07-07 17:18:14,251:INFO:_master_model_container: 1
2024-07-07 17:18:14,257:INFO:_display_container: 2
2024-07-07 17:18:14,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:18:14,263:INFO:create_model() successfully completed......................................
2024-07-07 17:18:15,340:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:15,340:INFO:Creating metrics dataframe
2024-07-07 17:18:15,413:INFO:Initializing K Neighbors Classifier
2024-07-07 17:18:15,414:INFO:Total runtime is 0.24017156759897867 minutes
2024-07-07 17:18:15,485:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:15,485:INFO:Initializing create_model()
2024-07-07 17:18:15,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:15,489:INFO:Checking exceptions
2024-07-07 17:18:15,489:INFO:Importing libraries
2024-07-07 17:18:15,490:INFO:Copying training dataset
2024-07-07 17:18:15,536:INFO:Defining folds
2024-07-07 17:18:15,545:INFO:Declaring metric variables
2024-07-07 17:18:15,601:INFO:Importing untrained model
2024-07-07 17:18:15,633:INFO:K Neighbors Classifier Imported successfully
2024-07-07 17:18:15,714:INFO:Starting cross validation
2024-07-07 17:18:15,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:15,742:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:17,158:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:17,174:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:17,175:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:17,178:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:17,188:INFO:Calculating mean and std
2024-07-07 17:18:17,197:INFO:Creating metrics dataframe
2024-07-07 17:18:17,202:INFO:Uploading results into container
2024-07-07 17:18:17,207:INFO:Uploading model into container now
2024-07-07 17:18:17,208:INFO:_master_model_container: 2
2024-07-07 17:18:17,208:INFO:_display_container: 2
2024-07-07 17:18:17,209:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-07 17:18:17,209:INFO:create_model() successfully completed......................................
2024-07-07 17:18:17,372:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:17,373:INFO:Creating metrics dataframe
2024-07-07 17:18:17,384:INFO:Initializing Naive Bayes
2024-07-07 17:18:17,384:INFO:Total runtime is 0.27301091750462847 minutes
2024-07-07 17:18:17,396:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:17,397:INFO:Initializing create_model()
2024-07-07 17:18:17,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:17,397:INFO:Checking exceptions
2024-07-07 17:18:17,397:INFO:Importing libraries
2024-07-07 17:18:17,398:INFO:Copying training dataset
2024-07-07 17:18:17,409:INFO:Defining folds
2024-07-07 17:18:17,410:INFO:Declaring metric variables
2024-07-07 17:18:17,426:INFO:Importing untrained model
2024-07-07 17:18:17,436:INFO:Naive Bayes Imported successfully
2024-07-07 17:18:17,463:INFO:Starting cross validation
2024-07-07 17:18:17,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:17,472:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:17,810:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:17,820:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:17,821:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:17,823:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:17,829:INFO:Calculating mean and std
2024-07-07 17:18:17,831:INFO:Creating metrics dataframe
2024-07-07 17:18:17,841:INFO:Uploading results into container
2024-07-07 17:18:17,842:INFO:Uploading model into container now
2024-07-07 17:18:17,843:INFO:_master_model_container: 3
2024-07-07 17:18:17,844:INFO:_display_container: 2
2024-07-07 17:18:17,844:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-07 17:18:17,844:INFO:create_model() successfully completed......................................
2024-07-07 17:18:17,998:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:17,999:INFO:Creating metrics dataframe
2024-07-07 17:18:18,011:INFO:Initializing Decision Tree Classifier
2024-07-07 17:18:18,012:INFO:Total runtime is 0.2834660013516744 minutes
2024-07-07 17:18:18,025:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:18,025:INFO:Initializing create_model()
2024-07-07 17:18:18,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:18,026:INFO:Checking exceptions
2024-07-07 17:18:18,026:INFO:Importing libraries
2024-07-07 17:18:18,026:INFO:Copying training dataset
2024-07-07 17:18:18,038:INFO:Defining folds
2024-07-07 17:18:18,039:INFO:Declaring metric variables
2024-07-07 17:18:18,056:INFO:Importing untrained model
2024-07-07 17:18:18,069:INFO:Decision Tree Classifier Imported successfully
2024-07-07 17:18:18,097:INFO:Starting cross validation
2024-07-07 17:18:18,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:18,106:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:18,408:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:18:18,465:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:18,481:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:18,481:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:18,486:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:18,489:INFO:Calculating mean and std
2024-07-07 17:18:18,496:INFO:Creating metrics dataframe
2024-07-07 17:18:18,505:INFO:Uploading results into container
2024-07-07 17:18:18,507:INFO:Uploading model into container now
2024-07-07 17:18:18,508:INFO:_master_model_container: 4
2024-07-07 17:18:18,508:INFO:_display_container: 2
2024-07-07 17:18:18,509:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-07-07 17:18:18,509:INFO:create_model() successfully completed......................................
2024-07-07 17:18:18,708:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:18,709:INFO:Creating metrics dataframe
2024-07-07 17:18:18,725:INFO:Initializing SVM - Linear Kernel
2024-07-07 17:18:18,727:INFO:Total runtime is 0.2953895290692647 minutes
2024-07-07 17:18:18,743:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:18,743:INFO:Initializing create_model()
2024-07-07 17:18:18,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:18,747:INFO:Checking exceptions
2024-07-07 17:18:18,747:INFO:Importing libraries
2024-07-07 17:18:18,747:INFO:Copying training dataset
2024-07-07 17:18:18,766:INFO:Defining folds
2024-07-07 17:18:18,767:INFO:Declaring metric variables
2024-07-07 17:18:18,784:INFO:Importing untrained model
2024-07-07 17:18:18,800:INFO:SVM - Linear Kernel Imported successfully
2024-07-07 17:18:18,839:INFO:Starting cross validation
2024-07-07 17:18:18,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:18,847:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:19,321:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:19,336:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:19,337:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:19,344:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:19,359:INFO:Calculating mean and std
2024-07-07 17:18:19,362:INFO:Creating metrics dataframe
2024-07-07 17:18:19,372:INFO:Uploading results into container
2024-07-07 17:18:19,374:INFO:Uploading model into container now
2024-07-07 17:18:19,376:INFO:_master_model_container: 5
2024-07-07 17:18:19,378:INFO:_display_container: 2
2024-07-07 17:18:19,380:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-07 17:18:19,380:INFO:create_model() successfully completed......................................
2024-07-07 17:18:19,527:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:19,527:INFO:Creating metrics dataframe
2024-07-07 17:18:19,541:INFO:Initializing Ridge Classifier
2024-07-07 17:18:19,541:INFO:Total runtime is 0.3089612523714701 minutes
2024-07-07 17:18:19,554:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:19,554:INFO:Initializing create_model()
2024-07-07 17:18:19,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:19,555:INFO:Checking exceptions
2024-07-07 17:18:19,555:INFO:Importing libraries
2024-07-07 17:18:19,555:INFO:Copying training dataset
2024-07-07 17:18:19,567:INFO:Defining folds
2024-07-07 17:18:19,568:INFO:Declaring metric variables
2024-07-07 17:18:19,582:INFO:Importing untrained model
2024-07-07 17:18:19,594:INFO:Ridge Classifier Imported successfully
2024-07-07 17:18:19,630:INFO:Starting cross validation
2024-07-07 17:18:19,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:19,638:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:19,971:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:19,986:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:19,987:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:19,989:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:20,000:INFO:Calculating mean and std
2024-07-07 17:18:20,007:INFO:Creating metrics dataframe
2024-07-07 17:18:20,010:INFO:Uploading results into container
2024-07-07 17:18:20,012:INFO:Uploading model into container now
2024-07-07 17:18:20,014:INFO:_master_model_container: 6
2024-07-07 17:18:20,015:INFO:_display_container: 2
2024-07-07 17:18:20,015:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-07-07 17:18:20,015:INFO:create_model() successfully completed......................................
2024-07-07 17:18:20,165:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:20,166:INFO:Creating metrics dataframe
2024-07-07 17:18:20,181:INFO:Initializing Random Forest Classifier
2024-07-07 17:18:20,181:INFO:Total runtime is 0.3196279088656107 minutes
2024-07-07 17:18:20,194:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:20,194:INFO:Initializing create_model()
2024-07-07 17:18:20,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:20,195:INFO:Checking exceptions
2024-07-07 17:18:20,195:INFO:Importing libraries
2024-07-07 17:18:20,195:INFO:Copying training dataset
2024-07-07 17:18:20,208:INFO:Defining folds
2024-07-07 17:18:20,209:INFO:Declaring metric variables
2024-07-07 17:18:20,225:INFO:Importing untrained model
2024-07-07 17:18:20,239:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:18:20,262:INFO:Starting cross validation
2024-07-07 17:18:20,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:20,271:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:22,213:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:22,224:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:22,224:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:22,227:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:22,234:INFO:Calculating mean and std
2024-07-07 17:18:22,236:INFO:Creating metrics dataframe
2024-07-07 17:18:22,247:INFO:Uploading results into container
2024-07-07 17:18:22,248:INFO:Uploading model into container now
2024-07-07 17:18:22,249:INFO:_master_model_container: 7
2024-07-07 17:18:22,250:INFO:_display_container: 2
2024-07-07 17:18:22,250:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:18:22,251:INFO:create_model() successfully completed......................................
2024-07-07 17:18:22,401:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:22,401:INFO:Creating metrics dataframe
2024-07-07 17:18:22,414:INFO:Initializing Quadratic Discriminant Analysis
2024-07-07 17:18:22,414:INFO:Total runtime is 0.35684238672256463 minutes
2024-07-07 17:18:22,427:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:22,428:INFO:Initializing create_model()
2024-07-07 17:18:22,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:22,428:INFO:Checking exceptions
2024-07-07 17:18:22,429:INFO:Importing libraries
2024-07-07 17:18:22,429:INFO:Copying training dataset
2024-07-07 17:18:22,442:INFO:Defining folds
2024-07-07 17:18:22,444:INFO:Declaring metric variables
2024-07-07 17:18:22,458:INFO:Importing untrained model
2024-07-07 17:18:22,475:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-07 17:18:22,506:INFO:Starting cross validation
2024-07-07 17:18:22,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:22,513:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:22,560:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,561:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,631:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,657:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,694:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,722:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,763:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,784:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,821:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,844:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-07 17:18:22,860:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:22,870:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:22,870:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:22,872:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:22,875:INFO:Calculating mean and std
2024-07-07 17:18:22,877:INFO:Creating metrics dataframe
2024-07-07 17:18:22,884:INFO:Uploading results into container
2024-07-07 17:18:22,886:INFO:Uploading model into container now
2024-07-07 17:18:22,887:INFO:_master_model_container: 8
2024-07-07 17:18:22,887:INFO:_display_container: 2
2024-07-07 17:18:22,888:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-07 17:18:22,888:INFO:create_model() successfully completed......................................
2024-07-07 17:18:23,041:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:23,042:INFO:Creating metrics dataframe
2024-07-07 17:18:23,054:INFO:Initializing Ada Boost Classifier
2024-07-07 17:18:23,055:INFO:Total runtime is 0.36752107540766393 minutes
2024-07-07 17:18:23,067:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:23,070:INFO:Initializing create_model()
2024-07-07 17:18:23,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:23,071:INFO:Checking exceptions
2024-07-07 17:18:23,071:INFO:Importing libraries
2024-07-07 17:18:23,071:INFO:Copying training dataset
2024-07-07 17:18:23,082:INFO:Defining folds
2024-07-07 17:18:23,083:INFO:Declaring metric variables
2024-07-07 17:18:23,098:INFO:Importing untrained model
2024-07-07 17:18:23,113:INFO:Ada Boost Classifier Imported successfully
2024-07-07 17:18:23,136:INFO:Starting cross validation
2024-07-07 17:18:23,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:23,146:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:23,174:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,185:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,245:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,254:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,325:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,328:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,386:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,388:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,450:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,451:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-07 17:18:23,471:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:23,488:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:23,489:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:23,492:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:23,496:INFO:Calculating mean and std
2024-07-07 17:18:23,501:INFO:Creating metrics dataframe
2024-07-07 17:18:23,510:INFO:Uploading results into container
2024-07-07 17:18:23,512:INFO:Uploading model into container now
2024-07-07 17:18:23,514:INFO:_master_model_container: 9
2024-07-07 17:18:23,515:INFO:_display_container: 2
2024-07-07 17:18:23,515:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-07-07 17:18:23,516:INFO:create_model() successfully completed......................................
2024-07-07 17:18:23,681:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:23,682:INFO:Creating metrics dataframe
2024-07-07 17:18:23,702:INFO:Initializing Gradient Boosting Classifier
2024-07-07 17:18:23,702:INFO:Total runtime is 0.37830579678217563 minutes
2024-07-07 17:18:23,713:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:23,714:INFO:Initializing create_model()
2024-07-07 17:18:23,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:23,714:INFO:Checking exceptions
2024-07-07 17:18:23,714:INFO:Importing libraries
2024-07-07 17:18:23,715:INFO:Copying training dataset
2024-07-07 17:18:23,726:INFO:Defining folds
2024-07-07 17:18:23,727:INFO:Declaring metric variables
2024-07-07 17:18:23,743:INFO:Importing untrained model
2024-07-07 17:18:23,753:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:18:23,777:INFO:Starting cross validation
2024-07-07 17:18:23,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:23,787:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:24,737:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:24,746:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:24,747:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:24,749:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:24,756:INFO:Calculating mean and std
2024-07-07 17:18:24,758:INFO:Creating metrics dataframe
2024-07-07 17:18:24,764:INFO:Uploading results into container
2024-07-07 17:18:24,766:INFO:Uploading model into container now
2024-07-07 17:18:24,766:INFO:_master_model_container: 10
2024-07-07 17:18:24,767:INFO:_display_container: 2
2024-07-07 17:18:24,767:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:18:24,767:INFO:create_model() successfully completed......................................
2024-07-07 17:18:24,919:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:24,920:INFO:Creating metrics dataframe
2024-07-07 17:18:24,933:INFO:Initializing Linear Discriminant Analysis
2024-07-07 17:18:24,934:INFO:Total runtime is 0.398835003376007 minutes
2024-07-07 17:18:24,946:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:24,948:INFO:Initializing create_model()
2024-07-07 17:18:24,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:24,948:INFO:Checking exceptions
2024-07-07 17:18:24,949:INFO:Importing libraries
2024-07-07 17:18:24,949:INFO:Copying training dataset
2024-07-07 17:18:24,960:INFO:Defining folds
2024-07-07 17:18:24,960:INFO:Declaring metric variables
2024-07-07 17:18:24,975:INFO:Importing untrained model
2024-07-07 17:18:24,988:INFO:Linear Discriminant Analysis Imported successfully
2024-07-07 17:18:25,011:INFO:Starting cross validation
2024-07-07 17:18:25,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:25,021:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:25,328:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:25,342:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:25,342:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:25,344:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:25,352:INFO:Calculating mean and std
2024-07-07 17:18:25,355:INFO:Creating metrics dataframe
2024-07-07 17:18:25,363:INFO:Uploading results into container
2024-07-07 17:18:25,364:INFO:Uploading model into container now
2024-07-07 17:18:25,365:INFO:_master_model_container: 11
2024-07-07 17:18:25,365:INFO:_display_container: 2
2024-07-07 17:18:25,366:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-07 17:18:25,366:INFO:create_model() successfully completed......................................
2024-07-07 17:18:25,514:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:25,515:INFO:Creating metrics dataframe
2024-07-07 17:18:25,530:INFO:Initializing Extra Trees Classifier
2024-07-07 17:18:25,531:INFO:Total runtime is 0.4087874094645182 minutes
2024-07-07 17:18:25,543:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:25,544:INFO:Initializing create_model()
2024-07-07 17:18:25,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:25,544:INFO:Checking exceptions
2024-07-07 17:18:25,545:INFO:Importing libraries
2024-07-07 17:18:25,545:INFO:Copying training dataset
2024-07-07 17:18:25,556:INFO:Defining folds
2024-07-07 17:18:25,557:INFO:Declaring metric variables
2024-07-07 17:18:25,572:INFO:Importing untrained model
2024-07-07 17:18:25,589:INFO:Extra Trees Classifier Imported successfully
2024-07-07 17:18:25,627:INFO:Starting cross validation
2024-07-07 17:18:25,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:25,634:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:27,268:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:27,283:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:27,284:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:27,287:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:27,291:INFO:Calculating mean and std
2024-07-07 17:18:27,296:INFO:Creating metrics dataframe
2024-07-07 17:18:27,302:INFO:Uploading results into container
2024-07-07 17:18:27,307:INFO:Uploading model into container now
2024-07-07 17:18:27,309:INFO:_master_model_container: 12
2024-07-07 17:18:27,309:INFO:_display_container: 2
2024-07-07 17:18:27,310:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-07 17:18:27,311:INFO:create_model() successfully completed......................................
2024-07-07 17:18:27,502:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:27,503:INFO:Creating metrics dataframe
2024-07-07 17:18:27,524:INFO:Initializing Extreme Gradient Boosting
2024-07-07 17:18:27,528:INFO:Total runtime is 0.44207379817962644 minutes
2024-07-07 17:18:27,546:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:27,550:INFO:Initializing create_model()
2024-07-07 17:18:27,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:27,551:INFO:Checking exceptions
2024-07-07 17:18:27,551:INFO:Importing libraries
2024-07-07 17:18:27,551:INFO:Copying training dataset
2024-07-07 17:18:27,570:INFO:Defining folds
2024-07-07 17:18:27,570:INFO:Declaring metric variables
2024-07-07 17:18:27,592:INFO:Importing untrained model
2024-07-07 17:18:27,616:INFO:Extreme Gradient Boosting Imported successfully
2024-07-07 17:18:27,652:INFO:Starting cross validation
2024-07-07 17:18:27,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:27,663:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:27,879:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:18:28,663:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:18:28,761:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:28,781:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:28,782:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:18:28,785:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:18:28,791:INFO:Calculating mean and std
2024-07-07 17:18:28,794:INFO:Creating metrics dataframe
2024-07-07 17:18:28,800:INFO:Uploading results into container
2024-07-07 17:18:28,802:INFO:Uploading model into container now
2024-07-07 17:18:28,803:INFO:_master_model_container: 13
2024-07-07 17:18:28,803:INFO:_display_container: 2
2024-07-07 17:18:28,806:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-07 17:18:28,806:INFO:create_model() successfully completed......................................
2024-07-07 17:18:29,007:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:29,007:INFO:Creating metrics dataframe
2024-07-07 17:18:29,030:INFO:Initializing Light Gradient Boosting Machine
2024-07-07 17:18:29,035:INFO:Total runtime is 0.4671851595242818 minutes
2024-07-07 17:18:29,051:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:29,055:INFO:Initializing create_model()
2024-07-07 17:18:29,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:29,055:INFO:Checking exceptions
2024-07-07 17:18:29,055:INFO:Importing libraries
2024-07-07 17:18:29,056:INFO:Copying training dataset
2024-07-07 17:18:29,069:INFO:Defining folds
2024-07-07 17:18:29,069:INFO:Declaring metric variables
2024-07-07 17:18:29,093:INFO:Importing untrained model
2024-07-07 17:18:29,109:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-07 17:18:29,141:INFO:Starting cross validation
2024-07-07 17:18:29,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:29,152:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:30,680:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:30,689:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:18:30,705:INFO:Calculating mean and std
2024-07-07 17:18:30,708:INFO:Creating metrics dataframe
2024-07-07 17:18:30,712:INFO:Uploading results into container
2024-07-07 17:18:30,717:INFO:Uploading model into container now
2024-07-07 17:18:30,719:INFO:_master_model_container: 14
2024-07-07 17:18:30,719:INFO:_display_container: 2
2024-07-07 17:18:30,722:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-07 17:18:30,722:INFO:create_model() successfully completed......................................
2024-07-07 17:18:30,917:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:30,918:INFO:Creating metrics dataframe
2024-07-07 17:18:30,940:INFO:Initializing Dummy Classifier
2024-07-07 17:18:30,942:INFO:Total runtime is 0.4989770531654358 minutes
2024-07-07 17:18:30,961:INFO:SubProcess create_model() called ==================================
2024-07-07 17:18:30,966:INFO:Initializing create_model()
2024-07-07 17:18:30,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dcbd90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:30,967:INFO:Checking exceptions
2024-07-07 17:18:30,967:INFO:Importing libraries
2024-07-07 17:18:30,967:INFO:Copying training dataset
2024-07-07 17:18:30,986:INFO:Defining folds
2024-07-07 17:18:30,988:INFO:Declaring metric variables
2024-07-07 17:18:31,003:INFO:Importing untrained model
2024-07-07 17:18:31,020:INFO:Dummy Classifier Imported successfully
2024-07-07 17:18:31,048:INFO:Starting cross validation
2024-07-07 17:18:31,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:18:31,062:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:18:31,593:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:18:31,603:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-07 17:18:31,619:INFO:Calculating mean and std
2024-07-07 17:18:31,630:INFO:Creating metrics dataframe
2024-07-07 17:18:31,639:INFO:Uploading results into container
2024-07-07 17:18:31,644:INFO:Uploading model into container now
2024-07-07 17:18:31,645:INFO:_master_model_container: 15
2024-07-07 17:18:31,649:INFO:_display_container: 2
2024-07-07 17:18:31,649:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-07-07 17:18:31,649:INFO:create_model() successfully completed......................................
2024-07-07 17:18:31,859:INFO:SubProcess create_model() end ==================================
2024-07-07 17:18:31,861:INFO:Creating metrics dataframe
2024-07-07 17:18:31,937:INFO:Initializing create_model()
2024-07-07 17:18:31,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:18:31,938:INFO:Checking exceptions
2024-07-07 17:18:31,941:INFO:Importing libraries
2024-07-07 17:18:31,942:INFO:Copying training dataset
2024-07-07 17:18:31,957:INFO:Defining folds
2024-07-07 17:18:31,958:INFO:Declaring metric variables
2024-07-07 17:18:31,958:INFO:Importing untrained model
2024-07-07 17:18:31,959:INFO:Declaring custom model
2024-07-07 17:18:31,960:INFO:Logistic Regression Imported successfully
2024-07-07 17:18:31,961:INFO:Cross validation set to False
2024-07-07 17:18:31,962:INFO:Fitting Model
2024-07-07 17:18:31,993:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:18:31,994:INFO:create_model() successfully completed......................................
2024-07-07 17:18:32,265:INFO:_master_model_container: 15
2024-07-07 17:18:32,265:INFO:_display_container: 2
2024-07-07 17:18:32,266:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-07 17:18:32,267:INFO:compare_models() successfully completed......................................
2024-07-07 17:20:18,585:INFO:Initializing create_model()
2024-07-07 17:20:18,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:20:18,587:INFO:Checking exceptions
2024-07-07 17:20:18,645:INFO:Importing libraries
2024-07-07 17:20:18,646:INFO:Copying training dataset
2024-07-07 17:20:18,666:INFO:Defining folds
2024-07-07 17:20:18,667:INFO:Declaring metric variables
2024-07-07 17:20:18,677:INFO:Importing untrained model
2024-07-07 17:20:18,693:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:20:18,715:INFO:Starting cross validation
2024-07-07 17:20:18,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:20:18,723:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:20:19,619:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:20:19,637:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:19,637:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:20:19,641:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:19,669:INFO:Calculating mean and std
2024-07-07 17:20:19,673:INFO:Creating metrics dataframe
2024-07-07 17:20:19,694:INFO:Finalizing model
2024-07-07 17:20:19,827:INFO:Uploading results into container
2024-07-07 17:20:19,828:INFO:Uploading model into container now
2024-07-07 17:20:19,862:INFO:_master_model_container: 16
2024-07-07 17:20:19,862:INFO:_display_container: 3
2024-07-07 17:20:19,863:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:20:19,864:INFO:create_model() successfully completed......................................
2024-07-07 17:20:27,159:INFO:Initializing tune_model()
2024-07-07 17:20:27,162:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>)
2024-07-07 17:20:27,163:INFO:Checking exceptions
2024-07-07 17:20:27,224:INFO:Copying training dataset
2024-07-07 17:20:27,239:INFO:Checking base model
2024-07-07 17:20:27,240:INFO:Base model : Gradient Boosting Classifier
2024-07-07 17:20:27,257:INFO:Declaring metric variables
2024-07-07 17:20:27,271:INFO:Defining Hyperparameters
2024-07-07 17:20:27,487:INFO:Tuning with n_jobs=-1
2024-07-07 17:20:27,488:INFO:Initializing RandomizedSearchCV
2024-07-07 17:20:27,496:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:20:41,775:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2024-07-07 17:20:41,777:INFO:Hyperparameter search completed
2024-07-07 17:20:41,777:INFO:SubProcess create_model() called ==================================
2024-07-07 17:20:41,779:INFO:Initializing create_model()
2024-07-07 17:20:41,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0d998e3b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2024-07-07 17:20:41,779:INFO:Checking exceptions
2024-07-07 17:20:41,779:INFO:Importing libraries
2024-07-07 17:20:41,780:INFO:Copying training dataset
2024-07-07 17:20:41,807:INFO:Defining folds
2024-07-07 17:20:41,807:INFO:Declaring metric variables
2024-07-07 17:20:41,823:INFO:Importing untrained model
2024-07-07 17:20:41,824:INFO:Declaring custom model
2024-07-07 17:20:41,838:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:20:41,862:INFO:Starting cross validation
2024-07-07 17:20:41,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:20:41,872:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:20:43,335:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:20:43,351:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:43,351:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:20:43,353:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:43,362:INFO:Calculating mean and std
2024-07-07 17:20:43,365:INFO:Creating metrics dataframe
2024-07-07 17:20:43,386:INFO:Finalizing model
2024-07-07 17:20:43,559:INFO:Uploading results into container
2024-07-07 17:20:43,561:INFO:Uploading model into container now
2024-07-07 17:20:43,562:INFO:_master_model_container: 17
2024-07-07 17:20:43,562:INFO:_display_container: 4
2024-07-07 17:20:43,563:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:20:43,564:INFO:create_model() successfully completed......................................
2024-07-07 17:20:43,761:INFO:SubProcess create_model() end ==================================
2024-07-07 17:20:43,761:INFO:choose_better activated
2024-07-07 17:20:43,771:INFO:SubProcess create_model() called ==================================
2024-07-07 17:20:43,772:INFO:Initializing create_model()
2024-07-07 17:20:43,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:20:43,773:INFO:Checking exceptions
2024-07-07 17:20:43,778:INFO:Importing libraries
2024-07-07 17:20:43,778:INFO:Copying training dataset
2024-07-07 17:20:43,787:INFO:Defining folds
2024-07-07 17:20:43,787:INFO:Declaring metric variables
2024-07-07 17:20:43,788:INFO:Importing untrained model
2024-07-07 17:20:43,788:INFO:Declaring custom model
2024-07-07 17:20:43,789:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:20:43,790:INFO:Starting cross validation
2024-07-07 17:20:43,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:20:43,800:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:20:45,250:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:20:45,279:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:45,286:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:20:45,289:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:20:45,296:INFO:Calculating mean and std
2024-07-07 17:20:45,302:INFO:Creating metrics dataframe
2024-07-07 17:20:45,307:INFO:Finalizing model
2024-07-07 17:20:45,452:INFO:Uploading results into container
2024-07-07 17:20:45,453:INFO:Uploading model into container now
2024-07-07 17:20:45,454:INFO:_master_model_container: 18
2024-07-07 17:20:45,455:INFO:_display_container: 5
2024-07-07 17:20:45,455:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:20:45,456:INFO:create_model() successfully completed......................................
2024-07-07 17:20:45,645:INFO:SubProcess create_model() end ==================================
2024-07-07 17:20:45,647:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 17:20:45,648:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 17:20:45,649:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-07 17:20:45,649:INFO:choose_better completed
2024-07-07 17:20:45,650:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 17:20:45,678:INFO:_master_model_container: 18
2024-07-07 17:20:45,680:INFO:_display_container: 4
2024-07-07 17:20:45,681:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:20:45,682:INFO:tune_model() successfully completed......................................
2024-07-07 17:20:45,924:INFO:Initializing tune_model()
2024-07-07 17:20:45,925:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>)
2024-07-07 17:20:45,926:INFO:Checking exceptions
2024-07-07 17:20:45,986:INFO:Copying training dataset
2024-07-07 17:20:46,000:INFO:Checking base model
2024-07-07 17:20:46,002:INFO:Base model : Gradient Boosting Classifier
2024-07-07 17:20:46,025:INFO:Declaring metric variables
2024-07-07 17:20:46,043:INFO:Defining Hyperparameters
2024-07-07 17:20:46,237:INFO:Tuning with n_jobs=-1
2024-07-07 17:20:46,237:INFO:Initializing RandomizedSearchCV
2024-07-07 17:20:46,244:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:20:59,703:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2024-07-07 17:20:59,704:INFO:Hyperparameter search completed
2024-07-07 17:20:59,705:INFO:SubProcess create_model() called ==================================
2024-07-07 17:20:59,706:INFO:Initializing create_model()
2024-07-07 17:20:59,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076c6e650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2024-07-07 17:20:59,707:INFO:Checking exceptions
2024-07-07 17:20:59,707:INFO:Importing libraries
2024-07-07 17:20:59,708:INFO:Copying training dataset
2024-07-07 17:20:59,717:INFO:Defining folds
2024-07-07 17:20:59,718:INFO:Declaring metric variables
2024-07-07 17:20:59,732:INFO:Importing untrained model
2024-07-07 17:20:59,732:INFO:Declaring custom model
2024-07-07 17:20:59,745:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:20:59,774:INFO:Starting cross validation
2024-07-07 17:20:59,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:20:59,782:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:21:01,767:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:21:01,789:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:21:01,790:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:21:01,794:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:21:01,801:INFO:Calculating mean and std
2024-07-07 17:21:01,807:INFO:Creating metrics dataframe
2024-07-07 17:21:01,886:INFO:Finalizing model
2024-07-07 17:21:02,113:INFO:Uploading results into container
2024-07-07 17:21:02,116:INFO:Uploading model into container now
2024-07-07 17:21:02,118:INFO:_master_model_container: 19
2024-07-07 17:21:02,118:INFO:_display_container: 5
2024-07-07 17:21:02,119:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:21:02,119:INFO:create_model() successfully completed......................................
2024-07-07 17:21:02,297:INFO:SubProcess create_model() end ==================================
2024-07-07 17:21:02,298:INFO:choose_better activated
2024-07-07 17:21:02,309:INFO:SubProcess create_model() called ==================================
2024-07-07 17:21:02,311:INFO:Initializing create_model()
2024-07-07 17:21:02,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:21:02,312:INFO:Checking exceptions
2024-07-07 17:21:02,316:INFO:Importing libraries
2024-07-07 17:21:02,316:INFO:Copying training dataset
2024-07-07 17:21:02,329:INFO:Defining folds
2024-07-07 17:21:02,330:INFO:Declaring metric variables
2024-07-07 17:21:02,330:INFO:Importing untrained model
2024-07-07 17:21:02,330:INFO:Declaring custom model
2024-07-07 17:21:02,331:INFO:Gradient Boosting Classifier Imported successfully
2024-07-07 17:21:02,332:INFO:Starting cross validation
2024-07-07 17:21:02,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:21:02,338:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:21:04,232:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:21:04,253:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:21:04,254:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:21:04,258:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:21:04,269:INFO:Calculating mean and std
2024-07-07 17:21:04,270:INFO:Creating metrics dataframe
2024-07-07 17:21:04,278:INFO:Finalizing model
2024-07-07 17:21:04,416:INFO:Uploading results into container
2024-07-07 17:21:04,417:INFO:Uploading model into container now
2024-07-07 17:21:04,419:INFO:_master_model_container: 20
2024-07-07 17:21:04,419:INFO:_display_container: 6
2024-07-07 17:21:04,420:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:21:04,420:INFO:create_model() successfully completed......................................
2024-07-07 17:21:04,674:INFO:SubProcess create_model() end ==================================
2024-07-07 17:21:04,679:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 17:21:04,685:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 1.0
2024-07-07 17:21:04,689:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-07 17:21:04,690:INFO:choose_better completed
2024-07-07 17:21:04,696:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 17:21:04,743:INFO:_master_model_container: 20
2024-07-07 17:21:04,744:INFO:_display_container: 5
2024-07-07 17:21:04,745:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-07 17:21:04,745:INFO:tune_model() successfully completed......................................
2024-07-07 17:21:05,125:INFO:Initializing plot_model()
2024-07-07 17:21:05,126:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:21:05,126:INFO:Checking exceptions
2024-07-07 17:21:05,146:INFO:Preloading libraries
2024-07-07 17:21:05,171:INFO:Copying training dataset
2024-07-07 17:21:05,176:INFO:Plot type: error
2024-07-07 17:21:05,438:INFO:Fitting Model
2024-07-07 17:21:05,440:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-07 17:21:05,441:INFO:Scoring test/hold-out set
2024-07-07 17:21:06,187:INFO:Visual Rendered Successfully
2024-07-07 17:21:06,418:INFO:plot_model() successfully completed......................................
2024-07-07 17:21:06,435:INFO:Initializing plot_model()
2024-07-07 17:21:06,436:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:21:06,437:INFO:Checking exceptions
2024-07-07 17:21:06,456:INFO:Preloading libraries
2024-07-07 17:21:06,483:INFO:Copying training dataset
2024-07-07 17:21:06,483:INFO:Plot type: learning
2024-07-07 17:21:06,715:INFO:Fitting Model
2024-07-07 17:21:06,799:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:21:18,406:INFO:Visual Rendered Successfully
2024-07-07 17:21:18,629:INFO:plot_model() successfully completed......................................
2024-07-07 17:21:18,646:INFO:Initializing plot_model()
2024-07-07 17:21:18,647:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:21:18,647:INFO:Checking exceptions
2024-07-07 17:21:18,656:INFO:Preloading libraries
2024-07-07 17:21:18,669:INFO:Copying training dataset
2024-07-07 17:21:18,670:INFO:Plot type: vc
2024-07-07 17:21:18,672:INFO:Determining param_name
2024-07-07 17:21:18,673:INFO:param_name: max_depth
2024-07-07 17:21:18,807:INFO:Fitting Model
2024-07-07 17:21:18,830:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:21:29,704:INFO:Visual Rendered Successfully
2024-07-07 17:21:29,877:INFO:plot_model() successfully completed......................................
2024-07-07 17:21:29,891:INFO:Initializing plot_model()
2024-07-07 17:21:29,894:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:21:29,894:INFO:Checking exceptions
2024-07-07 17:21:29,902:INFO:Preloading libraries
2024-07-07 17:21:29,914:INFO:Copying training dataset
2024-07-07 17:21:29,914:INFO:Plot type: feature
2024-07-07 17:21:29,916:WARNING:No coef_ found. Trying feature_importances_
2024-07-07 17:21:30,180:INFO:Visual Rendered Successfully
2024-07-07 17:21:30,339:INFO:plot_model() successfully completed......................................
2024-07-07 17:26:02,426:INFO:Initializing create_model()
2024-07-07 17:26:02,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:26:02,433:INFO:Checking exceptions
2024-07-07 17:26:02,588:INFO:Importing libraries
2024-07-07 17:26:02,622:INFO:Copying training dataset
2024-07-07 17:26:02,648:INFO:Defining folds
2024-07-07 17:26:02,650:INFO:Declaring metric variables
2024-07-07 17:26:02,680:INFO:Importing untrained model
2024-07-07 17:26:02,719:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:26:02,811:INFO:Starting cross validation
2024-07-07 17:26:02,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:26:02,861:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:26:06,472:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:26:06,489:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:06,490:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:26:06,494:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:06,504:INFO:Calculating mean and std
2024-07-07 17:26:06,510:INFO:Creating metrics dataframe
2024-07-07 17:26:06,535:INFO:Finalizing model
2024-07-07 17:26:06,879:INFO:Uploading results into container
2024-07-07 17:26:06,884:INFO:Uploading model into container now
2024-07-07 17:26:06,908:INFO:_master_model_container: 21
2024-07-07 17:26:06,910:INFO:_display_container: 6
2024-07-07 17:26:06,911:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:26:06,912:INFO:create_model() successfully completed......................................
2024-07-07 17:26:19,221:INFO:Initializing tune_model()
2024-07-07 17:26:19,222:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>)
2024-07-07 17:26:19,222:INFO:Checking exceptions
2024-07-07 17:26:19,286:INFO:Copying training dataset
2024-07-07 17:26:19,297:INFO:Checking base model
2024-07-07 17:26:19,297:INFO:Base model : Random Forest Classifier
2024-07-07 17:26:19,313:INFO:Declaring metric variables
2024-07-07 17:26:19,327:INFO:Defining Hyperparameters
2024-07-07 17:26:19,521:INFO:Tuning with n_jobs=-1
2024-07-07 17:26:19,521:INFO:Initializing RandomizedSearchCV
2024-07-07 17:26:19,529:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:26:44,288:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-07 17:26:44,290:INFO:Hyperparameter search completed
2024-07-07 17:26:44,293:INFO:SubProcess create_model() called ==================================
2024-07-07 17:26:44,295:INFO:Initializing create_model()
2024-07-07 17:26:44,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb076dc8250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-07 17:26:44,295:INFO:Checking exceptions
2024-07-07 17:26:44,295:INFO:Importing libraries
2024-07-07 17:26:44,296:INFO:Copying training dataset
2024-07-07 17:26:44,305:INFO:Defining folds
2024-07-07 17:26:44,306:INFO:Declaring metric variables
2024-07-07 17:26:44,316:INFO:Importing untrained model
2024-07-07 17:26:44,316:INFO:Declaring custom model
2024-07-07 17:26:44,327:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:26:44,352:INFO:Starting cross validation
2024-07-07 17:26:44,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:26:44,361:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:26:47,101:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:26:47,112:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:47,113:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:26:47,115:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:47,125:INFO:Calculating mean and std
2024-07-07 17:26:47,127:INFO:Creating metrics dataframe
2024-07-07 17:26:47,146:INFO:Finalizing model
2024-07-07 17:26:47,478:INFO:Uploading results into container
2024-07-07 17:26:47,482:INFO:Uploading model into container now
2024-07-07 17:26:47,483:INFO:_master_model_container: 22
2024-07-07 17:26:47,483:INFO:_display_container: 7
2024-07-07 17:26:47,484:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-07-07 17:26:47,484:INFO:create_model() successfully completed......................................
2024-07-07 17:26:47,662:INFO:SubProcess create_model() end ==================================
2024-07-07 17:26:47,664:INFO:choose_better activated
2024-07-07 17:26:47,677:INFO:SubProcess create_model() called ==================================
2024-07-07 17:26:47,679:INFO:Initializing create_model()
2024-07-07 17:26:47,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:26:47,679:INFO:Checking exceptions
2024-07-07 17:26:47,683:INFO:Importing libraries
2024-07-07 17:26:47,684:INFO:Copying training dataset
2024-07-07 17:26:47,692:INFO:Defining folds
2024-07-07 17:26:47,692:INFO:Declaring metric variables
2024-07-07 17:26:47,693:INFO:Importing untrained model
2024-07-07 17:26:47,693:INFO:Declaring custom model
2024-07-07 17:26:47,694:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:26:47,695:INFO:Starting cross validation
2024-07-07 17:26:47,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:26:47,700:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:26:49,569:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:26:49,587:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:49,587:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:26:49,591:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:26:49,612:INFO:Calculating mean and std
2024-07-07 17:26:49,613:INFO:Creating metrics dataframe
2024-07-07 17:26:49,616:INFO:Finalizing model
2024-07-07 17:26:49,859:INFO:Uploading results into container
2024-07-07 17:26:49,861:INFO:Uploading model into container now
2024-07-07 17:26:49,863:INFO:_master_model_container: 23
2024-07-07 17:26:49,863:INFO:_display_container: 8
2024-07-07 17:26:49,865:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:26:49,865:INFO:create_model() successfully completed......................................
2024-07-07 17:26:50,076:INFO:SubProcess create_model() end ==================================
2024-07-07 17:26:50,079:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 1.0
2024-07-07 17:26:50,083:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 1.0
2024-07-07 17:26:50,084:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-07 17:26:50,084:INFO:choose_better completed
2024-07-07 17:26:50,085:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 17:26:50,112:INFO:_master_model_container: 23
2024-07-07 17:26:50,114:INFO:_display_container: 7
2024-07-07 17:26:50,115:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:26:50,115:INFO:tune_model() successfully completed......................................
2024-07-07 17:26:50,352:INFO:Initializing tune_model()
2024-07-07 17:26:50,355:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>)
2024-07-07 17:26:50,356:INFO:Checking exceptions
2024-07-07 17:26:50,410:INFO:Copying training dataset
2024-07-07 17:26:50,419:INFO:Checking base model
2024-07-07 17:26:50,421:INFO:Base model : Random Forest Classifier
2024-07-07 17:26:50,440:INFO:Declaring metric variables
2024-07-07 17:26:50,459:INFO:Defining Hyperparameters
2024-07-07 17:26:50,686:INFO:Tuning with n_jobs=-1
2024-07-07 17:26:50,687:INFO:Initializing RandomizedSearchCV
2024-07-07 17:26:50,696:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:27:16,353:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-07 17:27:16,354:INFO:Hyperparameter search completed
2024-07-07 17:27:16,355:INFO:SubProcess create_model() called ==================================
2024-07-07 17:27:16,360:INFO:Initializing create_model()
2024-07-07 17:27:16,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7eb0a390ed70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-07 17:27:16,360:INFO:Checking exceptions
2024-07-07 17:27:16,361:INFO:Importing libraries
2024-07-07 17:27:16,361:INFO:Copying training dataset
2024-07-07 17:27:16,375:INFO:Defining folds
2024-07-07 17:27:16,375:INFO:Declaring metric variables
2024-07-07 17:27:16,385:INFO:Importing untrained model
2024-07-07 17:27:16,385:INFO:Declaring custom model
2024-07-07 17:27:16,397:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:27:16,422:INFO:Starting cross validation
2024-07-07 17:27:16,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:27:16,431:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:27:19,279:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:27:19,289:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:27:19,290:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:27:19,293:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:27:19,301:INFO:Calculating mean and std
2024-07-07 17:27:19,304:INFO:Creating metrics dataframe
2024-07-07 17:27:19,321:INFO:Finalizing model
2024-07-07 17:27:19,647:INFO:Uploading results into container
2024-07-07 17:27:19,649:INFO:Uploading model into container now
2024-07-07 17:27:19,650:INFO:_master_model_container: 24
2024-07-07 17:27:19,651:INFO:_display_container: 8
2024-07-07 17:27:19,652:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-07-07 17:27:19,652:INFO:create_model() successfully completed......................................
2024-07-07 17:27:19,808:INFO:SubProcess create_model() end ==================================
2024-07-07 17:27:19,808:INFO:choose_better activated
2024-07-07 17:27:19,819:INFO:SubProcess create_model() called ==================================
2024-07-07 17:27:19,822:INFO:Initializing create_model()
2024-07-07 17:27:19,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-07 17:27:19,825:INFO:Checking exceptions
2024-07-07 17:27:19,828:INFO:Importing libraries
2024-07-07 17:27:19,829:INFO:Copying training dataset
2024-07-07 17:27:19,840:INFO:Defining folds
2024-07-07 17:27:19,841:INFO:Declaring metric variables
2024-07-07 17:27:19,841:INFO:Importing untrained model
2024-07-07 17:27:19,841:INFO:Declaring custom model
2024-07-07 17:27:19,843:INFO:Random Forest Classifier Imported successfully
2024-07-07 17:27:19,843:INFO:Starting cross validation
2024-07-07 17:27:19,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-07 17:27:19,849:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:27:21,796:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2024-07-07 17:27:21,806:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:27:21,806:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2024-07-07 17:27:21,809:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2024-07-07 17:27:21,820:INFO:Calculating mean and std
2024-07-07 17:27:21,821:INFO:Creating metrics dataframe
2024-07-07 17:27:21,824:INFO:Finalizing model
2024-07-07 17:27:22,048:INFO:Uploading results into container
2024-07-07 17:27:22,049:INFO:Uploading model into container now
2024-07-07 17:27:22,050:INFO:_master_model_container: 25
2024-07-07 17:27:22,051:INFO:_display_container: 9
2024-07-07 17:27:22,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:27:22,052:INFO:create_model() successfully completed......................................
2024-07-07 17:27:22,203:INFO:SubProcess create_model() end ==================================
2024-07-07 17:27:22,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 1.0
2024-07-07 17:27:22,206:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=190, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 1.0
2024-07-07 17:27:22,206:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-07 17:27:22,207:INFO:choose_better completed
2024-07-07 17:27:22,208:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-07 17:27:22,226:INFO:_master_model_container: 25
2024-07-07 17:27:22,226:INFO:_display_container: 8
2024-07-07 17:27:22,227:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-07 17:27:22,228:INFO:tune_model() successfully completed......................................
2024-07-07 17:27:22,444:INFO:Initializing plot_model()
2024-07-07 17:27:22,444:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:27:22,445:INFO:Checking exceptions
2024-07-07 17:27:22,479:INFO:Preloading libraries
2024-07-07 17:27:22,491:INFO:Copying training dataset
2024-07-07 17:27:22,492:INFO:Plot type: error
2024-07-07 17:27:22,629:INFO:Fitting Model
2024-07-07 17:27:22,629:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-07 17:27:22,630:INFO:Scoring test/hold-out set
2024-07-07 17:27:23,026:INFO:Visual Rendered Successfully
2024-07-07 17:27:23,195:INFO:plot_model() successfully completed......................................
2024-07-07 17:27:23,208:INFO:Initializing plot_model()
2024-07-07 17:27:23,210:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:27:23,210:INFO:Checking exceptions
2024-07-07 17:27:23,252:INFO:Preloading libraries
2024-07-07 17:27:23,266:INFO:Copying training dataset
2024-07-07 17:27:23,267:INFO:Plot type: learning
2024-07-07 17:27:23,386:INFO:Fitting Model
2024-07-07 17:27:23,406:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:27:48,716:INFO:Visual Rendered Successfully
2024-07-07 17:27:48,872:INFO:plot_model() successfully completed......................................
2024-07-07 17:27:48,886:INFO:Initializing plot_model()
2024-07-07 17:27:48,887:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:27:48,887:INFO:Checking exceptions
2024-07-07 17:27:48,920:INFO:Preloading libraries
2024-07-07 17:27:48,932:INFO:Copying training dataset
2024-07-07 17:27:48,932:INFO:Plot type: vc
2024-07-07 17:27:48,933:INFO:Determining param_name
2024-07-07 17:27:48,934:INFO:param_name: max_depth
2024-07-07 17:27:49,042:INFO:Fitting Model
2024-07-07 17:27:49,061:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2024-07-07 17:28:11,629:INFO:Visual Rendered Successfully
2024-07-07 17:28:11,785:INFO:plot_model() successfully completed......................................
2024-07-07 17:28:11,799:INFO:Initializing plot_model()
2024-07-07 17:28:11,801:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7eb0dafe5540>, system=True)
2024-07-07 17:28:11,802:INFO:Checking exceptions
2024-07-07 17:28:11,834:INFO:Preloading libraries
2024-07-07 17:28:11,846:INFO:Copying training dataset
2024-07-07 17:28:11,846:INFO:Plot type: feature
2024-07-07 17:28:11,848:WARNING:No coef_ found. Trying feature_importances_
2024-07-07 17:28:12,142:INFO:Visual Rendered Successfully
2024-07-07 17:28:12,304:INFO:plot_model() successfully completed......................................
2024-07-08 09:30:21,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:30:21,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:30:21,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:30:21,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 09:30:22,619:INFO:PyCaret ClassificationExperiment
2024-07-08 09:30:22,620:INFO:Logging name: clf-default-name
2024-07-08 09:30:22,620:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:30:22,620:INFO:version 3.3.2
2024-07-08 09:30:22,621:INFO:Initializing setup()
2024-07-08 09:30:22,621:INFO:self.USI: 1bb5
2024-07-08 09:30:22,621:INFO:self._variable_keys: {'y', 'logging_param', 'memory', 'seed', 'pipeline', '_available_plots', 'target_param', 'fold_groups_param', 'gpu_param', 'html_param', 'idx', 'fold_shuffle_param', 'y_train', 'USI', 'exp_name_log', 'data', '_ml_usecase', 'X_test', 'fix_imbalance', 'is_multiclass', 'X_train', 'log_plots_param', 'X', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_id', 'y_test', 'fold_generator'}
2024-07-08 09:30:22,621:INFO:Checking environment
2024-07-08 09:30:22,621:INFO:python_version: 3.10.12
2024-07-08 09:30:22,622:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-08 09:30:22,622:INFO:machine: x86_64
2024-07-08 09:30:22,623:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:30:22,623:INFO:Memory: svmem(total=13609431040, available=12383748096, percent=9.0, used=889630720, free=5976616960, active=788783104, inactive=6445248512, buffers=415449088, cached=6327734272, shared=2818048, slab=311508992)
2024-07-08 09:30:22,624:INFO:Physical Core: 1
2024-07-08 09:30:22,624:INFO:Logical Core: 2
2024-07-08 09:30:22,625:INFO:Checking libraries
2024-07-08 09:30:22,625:INFO:System:
2024-07-08 09:30:22,625:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-08 09:30:22,625:INFO:executable: /usr/bin/python3
2024-07-08 09:30:22,625:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:30:22,626:INFO:PyCaret required dependencies:
2024-07-08 09:30:24,262:INFO:                 pip: 23.1.2
2024-07-08 09:30:24,262:INFO:          setuptools: 67.7.2
2024-07-08 09:30:24,262:INFO:             pycaret: 3.3.2
2024-07-08 09:30:24,263:INFO:             IPython: 7.34.0
2024-07-08 09:30:24,263:INFO:          ipywidgets: 7.7.1
2024-07-08 09:30:24,263:INFO:                tqdm: 4.66.4
2024-07-08 09:30:24,263:INFO:               numpy: 1.25.2
2024-07-08 09:30:24,263:INFO:              pandas: 2.0.3
2024-07-08 09:30:24,263:INFO:              jinja2: 3.1.4
2024-07-08 09:30:24,263:INFO:               scipy: 1.11.4
2024-07-08 09:30:24,268:INFO:              joblib: 1.3.2
2024-07-08 09:30:24,268:INFO:             sklearn: 1.4.2
2024-07-08 09:30:24,268:INFO:                pyod: 2.0.1
2024-07-08 09:30:24,269:INFO:            imblearn: 0.12.3
2024-07-08 09:30:24,269:INFO:   category_encoders: 2.6.3
2024-07-08 09:30:24,269:INFO:            lightgbm: 4.1.0
2024-07-08 09:30:24,269:INFO:               numba: 0.58.1
2024-07-08 09:30:24,269:INFO:            requests: 2.31.0
2024-07-08 09:30:24,269:INFO:          matplotlib: 3.7.1
2024-07-08 09:30:24,269:INFO:          scikitplot: 0.3.7
2024-07-08 09:30:24,269:INFO:         yellowbrick: 1.5
2024-07-08 09:30:24,270:INFO:              plotly: 5.15.0
2024-07-08 09:30:24,270:INFO:    plotly-resampler: Not installed
2024-07-08 09:30:24,270:INFO:             kaleido: 0.2.1
2024-07-08 09:30:24,270:INFO:           schemdraw: 0.15
2024-07-08 09:30:24,270:INFO:         statsmodels: 0.14.2
2024-07-08 09:30:24,270:INFO:              sktime: 0.26.0
2024-07-08 09:30:24,270:INFO:               tbats: 1.1.3
2024-07-08 09:30:24,270:INFO:            pmdarima: 2.0.4
2024-07-08 09:30:24,270:INFO:              psutil: 5.9.5
2024-07-08 09:30:24,271:INFO:          markupsafe: 2.1.5
2024-07-08 09:30:24,271:INFO:             pickle5: Not installed
2024-07-08 09:30:24,271:INFO:         cloudpickle: 2.2.1
2024-07-08 09:30:24,271:INFO:         deprecation: 2.1.0
2024-07-08 09:30:24,271:INFO:              xxhash: 3.4.1
2024-07-08 09:30:24,271:INFO:           wurlitzer: 3.1.1
2024-07-08 09:30:24,271:INFO:PyCaret optional dependencies:
2024-07-08 09:30:24,570:INFO:                shap: Not installed
2024-07-08 09:30:24,570:INFO:           interpret: Not installed
2024-07-08 09:30:24,570:INFO:                umap: Not installed
2024-07-08 09:30:24,570:INFO:     ydata_profiling: Not installed
2024-07-08 09:30:24,570:INFO:  explainerdashboard: Not installed
2024-07-08 09:30:24,570:INFO:             autoviz: Not installed
2024-07-08 09:30:24,571:INFO:           fairlearn: Not installed
2024-07-08 09:30:24,571:INFO:          deepchecks: Not installed
2024-07-08 09:30:24,571:INFO:             xgboost: 2.0.3
2024-07-08 09:30:24,571:INFO:            catboost: Not installed
2024-07-08 09:30:24,572:INFO:              kmodes: Not installed
2024-07-08 09:30:24,573:INFO:             mlxtend: 0.22.0
2024-07-08 09:30:24,574:INFO:       statsforecast: Not installed
2024-07-08 09:30:24,574:INFO:        tune_sklearn: Not installed
2024-07-08 09:30:24,574:INFO:                 ray: Not installed
2024-07-08 09:30:24,575:INFO:            hyperopt: 0.2.7
2024-07-08 09:30:24,575:INFO:              optuna: Not installed
2024-07-08 09:30:24,575:INFO:               skopt: Not installed
2024-07-08 09:30:24,575:INFO:              mlflow: Not installed
2024-07-08 09:30:24,576:INFO:              gradio: Not installed
2024-07-08 09:30:24,576:INFO:             fastapi: Not installed
2024-07-08 09:30:24,576:INFO:             uvicorn: Not installed
2024-07-08 09:30:24,576:INFO:              m2cgen: Not installed
2024-07-08 09:30:24,576:INFO:           evidently: Not installed
2024-07-08 09:30:24,576:INFO:               fugue: Not installed
2024-07-08 09:30:24,577:INFO:           streamlit: Not installed
2024-07-08 09:30:24,578:INFO:             prophet: 1.1.5
2024-07-08 09:30:24,579:INFO:None
2024-07-08 09:30:24,579:INFO:Set up data.
2024-07-08 09:32:10,177:INFO:PyCaret ClassificationExperiment
2024-07-08 09:32:10,180:INFO:Logging name: clf-default-name
2024-07-08 09:32:10,180:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:32:10,180:INFO:version 3.3.2
2024-07-08 09:32:10,180:INFO:Initializing setup()
2024-07-08 09:32:10,180:INFO:self.USI: e57c
2024-07-08 09:32:10,180:INFO:self._variable_keys: {'y', 'logging_param', 'memory', 'seed', 'pipeline', '_available_plots', 'target_param', 'fold_groups_param', 'gpu_param', 'html_param', 'idx', 'fold_shuffle_param', 'y_train', 'USI', 'exp_name_log', 'data', '_ml_usecase', 'X_test', 'fix_imbalance', 'is_multiclass', 'X_train', 'log_plots_param', 'X', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_id', 'y_test', 'fold_generator'}
2024-07-08 09:32:10,181:INFO:Checking environment
2024-07-08 09:32:10,181:INFO:python_version: 3.10.12
2024-07-08 09:32:10,181:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-08 09:32:10,181:INFO:machine: x86_64
2024-07-08 09:32:10,181:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:32:10,181:INFO:Memory: svmem(total=13609431040, available=11962036224, percent=12.1, used=1311305728, free=5445062656, active=794890240, inactive=6958071808, buffers=417546240, cached=6435516416, shared=2863104, slab=314597376)
2024-07-08 09:32:10,182:INFO:Physical Core: 1
2024-07-08 09:32:10,182:INFO:Logical Core: 2
2024-07-08 09:32:10,182:INFO:Checking libraries
2024-07-08 09:32:10,182:INFO:System:
2024-07-08 09:32:10,182:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-08 09:32:10,183:INFO:executable: /usr/bin/python3
2024-07-08 09:32:10,183:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:32:10,183:INFO:PyCaret required dependencies:
2024-07-08 09:32:10,183:INFO:                 pip: 23.1.2
2024-07-08 09:32:10,183:INFO:          setuptools: 67.7.2
2024-07-08 09:32:10,183:INFO:             pycaret: 3.3.2
2024-07-08 09:32:10,183:INFO:             IPython: 7.34.0
2024-07-08 09:32:10,183:INFO:          ipywidgets: 7.7.1
2024-07-08 09:32:10,183:INFO:                tqdm: 4.66.4
2024-07-08 09:32:10,184:INFO:               numpy: 1.25.2
2024-07-08 09:32:10,184:INFO:              pandas: 2.0.3
2024-07-08 09:32:10,184:INFO:              jinja2: 3.1.4
2024-07-08 09:32:10,184:INFO:               scipy: 1.11.4
2024-07-08 09:32:10,184:INFO:              joblib: 1.3.2
2024-07-08 09:32:10,184:INFO:             sklearn: 1.4.2
2024-07-08 09:32:10,184:INFO:                pyod: 2.0.1
2024-07-08 09:32:10,184:INFO:            imblearn: 0.12.3
2024-07-08 09:32:10,184:INFO:   category_encoders: 2.6.3
2024-07-08 09:32:10,184:INFO:            lightgbm: 4.1.0
2024-07-08 09:32:10,184:INFO:               numba: 0.58.1
2024-07-08 09:32:10,185:INFO:            requests: 2.31.0
2024-07-08 09:32:10,185:INFO:          matplotlib: 3.7.1
2024-07-08 09:32:10,185:INFO:          scikitplot: 0.3.7
2024-07-08 09:32:10,185:INFO:         yellowbrick: 1.5
2024-07-08 09:32:10,185:INFO:              plotly: 5.15.0
2024-07-08 09:32:10,185:INFO:    plotly-resampler: Not installed
2024-07-08 09:32:10,185:INFO:             kaleido: 0.2.1
2024-07-08 09:32:10,185:INFO:           schemdraw: 0.15
2024-07-08 09:32:10,185:INFO:         statsmodels: 0.14.2
2024-07-08 09:32:10,185:INFO:              sktime: 0.26.0
2024-07-08 09:32:10,186:INFO:               tbats: 1.1.3
2024-07-08 09:32:10,186:INFO:            pmdarima: 2.0.4
2024-07-08 09:32:10,186:INFO:              psutil: 5.9.5
2024-07-08 09:32:10,186:INFO:          markupsafe: 2.1.5
2024-07-08 09:32:10,186:INFO:             pickle5: Not installed
2024-07-08 09:32:10,186:INFO:         cloudpickle: 2.2.1
2024-07-08 09:32:10,186:INFO:         deprecation: 2.1.0
2024-07-08 09:32:10,186:INFO:              xxhash: 3.4.1
2024-07-08 09:32:10,186:INFO:           wurlitzer: 3.1.1
2024-07-08 09:32:10,186:INFO:PyCaret optional dependencies:
2024-07-08 09:32:10,187:INFO:                shap: Not installed
2024-07-08 09:32:10,187:INFO:           interpret: Not installed
2024-07-08 09:32:10,187:INFO:                umap: Not installed
2024-07-08 09:32:10,187:INFO:     ydata_profiling: Not installed
2024-07-08 09:32:10,187:INFO:  explainerdashboard: Not installed
2024-07-08 09:32:10,187:INFO:             autoviz: Not installed
2024-07-08 09:32:10,187:INFO:           fairlearn: Not installed
2024-07-08 09:32:10,187:INFO:          deepchecks: Not installed
2024-07-08 09:32:10,187:INFO:             xgboost: 2.0.3
2024-07-08 09:32:10,187:INFO:            catboost: Not installed
2024-07-08 09:32:10,187:INFO:              kmodes: Not installed
2024-07-08 09:32:10,188:INFO:             mlxtend: 0.22.0
2024-07-08 09:32:10,188:INFO:       statsforecast: Not installed
2024-07-08 09:32:10,188:INFO:        tune_sklearn: Not installed
2024-07-08 09:32:10,188:INFO:                 ray: Not installed
2024-07-08 09:32:10,188:INFO:            hyperopt: 0.2.7
2024-07-08 09:32:10,188:INFO:              optuna: Not installed
2024-07-08 09:32:10,188:INFO:               skopt: Not installed
2024-07-08 09:32:10,188:INFO:              mlflow: Not installed
2024-07-08 09:32:10,188:INFO:              gradio: Not installed
2024-07-08 09:32:10,188:INFO:             fastapi: Not installed
2024-07-08 09:32:10,188:INFO:             uvicorn: Not installed
2024-07-08 09:32:10,188:INFO:              m2cgen: Not installed
2024-07-08 09:32:10,189:INFO:           evidently: Not installed
2024-07-08 09:32:10,189:INFO:               fugue: Not installed
2024-07-08 09:32:10,189:INFO:           streamlit: Not installed
2024-07-08 09:32:10,189:INFO:             prophet: 1.1.5
2024-07-08 09:32:10,189:INFO:None
2024-07-08 09:32:10,189:INFO:Set up data.
2024-07-08 09:32:10,213:INFO:Set up folding strategy.
2024-07-08 09:32:10,213:INFO:Set up train/test split.
2024-07-08 09:32:10,224:INFO:Set up index.
2024-07-08 09:32:10,224:INFO:Assigning column types.
2024-07-08 09:32:10,235:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 09:32:10,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,394:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:10,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:10,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,562:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:10,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:10,569:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 09:32:10,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,743:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:10,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:10,842:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:32:10,904:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:10,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:10,910:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-08 09:32:11,061:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:11,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:11,221:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:11,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:11,229:INFO:Preparing preprocessing pipeline...
2024-07-08 09:32:11,232:INFO:Set up simple imputation.
2024-07-08 09:32:11,234:INFO:Set up column name cleaning.
2024-07-08 09:32:11,307:INFO:Finished creating preprocessing pipeline.
2024-07-08 09:32:11,317:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Les.1577.1.A1_at',
                                             'Les.23.1.S1_at',
                                             'Les.249.1.S1_at',
                                             'Les.254.1.S1_at',
                                             'Les.3124.1.S1_at',
                                             'Les.3124.2.S1_at',
                                             'Les.3124.3.S1_at',
                                             'Les.3593.1.S1_at',
                                             'Les.37.1.S1_at',
                                             'Les.3774.1.S1_at',
                                             'Les.4089.1.S1_at',
                                             'Les.4346.1.S1_at',
                                             'Les.4686....
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-07-08 09:32:11,317:INFO:Creating final display dataframe.
2024-07-08 09:32:11,544:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Condition
2                   Target type            Binary
3           Original data shape          (12, 32)
4        Transformed data shape          (12, 32)
5   Transformed train set shape           (9, 32)
6    Transformed test set shape           (3, 32)
7              Numeric features                31
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e57c
2024-07-08 09:32:11,725:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:11,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:11,884:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:32:11,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:32:11,893:INFO:setup() successfully completed in 1.72s...............
2024-07-08 09:32:19,193:INFO:Initializing compare_models()
2024-07-08 09:32:19,194:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-08 09:32:19,194:INFO:Checking exceptions
2024-07-08 09:32:19,206:INFO:Preparing display monitor
2024-07-08 09:32:19,282:INFO:Initializing Logistic Regression
2024-07-08 09:32:19,283:INFO:Total runtime is 1.388390858968099e-05 minutes
2024-07-08 09:32:19,294:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:19,295:INFO:Initializing create_model()
2024-07-08 09:32:19,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,296:INFO:Checking exceptions
2024-07-08 09:32:19,296:INFO:Importing libraries
2024-07-08 09:32:19,297:INFO:Copying training dataset
2024-07-08 09:32:19,307:INFO:Defining folds
2024-07-08 09:32:19,307:INFO:Declaring metric variables
2024-07-08 09:32:19,316:INFO:Importing untrained model
2024-07-08 09:32:19,327:INFO:Logistic Regression Imported successfully
2024-07-08 09:32:19,358:INFO:Starting cross validation
2024-07-08 09:32:19,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:19,386:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:19,392:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:19,393:INFO:Initializing create_model()
2024-07-08 09:32:19,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,393:INFO:Checking exceptions
2024-07-08 09:32:19,393:INFO:Importing libraries
2024-07-08 09:32:19,394:INFO:Copying training dataset
2024-07-08 09:32:19,415:INFO:Defining folds
2024-07-08 09:32:19,416:INFO:Declaring metric variables
2024-07-08 09:32:19,434:INFO:Importing untrained model
2024-07-08 09:32:19,449:INFO:Logistic Regression Imported successfully
2024-07-08 09:32:19,483:INFO:Starting cross validation
2024-07-08 09:32:19,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:19,493:ERROR:create_model() for lr raised an exception or returned all 0.0:
2024-07-08 09:32:19,494:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:19,495:INFO:Initializing K Neighbors Classifier
2024-07-08 09:32:19,495:INFO:Total runtime is 0.003555146853129069 minutes
2024-07-08 09:32:19,512:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:19,513:INFO:Initializing create_model()
2024-07-08 09:32:19,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,514:INFO:Checking exceptions
2024-07-08 09:32:19,514:INFO:Importing libraries
2024-07-08 09:32:19,514:INFO:Copying training dataset
2024-07-08 09:32:19,528:INFO:Defining folds
2024-07-08 09:32:19,528:INFO:Declaring metric variables
2024-07-08 09:32:19,544:INFO:Importing untrained model
2024-07-08 09:32:19,563:INFO:K Neighbors Classifier Imported successfully
2024-07-08 09:32:19,601:INFO:Starting cross validation
2024-07-08 09:32:19,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:19,629:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:19,630:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:19,631:INFO:Initializing create_model()
2024-07-08 09:32:19,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,632:INFO:Checking exceptions
2024-07-08 09:32:19,632:INFO:Importing libraries
2024-07-08 09:32:19,632:INFO:Copying training dataset
2024-07-08 09:32:19,654:INFO:Defining folds
2024-07-08 09:32:19,655:INFO:Declaring metric variables
2024-07-08 09:32:19,689:INFO:Importing untrained model
2024-07-08 09:32:19,713:INFO:K Neighbors Classifier Imported successfully
2024-07-08 09:32:19,779:INFO:Starting cross validation
2024-07-08 09:32:19,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:19,808:ERROR:create_model() for knn raised an exception or returned all 0.0:
2024-07-08 09:32:19,809:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:19,809:INFO:Initializing Naive Bayes
2024-07-08 09:32:19,809:INFO:Total runtime is 0.008791351318359375 minutes
2024-07-08 09:32:19,828:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:19,829:INFO:Initializing create_model()
2024-07-08 09:32:19,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,829:INFO:Checking exceptions
2024-07-08 09:32:19,829:INFO:Importing libraries
2024-07-08 09:32:19,829:INFO:Copying training dataset
2024-07-08 09:32:19,842:INFO:Defining folds
2024-07-08 09:32:19,842:INFO:Declaring metric variables
2024-07-08 09:32:19,854:INFO:Importing untrained model
2024-07-08 09:32:19,866:INFO:Naive Bayes Imported successfully
2024-07-08 09:32:19,893:INFO:Starting cross validation
2024-07-08 09:32:19,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:19,907:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:19,908:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:19,908:INFO:Initializing create_model()
2024-07-08 09:32:19,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:19,909:INFO:Checking exceptions
2024-07-08 09:32:19,909:INFO:Importing libraries
2024-07-08 09:32:19,909:INFO:Copying training dataset
2024-07-08 09:32:19,923:INFO:Defining folds
2024-07-08 09:32:19,924:INFO:Declaring metric variables
2024-07-08 09:32:19,936:INFO:Importing untrained model
2024-07-08 09:32:19,950:INFO:Naive Bayes Imported successfully
2024-07-08 09:32:20,129:INFO:Starting cross validation
2024-07-08 09:32:20,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,140:ERROR:create_model() for nb raised an exception or returned all 0.0:
2024-07-08 09:32:20,140:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,141:INFO:Initializing Decision Tree Classifier
2024-07-08 09:32:20,141:INFO:Total runtime is 0.01431896686553955 minutes
2024-07-08 09:32:20,150:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,151:INFO:Initializing create_model()
2024-07-08 09:32:20,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,151:INFO:Checking exceptions
2024-07-08 09:32:20,152:INFO:Importing libraries
2024-07-08 09:32:20,152:INFO:Copying training dataset
2024-07-08 09:32:20,163:INFO:Defining folds
2024-07-08 09:32:20,163:INFO:Declaring metric variables
2024-07-08 09:32:20,172:INFO:Importing untrained model
2024-07-08 09:32:20,187:INFO:Decision Tree Classifier Imported successfully
2024-07-08 09:32:20,207:INFO:Starting cross validation
2024-07-08 09:32:20,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,217:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:20,218:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,218:INFO:Initializing create_model()
2024-07-08 09:32:20,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,219:INFO:Checking exceptions
2024-07-08 09:32:20,219:INFO:Importing libraries
2024-07-08 09:32:20,219:INFO:Copying training dataset
2024-07-08 09:32:20,230:INFO:Defining folds
2024-07-08 09:32:20,230:INFO:Declaring metric variables
2024-07-08 09:32:20,243:INFO:Importing untrained model
2024-07-08 09:32:20,254:INFO:Decision Tree Classifier Imported successfully
2024-07-08 09:32:20,274:INFO:Starting cross validation
2024-07-08 09:32:20,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,283:ERROR:create_model() for dt raised an exception or returned all 0.0:
2024-07-08 09:32:20,284:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,284:INFO:Initializing SVM - Linear Kernel
2024-07-08 09:32:20,284:INFO:Total runtime is 0.01670395533243815 minutes
2024-07-08 09:32:20,293:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,294:INFO:Initializing create_model()
2024-07-08 09:32:20,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,294:INFO:Checking exceptions
2024-07-08 09:32:20,294:INFO:Importing libraries
2024-07-08 09:32:20,295:INFO:Copying training dataset
2024-07-08 09:32:20,305:INFO:Defining folds
2024-07-08 09:32:20,305:INFO:Declaring metric variables
2024-07-08 09:32:20,316:INFO:Importing untrained model
2024-07-08 09:32:20,330:INFO:SVM - Linear Kernel Imported successfully
2024-07-08 09:32:20,353:INFO:Starting cross validation
2024-07-08 09:32:20,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,363:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:20,364:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,365:INFO:Initializing create_model()
2024-07-08 09:32:20,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,365:INFO:Checking exceptions
2024-07-08 09:32:20,365:INFO:Importing libraries
2024-07-08 09:32:20,365:INFO:Copying training dataset
2024-07-08 09:32:20,375:INFO:Defining folds
2024-07-08 09:32:20,375:INFO:Declaring metric variables
2024-07-08 09:32:20,387:INFO:Importing untrained model
2024-07-08 09:32:20,400:INFO:SVM - Linear Kernel Imported successfully
2024-07-08 09:32:20,420:INFO:Starting cross validation
2024-07-08 09:32:20,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,428:ERROR:create_model() for svm raised an exception or returned all 0.0:
2024-07-08 09:32:20,428:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,429:INFO:Initializing Ridge Classifier
2024-07-08 09:32:20,429:INFO:Total runtime is 0.019116886456807453 minutes
2024-07-08 09:32:20,438:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,439:INFO:Initializing create_model()
2024-07-08 09:32:20,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,440:INFO:Checking exceptions
2024-07-08 09:32:20,440:INFO:Importing libraries
2024-07-08 09:32:20,440:INFO:Copying training dataset
2024-07-08 09:32:20,450:INFO:Defining folds
2024-07-08 09:32:20,451:INFO:Declaring metric variables
2024-07-08 09:32:20,467:INFO:Importing untrained model
2024-07-08 09:32:20,478:INFO:Ridge Classifier Imported successfully
2024-07-08 09:32:20,499:INFO:Starting cross validation
2024-07-08 09:32:20,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,510:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:20,510:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,511:INFO:Initializing create_model()
2024-07-08 09:32:20,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,512:INFO:Checking exceptions
2024-07-08 09:32:20,512:INFO:Importing libraries
2024-07-08 09:32:20,512:INFO:Copying training dataset
2024-07-08 09:32:20,522:INFO:Defining folds
2024-07-08 09:32:20,522:INFO:Declaring metric variables
2024-07-08 09:32:20,534:INFO:Importing untrained model
2024-07-08 09:32:20,544:INFO:Ridge Classifier Imported successfully
2024-07-08 09:32:20,568:INFO:Starting cross validation
2024-07-08 09:32:20,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,576:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2024-07-08 09:32:20,577:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,578:INFO:Initializing Random Forest Classifier
2024-07-08 09:32:20,578:INFO:Total runtime is 0.021600941816965737 minutes
2024-07-08 09:32:20,587:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,587:INFO:Initializing create_model()
2024-07-08 09:32:20,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,588:INFO:Checking exceptions
2024-07-08 09:32:20,588:INFO:Importing libraries
2024-07-08 09:32:20,588:INFO:Copying training dataset
2024-07-08 09:32:20,603:INFO:Defining folds
2024-07-08 09:32:20,604:INFO:Declaring metric variables
2024-07-08 09:32:20,618:INFO:Importing untrained model
2024-07-08 09:32:20,632:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:32:20,657:INFO:Starting cross validation
2024-07-08 09:32:20,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,667:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:20,668:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,668:INFO:Initializing create_model()
2024-07-08 09:32:20,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,669:INFO:Checking exceptions
2024-07-08 09:32:20,669:INFO:Importing libraries
2024-07-08 09:32:20,669:INFO:Copying training dataset
2024-07-08 09:32:20,682:INFO:Defining folds
2024-07-08 09:32:20,683:INFO:Declaring metric variables
2024-07-08 09:32:20,693:INFO:Importing untrained model
2024-07-08 09:32:20,707:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:32:20,737:INFO:Starting cross validation
2024-07-08 09:32:20,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,748:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-07-08 09:32:20,749:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,750:INFO:Initializing Quadratic Discriminant Analysis
2024-07-08 09:32:20,750:INFO:Total runtime is 0.024468366305033365 minutes
2024-07-08 09:32:20,769:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,770:INFO:Initializing create_model()
2024-07-08 09:32:20,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,771:INFO:Checking exceptions
2024-07-08 09:32:20,771:INFO:Importing libraries
2024-07-08 09:32:20,771:INFO:Copying training dataset
2024-07-08 09:32:20,784:INFO:Defining folds
2024-07-08 09:32:20,784:INFO:Declaring metric variables
2024-07-08 09:32:20,802:INFO:Importing untrained model
2024-07-08 09:32:20,818:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-08 09:32:20,842:INFO:Starting cross validation
2024-07-08 09:32:20,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,856:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:20,857:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,858:INFO:Initializing create_model()
2024-07-08 09:32:20,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,859:INFO:Checking exceptions
2024-07-08 09:32:20,859:INFO:Importing libraries
2024-07-08 09:32:20,859:INFO:Copying training dataset
2024-07-08 09:32:20,878:INFO:Defining folds
2024-07-08 09:32:20,879:INFO:Declaring metric variables
2024-07-08 09:32:20,895:INFO:Importing untrained model
2024-07-08 09:32:20,910:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-08 09:32:20,935:INFO:Starting cross validation
2024-07-08 09:32:20,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:20,945:ERROR:create_model() for qda raised an exception or returned all 0.0:
2024-07-08 09:32:20,947:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:20,947:INFO:Initializing Ada Boost Classifier
2024-07-08 09:32:20,948:INFO:Total runtime is 0.027761157353719076 minutes
2024-07-08 09:32:20,961:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:20,962:INFO:Initializing create_model()
2024-07-08 09:32:20,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:20,963:INFO:Checking exceptions
2024-07-08 09:32:20,963:INFO:Importing libraries
2024-07-08 09:32:20,963:INFO:Copying training dataset
2024-07-08 09:32:20,974:INFO:Defining folds
2024-07-08 09:32:20,974:INFO:Declaring metric variables
2024-07-08 09:32:20,984:INFO:Importing untrained model
2024-07-08 09:32:20,997:INFO:Ada Boost Classifier Imported successfully
2024-07-08 09:32:21,026:INFO:Starting cross validation
2024-07-08 09:32:21,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,035:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,035:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,036:INFO:Initializing create_model()
2024-07-08 09:32:21,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,036:INFO:Checking exceptions
2024-07-08 09:32:21,036:INFO:Importing libraries
2024-07-08 09:32:21,036:INFO:Copying training dataset
2024-07-08 09:32:21,053:INFO:Defining folds
2024-07-08 09:32:21,053:INFO:Declaring metric variables
2024-07-08 09:32:21,065:INFO:Importing untrained model
2024-07-08 09:32:21,078:INFO:Ada Boost Classifier Imported successfully
2024-07-08 09:32:21,102:INFO:Starting cross validation
2024-07-08 09:32:21,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,117:ERROR:create_model() for ada raised an exception or returned all 0.0:
2024-07-08 09:32:21,118:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,118:INFO:Initializing Gradient Boosting Classifier
2024-07-08 09:32:21,119:INFO:Total runtime is 0.0306096355120341 minutes
2024-07-08 09:32:21,129:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,130:INFO:Initializing create_model()
2024-07-08 09:32:21,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,130:INFO:Checking exceptions
2024-07-08 09:32:21,130:INFO:Importing libraries
2024-07-08 09:32:21,131:INFO:Copying training dataset
2024-07-08 09:32:21,141:INFO:Defining folds
2024-07-08 09:32:21,142:INFO:Declaring metric variables
2024-07-08 09:32:21,156:INFO:Importing untrained model
2024-07-08 09:32:21,166:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 09:32:21,186:INFO:Starting cross validation
2024-07-08 09:32:21,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,194:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,195:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,195:INFO:Initializing create_model()
2024-07-08 09:32:21,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,195:INFO:Checking exceptions
2024-07-08 09:32:21,196:INFO:Importing libraries
2024-07-08 09:32:21,196:INFO:Copying training dataset
2024-07-08 09:32:21,204:INFO:Defining folds
2024-07-08 09:32:21,204:INFO:Declaring metric variables
2024-07-08 09:32:21,215:INFO:Importing untrained model
2024-07-08 09:32:21,227:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 09:32:21,248:INFO:Starting cross validation
2024-07-08 09:32:21,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,257:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2024-07-08 09:32:21,258:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,258:INFO:Initializing Linear Discriminant Analysis
2024-07-08 09:32:21,259:INFO:Total runtime is 0.03294519186019897 minutes
2024-07-08 09:32:21,268:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,269:INFO:Initializing create_model()
2024-07-08 09:32:21,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,270:INFO:Checking exceptions
2024-07-08 09:32:21,270:INFO:Importing libraries
2024-07-08 09:32:21,270:INFO:Copying training dataset
2024-07-08 09:32:21,286:INFO:Defining folds
2024-07-08 09:32:21,287:INFO:Declaring metric variables
2024-07-08 09:32:21,300:INFO:Importing untrained model
2024-07-08 09:32:21,312:INFO:Linear Discriminant Analysis Imported successfully
2024-07-08 09:32:21,333:INFO:Starting cross validation
2024-07-08 09:32:21,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,342:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,343:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,343:INFO:Initializing create_model()
2024-07-08 09:32:21,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,344:INFO:Checking exceptions
2024-07-08 09:32:21,344:INFO:Importing libraries
2024-07-08 09:32:21,344:INFO:Copying training dataset
2024-07-08 09:32:21,353:INFO:Defining folds
2024-07-08 09:32:21,353:INFO:Declaring metric variables
2024-07-08 09:32:21,365:INFO:Importing untrained model
2024-07-08 09:32:21,375:INFO:Linear Discriminant Analysis Imported successfully
2024-07-08 09:32:21,397:INFO:Starting cross validation
2024-07-08 09:32:21,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,405:ERROR:create_model() for lda raised an exception or returned all 0.0:
2024-07-08 09:32:21,405:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,406:INFO:Initializing Extra Trees Classifier
2024-07-08 09:32:21,406:INFO:Total runtime is 0.03540400664011637 minutes
2024-07-08 09:32:21,415:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,416:INFO:Initializing create_model()
2024-07-08 09:32:21,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,416:INFO:Checking exceptions
2024-07-08 09:32:21,416:INFO:Importing libraries
2024-07-08 09:32:21,417:INFO:Copying training dataset
2024-07-08 09:32:21,430:INFO:Defining folds
2024-07-08 09:32:21,431:INFO:Declaring metric variables
2024-07-08 09:32:21,443:INFO:Importing untrained model
2024-07-08 09:32:21,455:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:32:21,475:INFO:Starting cross validation
2024-07-08 09:32:21,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,483:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,484:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,484:INFO:Initializing create_model()
2024-07-08 09:32:21,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,484:INFO:Checking exceptions
2024-07-08 09:32:21,485:INFO:Importing libraries
2024-07-08 09:32:21,485:INFO:Copying training dataset
2024-07-08 09:32:21,493:INFO:Defining folds
2024-07-08 09:32:21,494:INFO:Declaring metric variables
2024-07-08 09:32:21,502:INFO:Importing untrained model
2024-07-08 09:32:21,515:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:32:21,535:INFO:Starting cross validation
2024-07-08 09:32:21,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,545:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-07-08 09:32:21,545:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,546:INFO:Initializing Extreme Gradient Boosting
2024-07-08 09:32:21,546:INFO:Total runtime is 0.03774130344390869 minutes
2024-07-08 09:32:21,559:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,561:INFO:Initializing create_model()
2024-07-08 09:32:21,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,561:INFO:Checking exceptions
2024-07-08 09:32:21,561:INFO:Importing libraries
2024-07-08 09:32:21,561:INFO:Copying training dataset
2024-07-08 09:32:21,579:INFO:Defining folds
2024-07-08 09:32:21,579:INFO:Declaring metric variables
2024-07-08 09:32:21,592:INFO:Importing untrained model
2024-07-08 09:32:21,607:INFO:Extreme Gradient Boosting Imported successfully
2024-07-08 09:32:21,634:INFO:Starting cross validation
2024-07-08 09:32:21,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,649:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,650:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,651:INFO:Initializing create_model()
2024-07-08 09:32:21,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,651:INFO:Checking exceptions
2024-07-08 09:32:21,652:INFO:Importing libraries
2024-07-08 09:32:21,652:INFO:Copying training dataset
2024-07-08 09:32:21,668:INFO:Defining folds
2024-07-08 09:32:21,669:INFO:Declaring metric variables
2024-07-08 09:32:21,680:INFO:Importing untrained model
2024-07-08 09:32:21,693:INFO:Extreme Gradient Boosting Imported successfully
2024-07-08 09:32:21,725:INFO:Starting cross validation
2024-07-08 09:32:21,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,736:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2024-07-08 09:32:21,736:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,737:INFO:Initializing Light Gradient Boosting Machine
2024-07-08 09:32:21,737:INFO:Total runtime is 0.04091668128967285 minutes
2024-07-08 09:32:21,755:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,756:INFO:Initializing create_model()
2024-07-08 09:32:21,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,758:INFO:Checking exceptions
2024-07-08 09:32:21,758:INFO:Importing libraries
2024-07-08 09:32:21,759:INFO:Copying training dataset
2024-07-08 09:32:21,772:INFO:Defining folds
2024-07-08 09:32:21,773:INFO:Declaring metric variables
2024-07-08 09:32:21,785:INFO:Importing untrained model
2024-07-08 09:32:21,798:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:32:21,826:INFO:Starting cross validation
2024-07-08 09:32:21,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,836:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:21,836:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,837:INFO:Initializing create_model()
2024-07-08 09:32:21,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,837:INFO:Checking exceptions
2024-07-08 09:32:21,837:INFO:Importing libraries
2024-07-08 09:32:21,837:INFO:Copying training dataset
2024-07-08 09:32:21,848:INFO:Defining folds
2024-07-08 09:32:21,850:INFO:Declaring metric variables
2024-07-08 09:32:21,869:INFO:Importing untrained model
2024-07-08 09:32:21,881:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:32:21,910:INFO:Starting cross validation
2024-07-08 09:32:21,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:21,921:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-07-08 09:32:21,922:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:21,923:INFO:Initializing Dummy Classifier
2024-07-08 09:32:21,923:INFO:Total runtime is 0.044016802310943605 minutes
2024-07-08 09:32:21,937:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:21,937:INFO:Initializing create_model()
2024-07-08 09:32:21,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:21,938:INFO:Checking exceptions
2024-07-08 09:32:21,938:INFO:Importing libraries
2024-07-08 09:32:21,939:INFO:Copying training dataset
2024-07-08 09:32:21,950:INFO:Defining folds
2024-07-08 09:32:21,951:INFO:Declaring metric variables
2024-07-08 09:32:21,961:INFO:Importing untrained model
2024-07-08 09:32:21,975:INFO:Dummy Classifier Imported successfully
2024-07-08 09:32:22,006:INFO:Starting cross validation
2024-07-08 09:32:22,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:22,018:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:22,019:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:22,020:INFO:Initializing create_model()
2024-07-08 09:32:22,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eaba8c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:22,020:INFO:Checking exceptions
2024-07-08 09:32:22,020:INFO:Importing libraries
2024-07-08 09:32:22,020:INFO:Copying training dataset
2024-07-08 09:32:22,038:INFO:Defining folds
2024-07-08 09:32:22,039:INFO:Declaring metric variables
2024-07-08 09:32:22,056:INFO:Importing untrained model
2024-07-08 09:32:22,074:INFO:Dummy Classifier Imported successfully
2024-07-08 09:32:22,108:INFO:Starting cross validation
2024-07-08 09:32:22,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:22,119:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2024-07-08 09:32:22,120:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:22,156:INFO:_master_model_container: 0
2024-07-08 09:32:22,156:INFO:_display_container: 2
2024-07-08 09:32:22,157:INFO:[]
2024-07-08 09:32:22,157:INFO:compare_models() successfully completed......................................
2024-07-08 09:32:22,181:INFO:Initializing create_model()
2024-07-08 09:32:22,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:22,181:INFO:Checking exceptions
2024-07-08 09:32:22,244:INFO:Importing libraries
2024-07-08 09:32:22,245:INFO:Copying training dataset
2024-07-08 09:32:22,265:INFO:Defining folds
2024-07-08 09:32:22,266:INFO:Declaring metric variables
2024-07-08 09:32:22,282:INFO:Importing untrained model
2024-07-08 09:32:22,295:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:32:22,324:INFO:Starting cross validation
2024-07-08 09:32:22,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:30,919:INFO:Initializing compare_models()
2024-07-08 09:32:30,920:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-08 09:32:30,921:INFO:Checking exceptions
2024-07-08 09:32:30,927:INFO:Preparing display monitor
2024-07-08 09:32:31,004:INFO:Initializing Logistic Regression
2024-07-08 09:32:31,006:INFO:Total runtime is 2.9834111531575522e-05 minutes
2024-07-08 09:32:31,016:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,016:INFO:Initializing create_model()
2024-07-08 09:32:31,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,017:INFO:Checking exceptions
2024-07-08 09:32:31,017:INFO:Importing libraries
2024-07-08 09:32:31,017:INFO:Copying training dataset
2024-07-08 09:32:31,027:INFO:Defining folds
2024-07-08 09:32:31,027:INFO:Declaring metric variables
2024-07-08 09:32:31,036:INFO:Importing untrained model
2024-07-08 09:32:31,047:INFO:Logistic Regression Imported successfully
2024-07-08 09:32:31,068:INFO:Starting cross validation
2024-07-08 09:32:31,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,079:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,080:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,081:INFO:Initializing create_model()
2024-07-08 09:32:31,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,081:INFO:Checking exceptions
2024-07-08 09:32:31,082:INFO:Importing libraries
2024-07-08 09:32:31,082:INFO:Copying training dataset
2024-07-08 09:32:31,090:INFO:Defining folds
2024-07-08 09:32:31,091:INFO:Declaring metric variables
2024-07-08 09:32:31,100:INFO:Importing untrained model
2024-07-08 09:32:31,110:INFO:Logistic Regression Imported successfully
2024-07-08 09:32:31,131:INFO:Starting cross validation
2024-07-08 09:32:31,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,142:ERROR:create_model() for lr raised an exception or returned all 0.0:
2024-07-08 09:32:31,143:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,143:INFO:Initializing K Neighbors Classifier
2024-07-08 09:32:31,143:INFO:Total runtime is 0.0023188153902689614 minutes
2024-07-08 09:32:31,155:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,157:INFO:Initializing create_model()
2024-07-08 09:32:31,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,160:INFO:Checking exceptions
2024-07-08 09:32:31,160:INFO:Importing libraries
2024-07-08 09:32:31,161:INFO:Copying training dataset
2024-07-08 09:32:31,175:INFO:Defining folds
2024-07-08 09:32:31,175:INFO:Declaring metric variables
2024-07-08 09:32:31,185:INFO:Importing untrained model
2024-07-08 09:32:31,195:INFO:K Neighbors Classifier Imported successfully
2024-07-08 09:32:31,215:INFO:Starting cross validation
2024-07-08 09:32:31,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,226:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,226:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,227:INFO:Initializing create_model()
2024-07-08 09:32:31,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,227:INFO:Checking exceptions
2024-07-08 09:32:31,227:INFO:Importing libraries
2024-07-08 09:32:31,228:INFO:Copying training dataset
2024-07-08 09:32:31,236:INFO:Defining folds
2024-07-08 09:32:31,236:INFO:Declaring metric variables
2024-07-08 09:32:31,244:INFO:Importing untrained model
2024-07-08 09:32:31,255:INFO:K Neighbors Classifier Imported successfully
2024-07-08 09:32:31,277:INFO:Starting cross validation
2024-07-08 09:32:31,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,287:ERROR:create_model() for knn raised an exception or returned all 0.0:
2024-07-08 09:32:31,288:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,289:INFO:Initializing Naive Bayes
2024-07-08 09:32:31,289:INFO:Total runtime is 0.004750263690948486 minutes
2024-07-08 09:32:31,298:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,299:INFO:Initializing create_model()
2024-07-08 09:32:31,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,300:INFO:Checking exceptions
2024-07-08 09:32:31,300:INFO:Importing libraries
2024-07-08 09:32:31,300:INFO:Copying training dataset
2024-07-08 09:32:31,312:INFO:Defining folds
2024-07-08 09:32:31,312:INFO:Declaring metric variables
2024-07-08 09:32:31,325:INFO:Importing untrained model
2024-07-08 09:32:31,335:INFO:Naive Bayes Imported successfully
2024-07-08 09:32:31,355:INFO:Starting cross validation
2024-07-08 09:32:31,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,364:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,364:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,365:INFO:Initializing create_model()
2024-07-08 09:32:31,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,365:INFO:Checking exceptions
2024-07-08 09:32:31,365:INFO:Importing libraries
2024-07-08 09:32:31,365:INFO:Copying training dataset
2024-07-08 09:32:31,378:INFO:Defining folds
2024-07-08 09:32:31,378:INFO:Declaring metric variables
2024-07-08 09:32:31,389:INFO:Importing untrained model
2024-07-08 09:32:31,399:INFO:Naive Bayes Imported successfully
2024-07-08 09:32:31,419:INFO:Starting cross validation
2024-07-08 09:32:31,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,428:ERROR:create_model() for nb raised an exception or returned all 0.0:
2024-07-08 09:32:31,429:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,429:INFO:Initializing Decision Tree Classifier
2024-07-08 09:32:31,429:INFO:Total runtime is 0.007084802786509196 minutes
2024-07-08 09:32:31,438:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,438:INFO:Initializing create_model()
2024-07-08 09:32:31,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,439:INFO:Checking exceptions
2024-07-08 09:32:31,439:INFO:Importing libraries
2024-07-08 09:32:31,439:INFO:Copying training dataset
2024-07-08 09:32:31,451:INFO:Defining folds
2024-07-08 09:32:31,452:INFO:Declaring metric variables
2024-07-08 09:32:31,460:INFO:Importing untrained model
2024-07-08 09:32:31,472:INFO:Decision Tree Classifier Imported successfully
2024-07-08 09:32:31,495:INFO:Starting cross validation
2024-07-08 09:32:31,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,504:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,504:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,505:INFO:Initializing create_model()
2024-07-08 09:32:31,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,505:INFO:Checking exceptions
2024-07-08 09:32:31,505:INFO:Importing libraries
2024-07-08 09:32:31,506:INFO:Copying training dataset
2024-07-08 09:32:31,515:INFO:Defining folds
2024-07-08 09:32:31,515:INFO:Declaring metric variables
2024-07-08 09:32:31,528:INFO:Importing untrained model
2024-07-08 09:32:31,540:INFO:Decision Tree Classifier Imported successfully
2024-07-08 09:32:31,562:INFO:Starting cross validation
2024-07-08 09:32:31,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,571:ERROR:create_model() for dt raised an exception or returned all 0.0:
2024-07-08 09:32:31,572:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,572:INFO:Initializing SVM - Linear Kernel
2024-07-08 09:32:31,573:INFO:Total runtime is 0.009474384784698486 minutes
2024-07-08 09:32:31,585:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,586:INFO:Initializing create_model()
2024-07-08 09:32:31,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,587:INFO:Checking exceptions
2024-07-08 09:32:31,587:INFO:Importing libraries
2024-07-08 09:32:31,587:INFO:Copying training dataset
2024-07-08 09:32:31,614:INFO:Defining folds
2024-07-08 09:32:31,615:INFO:Declaring metric variables
2024-07-08 09:32:31,632:INFO:Importing untrained model
2024-07-08 09:32:31,644:INFO:SVM - Linear Kernel Imported successfully
2024-07-08 09:32:31,671:INFO:Starting cross validation
2024-07-08 09:32:31,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,680:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,681:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,681:INFO:Initializing create_model()
2024-07-08 09:32:31,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,681:INFO:Checking exceptions
2024-07-08 09:32:31,682:INFO:Importing libraries
2024-07-08 09:32:31,682:INFO:Copying training dataset
2024-07-08 09:32:31,693:INFO:Defining folds
2024-07-08 09:32:31,694:INFO:Declaring metric variables
2024-07-08 09:32:31,704:INFO:Importing untrained model
2024-07-08 09:32:31,717:INFO:SVM - Linear Kernel Imported successfully
2024-07-08 09:32:31,742:INFO:Starting cross validation
2024-07-08 09:32:31,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,752:ERROR:create_model() for svm raised an exception or returned all 0.0:
2024-07-08 09:32:31,753:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,754:INFO:Initializing Ridge Classifier
2024-07-08 09:32:31,754:INFO:Total runtime is 0.012499864896138508 minutes
2024-07-08 09:32:31,770:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,771:INFO:Initializing create_model()
2024-07-08 09:32:31,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,771:INFO:Checking exceptions
2024-07-08 09:32:31,771:INFO:Importing libraries
2024-07-08 09:32:31,772:INFO:Copying training dataset
2024-07-08 09:32:31,784:INFO:Defining folds
2024-07-08 09:32:31,785:INFO:Declaring metric variables
2024-07-08 09:32:31,797:INFO:Importing untrained model
2024-07-08 09:32:31,810:INFO:Ridge Classifier Imported successfully
2024-07-08 09:32:31,836:INFO:Starting cross validation
2024-07-08 09:32:31,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,846:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:31,847:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,848:INFO:Initializing create_model()
2024-07-08 09:32:31,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,848:INFO:Checking exceptions
2024-07-08 09:32:31,848:INFO:Importing libraries
2024-07-08 09:32:31,848:INFO:Copying training dataset
2024-07-08 09:32:31,860:INFO:Defining folds
2024-07-08 09:32:31,860:INFO:Declaring metric variables
2024-07-08 09:32:31,875:INFO:Importing untrained model
2024-07-08 09:32:31,888:INFO:Ridge Classifier Imported successfully
2024-07-08 09:32:31,918:INFO:Starting cross validation
2024-07-08 09:32:31,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:31,928:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2024-07-08 09:32:31,929:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:31,929:INFO:Initializing Random Forest Classifier
2024-07-08 09:32:31,929:INFO:Total runtime is 0.015417361259460449 minutes
2024-07-08 09:32:31,942:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:31,943:INFO:Initializing create_model()
2024-07-08 09:32:31,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:31,943:INFO:Checking exceptions
2024-07-08 09:32:31,943:INFO:Importing libraries
2024-07-08 09:32:31,943:INFO:Copying training dataset
2024-07-08 09:32:31,957:INFO:Defining folds
2024-07-08 09:32:31,957:INFO:Declaring metric variables
2024-07-08 09:32:31,971:INFO:Importing untrained model
2024-07-08 09:32:31,985:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:32:32,009:INFO:Starting cross validation
2024-07-08 09:32:32,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,018:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,019:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,019:INFO:Initializing create_model()
2024-07-08 09:32:32,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,020:INFO:Checking exceptions
2024-07-08 09:32:32,020:INFO:Importing libraries
2024-07-08 09:32:32,020:INFO:Copying training dataset
2024-07-08 09:32:32,033:INFO:Defining folds
2024-07-08 09:32:32,034:INFO:Declaring metric variables
2024-07-08 09:32:32,045:INFO:Importing untrained model
2024-07-08 09:32:32,058:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:32:32,092:INFO:Starting cross validation
2024-07-08 09:32:32,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,101:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-07-08 09:32:32,103:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,106:INFO:Initializing Quadratic Discriminant Analysis
2024-07-08 09:32:32,107:INFO:Total runtime is 0.018386566638946535 minutes
2024-07-08 09:32:32,119:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,120:INFO:Initializing create_model()
2024-07-08 09:32:32,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,120:INFO:Checking exceptions
2024-07-08 09:32:32,120:INFO:Importing libraries
2024-07-08 09:32:32,120:INFO:Copying training dataset
2024-07-08 09:32:32,134:INFO:Defining folds
2024-07-08 09:32:32,134:INFO:Declaring metric variables
2024-07-08 09:32:32,145:INFO:Importing untrained model
2024-07-08 09:32:32,158:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-08 09:32:32,183:INFO:Starting cross validation
2024-07-08 09:32:32,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,196:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,197:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,198:INFO:Initializing create_model()
2024-07-08 09:32:32,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,198:INFO:Checking exceptions
2024-07-08 09:32:32,198:INFO:Importing libraries
2024-07-08 09:32:32,199:INFO:Copying training dataset
2024-07-08 09:32:32,218:INFO:Defining folds
2024-07-08 09:32:32,219:INFO:Declaring metric variables
2024-07-08 09:32:32,235:INFO:Importing untrained model
2024-07-08 09:32:32,247:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-08 09:32:32,275:INFO:Starting cross validation
2024-07-08 09:32:32,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,285:ERROR:create_model() for qda raised an exception or returned all 0.0:
2024-07-08 09:32:32,286:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,286:INFO:Initializing Ada Boost Classifier
2024-07-08 09:32:32,287:INFO:Total runtime is 0.021375747521718343 minutes
2024-07-08 09:32:32,301:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,301:INFO:Initializing create_model()
2024-07-08 09:32:32,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,303:INFO:Checking exceptions
2024-07-08 09:32:32,303:INFO:Importing libraries
2024-07-08 09:32:32,303:INFO:Copying training dataset
2024-07-08 09:32:32,314:INFO:Defining folds
2024-07-08 09:32:32,314:INFO:Declaring metric variables
2024-07-08 09:32:32,325:INFO:Importing untrained model
2024-07-08 09:32:32,337:INFO:Ada Boost Classifier Imported successfully
2024-07-08 09:32:32,360:INFO:Starting cross validation
2024-07-08 09:32:32,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,369:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,369:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,370:INFO:Initializing create_model()
2024-07-08 09:32:32,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,370:INFO:Checking exceptions
2024-07-08 09:32:32,370:INFO:Importing libraries
2024-07-08 09:32:32,370:INFO:Copying training dataset
2024-07-08 09:32:32,379:INFO:Defining folds
2024-07-08 09:32:32,379:INFO:Declaring metric variables
2024-07-08 09:32:32,391:INFO:Importing untrained model
2024-07-08 09:32:32,401:INFO:Ada Boost Classifier Imported successfully
2024-07-08 09:32:32,420:INFO:Starting cross validation
2024-07-08 09:32:32,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,428:ERROR:create_model() for ada raised an exception or returned all 0.0:
2024-07-08 09:32:32,428:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,429:INFO:Initializing Gradient Boosting Classifier
2024-07-08 09:32:32,429:INFO:Total runtime is 0.02374873161315918 minutes
2024-07-08 09:32:32,438:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,438:INFO:Initializing create_model()
2024-07-08 09:32:32,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,440:INFO:Checking exceptions
2024-07-08 09:32:32,440:INFO:Importing libraries
2024-07-08 09:32:32,440:INFO:Copying training dataset
2024-07-08 09:32:32,449:INFO:Defining folds
2024-07-08 09:32:32,451:INFO:Declaring metric variables
2024-07-08 09:32:32,467:INFO:Importing untrained model
2024-07-08 09:32:32,478:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 09:32:32,500:INFO:Starting cross validation
2024-07-08 09:32:32,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,508:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,509:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,509:INFO:Initializing create_model()
2024-07-08 09:32:32,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,509:INFO:Checking exceptions
2024-07-08 09:32:32,509:INFO:Importing libraries
2024-07-08 09:32:32,509:INFO:Copying training dataset
2024-07-08 09:32:32,518:INFO:Defining folds
2024-07-08 09:32:32,518:INFO:Declaring metric variables
2024-07-08 09:32:32,531:INFO:Importing untrained model
2024-07-08 09:32:32,544:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 09:32:32,565:INFO:Starting cross validation
2024-07-08 09:32:32,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,579:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2024-07-08 09:32:32,582:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,582:INFO:Initializing Linear Discriminant Analysis
2024-07-08 09:32:32,583:INFO:Total runtime is 0.026306978861490884 minutes
2024-07-08 09:32:32,591:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,592:INFO:Initializing create_model()
2024-07-08 09:32:32,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,593:INFO:Checking exceptions
2024-07-08 09:32:32,593:INFO:Importing libraries
2024-07-08 09:32:32,593:INFO:Copying training dataset
2024-07-08 09:32:32,614:INFO:Defining folds
2024-07-08 09:32:32,617:INFO:Declaring metric variables
2024-07-08 09:32:32,634:INFO:Importing untrained model
2024-07-08 09:32:32,651:INFO:Linear Discriminant Analysis Imported successfully
2024-07-08 09:32:32,677:INFO:Starting cross validation
2024-07-08 09:32:32,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,686:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,687:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,687:INFO:Initializing create_model()
2024-07-08 09:32:32,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,688:INFO:Checking exceptions
2024-07-08 09:32:32,688:INFO:Importing libraries
2024-07-08 09:32:32,688:INFO:Copying training dataset
2024-07-08 09:32:32,698:INFO:Defining folds
2024-07-08 09:32:32,699:INFO:Declaring metric variables
2024-07-08 09:32:32,713:INFO:Importing untrained model
2024-07-08 09:32:32,725:INFO:Linear Discriminant Analysis Imported successfully
2024-07-08 09:32:32,757:INFO:Starting cross validation
2024-07-08 09:32:32,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,768:ERROR:create_model() for lda raised an exception or returned all 0.0:
2024-07-08 09:32:32,768:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,769:INFO:Initializing Extra Trees Classifier
2024-07-08 09:32:32,769:INFO:Total runtime is 0.02941497961680094 minutes
2024-07-08 09:32:32,785:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,786:INFO:Initializing create_model()
2024-07-08 09:32:32,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,786:INFO:Checking exceptions
2024-07-08 09:32:32,786:INFO:Importing libraries
2024-07-08 09:32:32,787:INFO:Copying training dataset
2024-07-08 09:32:32,800:INFO:Defining folds
2024-07-08 09:32:32,801:INFO:Declaring metric variables
2024-07-08 09:32:32,811:INFO:Importing untrained model
2024-07-08 09:32:32,824:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:32:32,850:INFO:Starting cross validation
2024-07-08 09:32:32,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,863:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:32,864:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,865:INFO:Initializing create_model()
2024-07-08 09:32:32,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,865:INFO:Checking exceptions
2024-07-08 09:32:32,865:INFO:Importing libraries
2024-07-08 09:32:32,866:INFO:Copying training dataset
2024-07-08 09:32:32,883:INFO:Defining folds
2024-07-08 09:32:32,885:INFO:Declaring metric variables
2024-07-08 09:32:32,900:INFO:Importing untrained model
2024-07-08 09:32:32,914:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:32:32,936:INFO:Starting cross validation
2024-07-08 09:32:32,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:32,943:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-07-08 09:32:32,944:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:32,944:INFO:Initializing Extreme Gradient Boosting
2024-07-08 09:32:32,944:INFO:Total runtime is 0.03233679135640462 minutes
2024-07-08 09:32:32,952:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:32,953:INFO:Initializing create_model()
2024-07-08 09:32:32,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:32,953:INFO:Checking exceptions
2024-07-08 09:32:32,954:INFO:Importing libraries
2024-07-08 09:32:32,954:INFO:Copying training dataset
2024-07-08 09:32:32,965:INFO:Defining folds
2024-07-08 09:32:32,966:INFO:Declaring metric variables
2024-07-08 09:32:32,974:INFO:Importing untrained model
2024-07-08 09:32:32,986:INFO:Extreme Gradient Boosting Imported successfully
2024-07-08 09:32:33,008:INFO:Starting cross validation
2024-07-08 09:32:33,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,016:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:33,016:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,017:INFO:Initializing create_model()
2024-07-08 09:32:33,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:33,017:INFO:Checking exceptions
2024-07-08 09:32:33,017:INFO:Importing libraries
2024-07-08 09:32:33,017:INFO:Copying training dataset
2024-07-08 09:32:33,025:INFO:Defining folds
2024-07-08 09:32:33,025:INFO:Declaring metric variables
2024-07-08 09:32:33,039:INFO:Importing untrained model
2024-07-08 09:32:33,050:INFO:Extreme Gradient Boosting Imported successfully
2024-07-08 09:32:33,071:INFO:Starting cross validation
2024-07-08 09:32:33,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,079:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2024-07-08 09:32:33,080:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,080:INFO:Initializing Light Gradient Boosting Machine
2024-07-08 09:32:33,080:INFO:Total runtime is 0.03459993600845337 minutes
2024-07-08 09:32:33,089:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:33,090:INFO:Initializing create_model()
2024-07-08 09:32:33,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:33,090:INFO:Checking exceptions
2024-07-08 09:32:33,090:INFO:Importing libraries
2024-07-08 09:32:33,091:INFO:Copying training dataset
2024-07-08 09:32:33,103:INFO:Defining folds
2024-07-08 09:32:33,104:INFO:Declaring metric variables
2024-07-08 09:32:33,118:INFO:Importing untrained model
2024-07-08 09:32:33,128:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:32:33,153:INFO:Starting cross validation
2024-07-08 09:32:33,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,160:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:33,161:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,161:INFO:Initializing create_model()
2024-07-08 09:32:33,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:33,161:INFO:Checking exceptions
2024-07-08 09:32:33,161:INFO:Importing libraries
2024-07-08 09:32:33,162:INFO:Copying training dataset
2024-07-08 09:32:33,170:INFO:Defining folds
2024-07-08 09:32:33,170:INFO:Declaring metric variables
2024-07-08 09:32:33,181:INFO:Importing untrained model
2024-07-08 09:32:33,190:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:32:33,215:INFO:Starting cross validation
2024-07-08 09:32:33,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,227:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-07-08 09:32:33,227:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,228:INFO:Initializing Dummy Classifier
2024-07-08 09:32:33,228:INFO:Total runtime is 0.037068597475687665 minutes
2024-07-08 09:32:33,241:INFO:SubProcess create_model() called ==================================
2024-07-08 09:32:33,242:INFO:Initializing create_model()
2024-07-08 09:32:33,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:33,242:INFO:Checking exceptions
2024-07-08 09:32:33,243:INFO:Importing libraries
2024-07-08 09:32:33,243:INFO:Copying training dataset
2024-07-08 09:32:33,253:INFO:Defining folds
2024-07-08 09:32:33,253:INFO:Declaring metric variables
2024-07-08 09:32:33,266:INFO:Importing untrained model
2024-07-08 09:32:33,277:INFO:Dummy Classifier Imported successfully
2024-07-08 09:32:33,298:INFO:Starting cross validation
2024-07-08 09:32:33,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,307:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2024-07-08 09:32:33,307:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,308:INFO:Initializing create_model()
2024-07-08 09:32:33,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a9ab7c790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9ab7df30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:32:33,308:INFO:Checking exceptions
2024-07-08 09:32:33,308:INFO:Importing libraries
2024-07-08 09:32:33,309:INFO:Copying training dataset
2024-07-08 09:32:33,318:INFO:Defining folds
2024-07-08 09:32:33,319:INFO:Declaring metric variables
2024-07-08 09:32:33,327:INFO:Importing untrained model
2024-07-08 09:32:33,343:INFO:Dummy Classifier Imported successfully
2024-07-08 09:32:33,366:INFO:Starting cross validation
2024-07-08 09:32:33,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:32:33,375:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2024-07-08 09:32:33,376:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "/usr/lib/python3.10/queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1950, in __call__
    next(output)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.10/dist-packages/joblib/parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py", line 430, in <genexpr>
    results = parallel(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py", line 370, in split
    raise ValueError(
ValueError: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.

2024-07-08 09:32:33,404:INFO:_master_model_container: 0
2024-07-08 09:32:33,405:INFO:_display_container: 3
2024-07-08 09:32:33,405:INFO:[]
2024-07-08 09:32:33,405:INFO:compare_models() successfully completed......................................
2024-07-08 09:54:28,605:INFO:PyCaret ClassificationExperiment
2024-07-08 09:54:28,608:INFO:Logging name: clf-default-name
2024-07-08 09:54:28,609:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:54:28,610:INFO:version 3.3.2
2024-07-08 09:54:28,610:INFO:Initializing setup()
2024-07-08 09:54:28,611:INFO:self.USI: 6900
2024-07-08 09:54:28,611:INFO:self._variable_keys: {'y', 'logging_param', 'memory', 'seed', 'pipeline', '_available_plots', 'target_param', 'fold_groups_param', 'gpu_param', 'html_param', 'idx', 'fold_shuffle_param', 'y_train', 'USI', 'exp_name_log', 'data', '_ml_usecase', 'X_test', 'fix_imbalance', 'is_multiclass', 'X_train', 'log_plots_param', 'X', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_id', 'y_test', 'fold_generator'}
2024-07-08 09:54:28,611:INFO:Checking environment
2024-07-08 09:54:28,612:INFO:python_version: 3.10.12
2024-07-08 09:54:28,612:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-08 09:54:28,612:INFO:machine: x86_64
2024-07-08 09:54:28,613:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:54:28,613:INFO:Memory: svmem(total=13609431040, available=11955613696, percent=12.2, used=1317658624, free=8414756864, active=904904704, inactive=3919663104, buffers=424140800, cached=3452874752, shared=2932736, slab=278347776)
2024-07-08 09:54:28,614:INFO:Physical Core: 1
2024-07-08 09:54:28,614:INFO:Logical Core: 2
2024-07-08 09:54:28,614:INFO:Checking libraries
2024-07-08 09:54:28,615:INFO:System:
2024-07-08 09:54:28,615:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-08 09:54:28,615:INFO:executable: /usr/bin/python3
2024-07-08 09:54:28,615:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:54:28,615:INFO:PyCaret required dependencies:
2024-07-08 09:54:28,616:INFO:                 pip: 23.1.2
2024-07-08 09:54:28,616:INFO:          setuptools: 67.7.2
2024-07-08 09:54:28,616:INFO:             pycaret: 3.3.2
2024-07-08 09:54:28,616:INFO:             IPython: 7.34.0
2024-07-08 09:54:28,617:INFO:          ipywidgets: 7.7.1
2024-07-08 09:54:28,617:INFO:                tqdm: 4.66.4
2024-07-08 09:54:28,617:INFO:               numpy: 1.25.2
2024-07-08 09:54:28,617:INFO:              pandas: 2.0.3
2024-07-08 09:54:28,617:INFO:              jinja2: 3.1.4
2024-07-08 09:54:28,617:INFO:               scipy: 1.11.4
2024-07-08 09:54:28,618:INFO:              joblib: 1.3.2
2024-07-08 09:54:28,618:INFO:             sklearn: 1.4.2
2024-07-08 09:54:28,618:INFO:                pyod: 2.0.1
2024-07-08 09:54:28,618:INFO:            imblearn: 0.12.3
2024-07-08 09:54:28,619:INFO:   category_encoders: 2.6.3
2024-07-08 09:54:28,619:INFO:            lightgbm: 4.1.0
2024-07-08 09:54:28,619:INFO:               numba: 0.58.1
2024-07-08 09:54:28,619:INFO:            requests: 2.31.0
2024-07-08 09:54:28,619:INFO:          matplotlib: 3.7.1
2024-07-08 09:54:28,619:INFO:          scikitplot: 0.3.7
2024-07-08 09:54:28,620:INFO:         yellowbrick: 1.5
2024-07-08 09:54:28,620:INFO:              plotly: 5.15.0
2024-07-08 09:54:28,620:INFO:    plotly-resampler: Not installed
2024-07-08 09:54:28,620:INFO:             kaleido: 0.2.1
2024-07-08 09:54:28,620:INFO:           schemdraw: 0.15
2024-07-08 09:54:28,621:INFO:         statsmodels: 0.14.2
2024-07-08 09:54:28,621:INFO:              sktime: 0.26.0
2024-07-08 09:54:28,621:INFO:               tbats: 1.1.3
2024-07-08 09:54:28,621:INFO:            pmdarima: 2.0.4
2024-07-08 09:54:28,621:INFO:              psutil: 5.9.5
2024-07-08 09:54:28,622:INFO:          markupsafe: 2.1.5
2024-07-08 09:54:28,622:INFO:             pickle5: Not installed
2024-07-08 09:54:28,622:INFO:         cloudpickle: 2.2.1
2024-07-08 09:54:28,622:INFO:         deprecation: 2.1.0
2024-07-08 09:54:28,623:INFO:              xxhash: 3.4.1
2024-07-08 09:54:28,623:INFO:           wurlitzer: 3.1.1
2024-07-08 09:54:28,623:INFO:PyCaret optional dependencies:
2024-07-08 09:54:28,624:INFO:                shap: Not installed
2024-07-08 09:54:28,624:INFO:           interpret: Not installed
2024-07-08 09:54:28,624:INFO:                umap: Not installed
2024-07-08 09:54:28,624:INFO:     ydata_profiling: Not installed
2024-07-08 09:54:28,624:INFO:  explainerdashboard: Not installed
2024-07-08 09:54:28,624:INFO:             autoviz: Not installed
2024-07-08 09:54:28,625:INFO:           fairlearn: Not installed
2024-07-08 09:54:28,625:INFO:          deepchecks: Not installed
2024-07-08 09:54:28,625:INFO:             xgboost: 2.0.3
2024-07-08 09:54:28,625:INFO:            catboost: Not installed
2024-07-08 09:54:28,625:INFO:              kmodes: Not installed
2024-07-08 09:54:28,626:INFO:             mlxtend: 0.22.0
2024-07-08 09:54:28,626:INFO:       statsforecast: Not installed
2024-07-08 09:54:28,626:INFO:        tune_sklearn: Not installed
2024-07-08 09:54:28,626:INFO:                 ray: Not installed
2024-07-08 09:54:28,626:INFO:            hyperopt: 0.2.7
2024-07-08 09:54:28,626:INFO:              optuna: Not installed
2024-07-08 09:54:28,626:INFO:               skopt: Not installed
2024-07-08 09:54:28,627:INFO:              mlflow: Not installed
2024-07-08 09:54:28,627:INFO:              gradio: Not installed
2024-07-08 09:54:28,627:INFO:             fastapi: Not installed
2024-07-08 09:54:28,627:INFO:             uvicorn: Not installed
2024-07-08 09:54:28,627:INFO:              m2cgen: Not installed
2024-07-08 09:54:28,627:INFO:           evidently: Not installed
2024-07-08 09:54:28,628:INFO:               fugue: Not installed
2024-07-08 09:54:28,628:INFO:           streamlit: Not installed
2024-07-08 09:54:28,628:INFO:             prophet: 1.1.5
2024-07-08 09:54:28,628:INFO:None
2024-07-08 09:54:28,628:INFO:Set up data.
2024-07-08 09:54:28,644:INFO:Set up folding strategy.
2024-07-08 09:54:28,644:INFO:Set up train/test split.
2024-07-08 09:54:28,653:INFO:Set up index.
2024-07-08 09:54:28,653:INFO:Assigning column types.
2024-07-08 09:54:28,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 09:54:28,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:54:28,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:54:28,752:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:28,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:28,810:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:54:28,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:54:28,847:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:28,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:28,851:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 09:54:28,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:54:28,951:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:28,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:54:29,053:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:29,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,057:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-08 09:54:29,145:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:29,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,236:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:29,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,241:INFO:Preparing preprocessing pipeline...
2024-07-08 09:54:29,243:INFO:Set up simple imputation.
2024-07-08 09:54:29,274:INFO:Finished creating preprocessing pipeline.
2024-07-08 09:54:29,278:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Solyc01g105660', 'Solyc02g061770',
                                             'Solyc02g062040', 'Solyc02g084850',
                                             'Solyc03g098100', 'Solyc03g098240',
                                             'Solyc03g121880', 'Solyc04g005250',
                                             'Solyc04g009860', 'Solyc04g071780',
                                             'Solyc04g081900', 'Solyc06g050130',
                                             'Solyc06g066600', 'Solyc06g06...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-08 09:54:29,279:INFO:Creating final display dataframe.
2024-07-08 09:54:29,449:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         condition
2                   Target type            Binary
3           Original data shape          (36, 27)
4        Transformed data shape          (36, 27)
5   Transformed train set shape          (28, 27)
6    Transformed test set shape           (8, 27)
7              Numeric features                26
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6900
2024-07-08 09:54:29,580:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:29,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,681:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:54:29,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:54:29,687:INFO:setup() successfully completed in 1.09s...............
2024-07-08 09:55:01,783:INFO:PyCaret ClassificationExperiment
2024-07-08 09:55:01,784:INFO:Logging name: clf-default-name
2024-07-08 09:55:01,785:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-08 09:55:01,785:INFO:version 3.3.2
2024-07-08 09:55:01,785:INFO:Initializing setup()
2024-07-08 09:55:01,785:INFO:self.USI: 866e
2024-07-08 09:55:01,785:INFO:self._variable_keys: {'y', 'logging_param', 'memory', 'seed', 'pipeline', '_available_plots', 'target_param', 'fold_groups_param', 'gpu_param', 'html_param', 'idx', 'fold_shuffle_param', 'y_train', 'USI', 'exp_name_log', 'data', '_ml_usecase', 'X_test', 'fix_imbalance', 'is_multiclass', 'X_train', 'log_plots_param', 'X', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_id', 'y_test', 'fold_generator'}
2024-07-08 09:55:01,785:INFO:Checking environment
2024-07-08 09:55:01,785:INFO:python_version: 3.10.12
2024-07-08 09:55:01,786:INFO:python_build: ('main', 'Nov 20 2023 15:14:05')
2024-07-08 09:55:01,786:INFO:machine: x86_64
2024-07-08 09:55:01,786:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:55:01,787:INFO:Memory: svmem(total=13609431040, available=12209377280, percent=10.3, used=1063809024, free=8665952256, active=912936960, inactive=3666481152, buffers=424579072, cached=3455090688, shared=3010560, slab=278106112)
2024-07-08 09:55:01,789:INFO:Physical Core: 1
2024-07-08 09:55:01,790:INFO:Logical Core: 2
2024-07-08 09:55:01,790:INFO:Checking libraries
2024-07-08 09:55:01,790:INFO:System:
2024-07-08 09:55:01,790:INFO:    python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]
2024-07-08 09:55:01,790:INFO:executable: /usr/bin/python3
2024-07-08 09:55:01,790:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-07-08 09:55:01,792:INFO:PyCaret required dependencies:
2024-07-08 09:55:01,792:INFO:                 pip: 23.1.2
2024-07-08 09:55:01,792:INFO:          setuptools: 67.7.2
2024-07-08 09:55:01,793:INFO:             pycaret: 3.3.2
2024-07-08 09:55:01,793:INFO:             IPython: 7.34.0
2024-07-08 09:55:01,793:INFO:          ipywidgets: 7.7.1
2024-07-08 09:55:01,793:INFO:                tqdm: 4.66.4
2024-07-08 09:55:01,793:INFO:               numpy: 1.25.2
2024-07-08 09:55:01,793:INFO:              pandas: 2.0.3
2024-07-08 09:55:01,793:INFO:              jinja2: 3.1.4
2024-07-08 09:55:01,793:INFO:               scipy: 1.11.4
2024-07-08 09:55:01,794:INFO:              joblib: 1.3.2
2024-07-08 09:55:01,794:INFO:             sklearn: 1.4.2
2024-07-08 09:55:01,794:INFO:                pyod: 2.0.1
2024-07-08 09:55:01,794:INFO:            imblearn: 0.12.3
2024-07-08 09:55:01,799:INFO:   category_encoders: 2.6.3
2024-07-08 09:55:01,799:INFO:            lightgbm: 4.1.0
2024-07-08 09:55:01,799:INFO:               numba: 0.58.1
2024-07-08 09:55:01,799:INFO:            requests: 2.31.0
2024-07-08 09:55:01,800:INFO:          matplotlib: 3.7.1
2024-07-08 09:55:01,800:INFO:          scikitplot: 0.3.7
2024-07-08 09:55:01,800:INFO:         yellowbrick: 1.5
2024-07-08 09:55:01,800:INFO:              plotly: 5.15.0
2024-07-08 09:55:01,809:INFO:    plotly-resampler: Not installed
2024-07-08 09:55:01,809:INFO:             kaleido: 0.2.1
2024-07-08 09:55:01,809:INFO:           schemdraw: 0.15
2024-07-08 09:55:01,809:INFO:         statsmodels: 0.14.2
2024-07-08 09:55:01,809:INFO:              sktime: 0.26.0
2024-07-08 09:55:01,809:INFO:               tbats: 1.1.3
2024-07-08 09:55:01,810:INFO:            pmdarima: 2.0.4
2024-07-08 09:55:01,810:INFO:              psutil: 5.9.5
2024-07-08 09:55:01,810:INFO:          markupsafe: 2.1.5
2024-07-08 09:55:01,810:INFO:             pickle5: Not installed
2024-07-08 09:55:01,810:INFO:         cloudpickle: 2.2.1
2024-07-08 09:55:01,810:INFO:         deprecation: 2.1.0
2024-07-08 09:55:01,810:INFO:              xxhash: 3.4.1
2024-07-08 09:55:01,810:INFO:           wurlitzer: 3.1.1
2024-07-08 09:55:01,810:INFO:PyCaret optional dependencies:
2024-07-08 09:55:01,811:INFO:                shap: Not installed
2024-07-08 09:55:01,811:INFO:           interpret: Not installed
2024-07-08 09:55:01,813:INFO:                umap: Not installed
2024-07-08 09:55:01,813:INFO:     ydata_profiling: Not installed
2024-07-08 09:55:01,817:INFO:  explainerdashboard: Not installed
2024-07-08 09:55:01,817:INFO:             autoviz: Not installed
2024-07-08 09:55:01,817:INFO:           fairlearn: Not installed
2024-07-08 09:55:01,818:INFO:          deepchecks: Not installed
2024-07-08 09:55:01,818:INFO:             xgboost: 2.0.3
2024-07-08 09:55:01,818:INFO:            catboost: Not installed
2024-07-08 09:55:01,818:INFO:              kmodes: Not installed
2024-07-08 09:55:01,818:INFO:             mlxtend: 0.22.0
2024-07-08 09:55:01,818:INFO:       statsforecast: Not installed
2024-07-08 09:55:01,818:INFO:        tune_sklearn: Not installed
2024-07-08 09:55:01,818:INFO:                 ray: Not installed
2024-07-08 09:55:01,819:INFO:            hyperopt: 0.2.7
2024-07-08 09:55:01,819:INFO:              optuna: Not installed
2024-07-08 09:55:01,819:INFO:               skopt: Not installed
2024-07-08 09:55:01,819:INFO:              mlflow: Not installed
2024-07-08 09:55:01,819:INFO:              gradio: Not installed
2024-07-08 09:55:01,821:INFO:             fastapi: Not installed
2024-07-08 09:55:01,821:INFO:             uvicorn: Not installed
2024-07-08 09:55:01,821:INFO:              m2cgen: Not installed
2024-07-08 09:55:01,822:INFO:           evidently: Not installed
2024-07-08 09:55:01,822:INFO:               fugue: Not installed
2024-07-08 09:55:01,822:INFO:           streamlit: Not installed
2024-07-08 09:55:01,822:INFO:             prophet: 1.1.5
2024-07-08 09:55:01,822:INFO:None
2024-07-08 09:55:01,822:INFO:Set up data.
2024-07-08 09:55:01,859:INFO:Set up folding strategy.
2024-07-08 09:55:01,867:INFO:Set up train/test split.
2024-07-08 09:55:01,882:INFO:Set up index.
2024-07-08 09:55:01,882:INFO:Assigning column types.
2024-07-08 09:55:01,894:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 09:55:02,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:55:02,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:55:02,155:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:02,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:02,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 09:55:02,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:55:02,444:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:02,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:02,466:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 09:55:02,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:55:02,883:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:02,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:03,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-08 09:55:03,164:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:03,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:03,179:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-08 09:55:03,430:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:03,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:03,612:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:03,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:03,622:INFO:Preparing preprocessing pipeline...
2024-07-08 09:55:03,624:INFO:Set up simple imputation.
2024-07-08 09:55:03,671:INFO:Finished creating preprocessing pipeline.
2024-07-08 09:55:03,678:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Solyc01g105660', 'Solyc02g061770',
                                             'Solyc02g062040', 'Solyc02g084850',
                                             'Solyc03g098100', 'Solyc03g098240',
                                             'Solyc03g121880', 'Solyc04g005250',
                                             'Solyc04g009860', 'Solyc04g071780',
                                             'Solyc04g081900', 'Solyc06g050130',
                                             'Solyc06g066600', 'Solyc06g06...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-08 09:55:03,679:INFO:Creating final display dataframe.
2024-07-08 09:55:03,871:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         condition
2                   Target type            Binary
3           Original data shape          (36, 27)
4        Transformed data shape          (36, 27)
5   Transformed train set shape          (28, 27)
6    Transformed test set shape           (8, 27)
7              Numeric features                26
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              866e
2024-07-08 09:55:04,060:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:04,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:04,233:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-08 09:55:04,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 09:55:04,243:INFO:setup() successfully completed in 2.48s...............
2024-07-08 09:55:14,646:INFO:Initializing compare_models()
2024-07-08 09:55:14,647:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-08 09:55:14,647:INFO:Checking exceptions
2024-07-08 09:55:14,657:INFO:Preparing display monitor
2024-07-08 09:55:14,740:INFO:Initializing Logistic Regression
2024-07-08 09:55:14,740:INFO:Total runtime is 6.647904713948568e-06 minutes
2024-07-08 09:55:14,753:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:14,754:INFO:Initializing create_model()
2024-07-08 09:55:14,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:14,755:INFO:Checking exceptions
2024-07-08 09:55:14,755:INFO:Importing libraries
2024-07-08 09:55:14,755:INFO:Copying training dataset
2024-07-08 09:55:14,766:INFO:Defining folds
2024-07-08 09:55:14,767:INFO:Declaring metric variables
2024-07-08 09:55:14,775:INFO:Importing untrained model
2024-07-08 09:55:14,785:INFO:Logistic Regression Imported successfully
2024-07-08 09:55:14,807:INFO:Starting cross validation
2024-07-08 09:55:14,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:22,458:INFO:Calculating mean and std
2024-07-08 09:55:22,463:INFO:Creating metrics dataframe
2024-07-08 09:55:22,469:INFO:Uploading results into container
2024-07-08 09:55:22,470:INFO:Uploading model into container now
2024-07-08 09:55:22,471:INFO:_master_model_container: 1
2024-07-08 09:55:22,471:INFO:_display_container: 2
2024-07-08 09:55:22,472:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-08 09:55:22,472:INFO:create_model() successfully completed......................................
2024-07-08 09:55:22,789:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:22,790:INFO:Creating metrics dataframe
2024-07-08 09:55:22,804:INFO:Initializing K Neighbors Classifier
2024-07-08 09:55:22,804:INFO:Total runtime is 0.13440609375635781 minutes
2024-07-08 09:55:22,817:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:22,818:INFO:Initializing create_model()
2024-07-08 09:55:22,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:22,818:INFO:Checking exceptions
2024-07-08 09:55:22,818:INFO:Importing libraries
2024-07-08 09:55:22,819:INFO:Copying training dataset
2024-07-08 09:55:22,832:INFO:Defining folds
2024-07-08 09:55:22,833:INFO:Declaring metric variables
2024-07-08 09:55:22,854:INFO:Importing untrained model
2024-07-08 09:55:22,876:INFO:K Neighbors Classifier Imported successfully
2024-07-08 09:55:22,914:INFO:Starting cross validation
2024-07-08 09:55:22,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:23,612:INFO:Calculating mean and std
2024-07-08 09:55:23,618:INFO:Creating metrics dataframe
2024-07-08 09:55:23,625:INFO:Uploading results into container
2024-07-08 09:55:23,627:INFO:Uploading model into container now
2024-07-08 09:55:23,628:INFO:_master_model_container: 2
2024-07-08 09:55:23,628:INFO:_display_container: 2
2024-07-08 09:55:23,629:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-08 09:55:23,630:INFO:create_model() successfully completed......................................
2024-07-08 09:55:23,808:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:23,808:INFO:Creating metrics dataframe
2024-07-08 09:55:23,824:INFO:Initializing Naive Bayes
2024-07-08 09:55:23,824:INFO:Total runtime is 0.15140795707702637 minutes
2024-07-08 09:55:23,841:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:23,841:INFO:Initializing create_model()
2024-07-08 09:55:23,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:23,842:INFO:Checking exceptions
2024-07-08 09:55:23,842:INFO:Importing libraries
2024-07-08 09:55:23,843:INFO:Copying training dataset
2024-07-08 09:55:23,863:INFO:Defining folds
2024-07-08 09:55:23,865:INFO:Declaring metric variables
2024-07-08 09:55:23,879:INFO:Importing untrained model
2024-07-08 09:55:23,894:INFO:Naive Bayes Imported successfully
2024-07-08 09:55:23,920:INFO:Starting cross validation
2024-07-08 09:55:23,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:24,013:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:24,206:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:24,278:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:24,433:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:24,485:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:24,537:INFO:Calculating mean and std
2024-07-08 09:55:24,545:INFO:Creating metrics dataframe
2024-07-08 09:55:24,550:INFO:Uploading results into container
2024-07-08 09:55:24,552:INFO:Uploading model into container now
2024-07-08 09:55:24,553:INFO:_master_model_container: 3
2024-07-08 09:55:24,554:INFO:_display_container: 2
2024-07-08 09:55:24,554:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-08 09:55:24,555:INFO:create_model() successfully completed......................................
2024-07-08 09:55:24,758:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:24,760:INFO:Creating metrics dataframe
2024-07-08 09:55:24,778:INFO:Initializing Decision Tree Classifier
2024-07-08 09:55:24,780:INFO:Total runtime is 0.16734008391698202 minutes
2024-07-08 09:55:24,793:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:24,794:INFO:Initializing create_model()
2024-07-08 09:55:24,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:24,794:INFO:Checking exceptions
2024-07-08 09:55:24,794:INFO:Importing libraries
2024-07-08 09:55:24,794:INFO:Copying training dataset
2024-07-08 09:55:24,811:INFO:Defining folds
2024-07-08 09:55:24,811:INFO:Declaring metric variables
2024-07-08 09:55:24,827:INFO:Importing untrained model
2024-07-08 09:55:24,844:INFO:Decision Tree Classifier Imported successfully
2024-07-08 09:55:24,870:INFO:Starting cross validation
2024-07-08 09:55:24,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:25,244:INFO:Calculating mean and std
2024-07-08 09:55:25,246:INFO:Creating metrics dataframe
2024-07-08 09:55:25,251:INFO:Uploading results into container
2024-07-08 09:55:25,253:INFO:Uploading model into container now
2024-07-08 09:55:25,253:INFO:_master_model_container: 4
2024-07-08 09:55:25,254:INFO:_display_container: 2
2024-07-08 09:55:25,254:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-07-08 09:55:25,255:INFO:create_model() successfully completed......................................
2024-07-08 09:55:25,394:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:25,394:INFO:Creating metrics dataframe
2024-07-08 09:55:25,408:INFO:Initializing SVM - Linear Kernel
2024-07-08 09:55:25,410:INFO:Total runtime is 0.17783381938934326 minutes
2024-07-08 09:55:25,420:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:25,421:INFO:Initializing create_model()
2024-07-08 09:55:25,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:25,422:INFO:Checking exceptions
2024-07-08 09:55:25,422:INFO:Importing libraries
2024-07-08 09:55:25,422:INFO:Copying training dataset
2024-07-08 09:55:25,432:INFO:Defining folds
2024-07-08 09:55:25,433:INFO:Declaring metric variables
2024-07-08 09:55:25,445:INFO:Importing untrained model
2024-07-08 09:55:25,455:INFO:SVM - Linear Kernel Imported successfully
2024-07-08 09:55:25,477:INFO:Starting cross validation
2024-07-08 09:55:25,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:25,834:INFO:Calculating mean and std
2024-07-08 09:55:25,836:INFO:Creating metrics dataframe
2024-07-08 09:55:25,841:INFO:Uploading results into container
2024-07-08 09:55:25,842:INFO:Uploading model into container now
2024-07-08 09:55:25,842:INFO:_master_model_container: 5
2024-07-08 09:55:25,843:INFO:_display_container: 2
2024-07-08 09:55:25,844:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-08 09:55:25,844:INFO:create_model() successfully completed......................................
2024-07-08 09:55:25,973:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:25,974:INFO:Creating metrics dataframe
2024-07-08 09:55:25,985:INFO:Initializing Ridge Classifier
2024-07-08 09:55:25,986:INFO:Total runtime is 0.18743476470311482 minutes
2024-07-08 09:55:25,998:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:25,999:INFO:Initializing create_model()
2024-07-08 09:55:25,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:25,999:INFO:Checking exceptions
2024-07-08 09:55:25,999:INFO:Importing libraries
2024-07-08 09:55:25,999:INFO:Copying training dataset
2024-07-08 09:55:26,010:INFO:Defining folds
2024-07-08 09:55:26,011:INFO:Declaring metric variables
2024-07-08 09:55:26,025:INFO:Importing untrained model
2024-07-08 09:55:26,038:INFO:Ridge Classifier Imported successfully
2024-07-08 09:55:26,059:INFO:Starting cross validation
2024-07-08 09:55:26,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:26,110:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,110:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,190:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,191:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,249:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,268:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,319:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,334:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-07-08 09:55:26,430:INFO:Calculating mean and std
2024-07-08 09:55:26,432:INFO:Creating metrics dataframe
2024-07-08 09:55:26,437:INFO:Uploading results into container
2024-07-08 09:55:26,439:INFO:Uploading model into container now
2024-07-08 09:55:26,439:INFO:_master_model_container: 6
2024-07-08 09:55:26,440:INFO:_display_container: 2
2024-07-08 09:55:26,440:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-07-08 09:55:26,441:INFO:create_model() successfully completed......................................
2024-07-08 09:55:26,570:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:26,570:INFO:Creating metrics dataframe
2024-07-08 09:55:26,582:INFO:Initializing Random Forest Classifier
2024-07-08 09:55:26,582:INFO:Total runtime is 0.19737162590026855 minutes
2024-07-08 09:55:26,593:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:26,593:INFO:Initializing create_model()
2024-07-08 09:55:26,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:26,594:INFO:Checking exceptions
2024-07-08 09:55:26,594:INFO:Importing libraries
2024-07-08 09:55:26,594:INFO:Copying training dataset
2024-07-08 09:55:26,606:INFO:Defining folds
2024-07-08 09:55:26,607:INFO:Declaring metric variables
2024-07-08 09:55:26,628:INFO:Importing untrained model
2024-07-08 09:55:26,644:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:55:26,669:INFO:Starting cross validation
2024-07-08 09:55:26,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:28,549:INFO:Calculating mean and std
2024-07-08 09:55:28,551:INFO:Creating metrics dataframe
2024-07-08 09:55:28,556:INFO:Uploading results into container
2024-07-08 09:55:28,557:INFO:Uploading model into container now
2024-07-08 09:55:28,558:INFO:_master_model_container: 7
2024-07-08 09:55:28,559:INFO:_display_container: 2
2024-07-08 09:55:28,560:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:55:28,561:INFO:create_model() successfully completed......................................
2024-07-08 09:55:28,695:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:28,695:INFO:Creating metrics dataframe
2024-07-08 09:55:28,707:INFO:Initializing Quadratic Discriminant Analysis
2024-07-08 09:55:28,707:INFO:Total runtime is 0.23279280662536622 minutes
2024-07-08 09:55:28,718:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:28,718:INFO:Initializing create_model()
2024-07-08 09:55:28,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:28,719:INFO:Checking exceptions
2024-07-08 09:55:28,719:INFO:Importing libraries
2024-07-08 09:55:28,719:INFO:Copying training dataset
2024-07-08 09:55:28,729:INFO:Defining folds
2024-07-08 09:55:28,730:INFO:Declaring metric variables
2024-07-08 09:55:28,744:INFO:Importing untrained model
2024-07-08 09:55:28,755:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-08 09:55:28,776:INFO:Starting cross validation
2024-07-08 09:55:28,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:28,835:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:28,835:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:28,891:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:28,906:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:28,944:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:28,969:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:29,001:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:29,019:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:29,062:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:29,076:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-08 09:55:29,116:INFO:Calculating mean and std
2024-07-08 09:55:29,118:INFO:Creating metrics dataframe
2024-07-08 09:55:29,126:INFO:Uploading results into container
2024-07-08 09:55:29,127:INFO:Uploading model into container now
2024-07-08 09:55:29,128:INFO:_master_model_container: 8
2024-07-08 09:55:29,128:INFO:_display_container: 2
2024-07-08 09:55:29,129:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-08 09:55:29,129:INFO:create_model() successfully completed......................................
2024-07-08 09:55:29,260:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:29,261:INFO:Creating metrics dataframe
2024-07-08 09:55:29,273:INFO:Initializing Ada Boost Classifier
2024-07-08 09:55:29,273:INFO:Total runtime is 0.24222188393274943 minutes
2024-07-08 09:55:29,284:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:29,284:INFO:Initializing create_model()
2024-07-08 09:55:29,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:29,285:INFO:Checking exceptions
2024-07-08 09:55:29,285:INFO:Importing libraries
2024-07-08 09:55:29,285:INFO:Copying training dataset
2024-07-08 09:55:29,298:INFO:Defining folds
2024-07-08 09:55:29,298:INFO:Declaring metric variables
2024-07-08 09:55:29,314:INFO:Importing untrained model
2024-07-08 09:55:29,326:INFO:Ada Boost Classifier Imported successfully
2024-07-08 09:55:29,348:INFO:Starting cross validation
2024-07-08 09:55:29,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:29,385:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,387:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,605:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,632:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,862:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,890:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:29,950:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:30,083:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:30,162:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:30,303:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-08 09:55:30,451:INFO:Calculating mean and std
2024-07-08 09:55:30,456:INFO:Creating metrics dataframe
2024-07-08 09:55:30,461:INFO:Uploading results into container
2024-07-08 09:55:30,463:INFO:Uploading model into container now
2024-07-08 09:55:30,465:INFO:_master_model_container: 9
2024-07-08 09:55:30,465:INFO:_display_container: 2
2024-07-08 09:55:30,466:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-07-08 09:55:30,466:INFO:create_model() successfully completed......................................
2024-07-08 09:55:30,601:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:30,601:INFO:Creating metrics dataframe
2024-07-08 09:55:30,619:INFO:Initializing Gradient Boosting Classifier
2024-07-08 09:55:30,620:INFO:Total runtime is 0.26466678380966185 minutes
2024-07-08 09:55:30,635:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:30,636:INFO:Initializing create_model()
2024-07-08 09:55:30,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:30,636:INFO:Checking exceptions
2024-07-08 09:55:30,637:INFO:Importing libraries
2024-07-08 09:55:30,637:INFO:Copying training dataset
2024-07-08 09:55:30,651:INFO:Defining folds
2024-07-08 09:55:30,652:INFO:Declaring metric variables
2024-07-08 09:55:30,665:INFO:Importing untrained model
2024-07-08 09:55:30,677:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 09:55:30,699:INFO:Starting cross validation
2024-07-08 09:55:30,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:31,750:INFO:Calculating mean and std
2024-07-08 09:55:31,752:INFO:Creating metrics dataframe
2024-07-08 09:55:31,756:INFO:Uploading results into container
2024-07-08 09:55:31,760:INFO:Uploading model into container now
2024-07-08 09:55:31,761:INFO:_master_model_container: 10
2024-07-08 09:55:31,761:INFO:_display_container: 2
2024-07-08 09:55:31,761:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 09:55:31,762:INFO:create_model() successfully completed......................................
2024-07-08 09:55:31,890:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:31,891:INFO:Creating metrics dataframe
2024-07-08 09:55:31,904:INFO:Initializing Linear Discriminant Analysis
2024-07-08 09:55:31,905:INFO:Total runtime is 0.2860825896263122 minutes
2024-07-08 09:55:31,915:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:31,916:INFO:Initializing create_model()
2024-07-08 09:55:31,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:31,916:INFO:Checking exceptions
2024-07-08 09:55:31,916:INFO:Importing libraries
2024-07-08 09:55:31,916:INFO:Copying training dataset
2024-07-08 09:55:31,927:INFO:Defining folds
2024-07-08 09:55:31,927:INFO:Declaring metric variables
2024-07-08 09:55:31,939:INFO:Importing untrained model
2024-07-08 09:55:31,950:INFO:Linear Discriminant Analysis Imported successfully
2024-07-08 09:55:31,968:INFO:Starting cross validation
2024-07-08 09:55:31,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:32,265:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:32,284:INFO:Calculating mean and std
2024-07-08 09:55:32,286:INFO:Creating metrics dataframe
2024-07-08 09:55:32,291:INFO:Uploading results into container
2024-07-08 09:55:32,293:INFO:Uploading model into container now
2024-07-08 09:55:32,294:INFO:_master_model_container: 11
2024-07-08 09:55:32,296:INFO:_display_container: 2
2024-07-08 09:55:32,297:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-08 09:55:32,297:INFO:create_model() successfully completed......................................
2024-07-08 09:55:32,426:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:32,427:INFO:Creating metrics dataframe
2024-07-08 09:55:32,439:INFO:Initializing Extra Trees Classifier
2024-07-08 09:55:32,439:INFO:Total runtime is 0.2949925859769185 minutes
2024-07-08 09:55:32,451:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:32,452:INFO:Initializing create_model()
2024-07-08 09:55:32,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:32,453:INFO:Checking exceptions
2024-07-08 09:55:32,453:INFO:Importing libraries
2024-07-08 09:55:32,454:INFO:Copying training dataset
2024-07-08 09:55:32,465:INFO:Defining folds
2024-07-08 09:55:32,465:INFO:Declaring metric variables
2024-07-08 09:55:32,478:INFO:Importing untrained model
2024-07-08 09:55:32,492:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:55:32,520:INFO:Starting cross validation
2024-07-08 09:55:32,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:34,126:INFO:Calculating mean and std
2024-07-08 09:55:34,128:INFO:Creating metrics dataframe
2024-07-08 09:55:34,135:INFO:Uploading results into container
2024-07-08 09:55:34,136:INFO:Uploading model into container now
2024-07-08 09:55:34,137:INFO:_master_model_container: 12
2024-07-08 09:55:34,137:INFO:_display_container: 2
2024-07-08 09:55:34,138:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-08 09:55:34,138:INFO:create_model() successfully completed......................................
2024-07-08 09:55:34,275:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:34,276:INFO:Creating metrics dataframe
2024-07-08 09:55:34,289:INFO:Initializing Extreme Gradient Boosting
2024-07-08 09:55:34,290:INFO:Total runtime is 0.32583905855814616 minutes
2024-07-08 09:55:34,303:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:34,304:INFO:Initializing create_model()
2024-07-08 09:55:34,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:34,304:INFO:Checking exceptions
2024-07-08 09:55:34,305:INFO:Importing libraries
2024-07-08 09:55:34,305:INFO:Copying training dataset
2024-07-08 09:55:34,315:INFO:Defining folds
2024-07-08 09:55:34,315:INFO:Declaring metric variables
2024-07-08 09:55:34,327:INFO:Importing untrained model
2024-07-08 09:55:34,341:INFO:Extreme Gradient Boosting Imported successfully
2024-07-08 09:55:34,362:INFO:Starting cross validation
2024-07-08 09:55:34,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:34,911:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:35,046:INFO:Calculating mean and std
2024-07-08 09:55:35,048:INFO:Creating metrics dataframe
2024-07-08 09:55:35,052:INFO:Uploading results into container
2024-07-08 09:55:35,057:INFO:Uploading model into container now
2024-07-08 09:55:35,060:INFO:_master_model_container: 13
2024-07-08 09:55:35,061:INFO:_display_container: 2
2024-07-08 09:55:35,064:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-08 09:55:35,067:INFO:create_model() successfully completed......................................
2024-07-08 09:55:35,241:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:35,242:INFO:Creating metrics dataframe
2024-07-08 09:55:35,262:INFO:Initializing Light Gradient Boosting Machine
2024-07-08 09:55:35,262:INFO:Total runtime is 0.34203668038050333 minutes
2024-07-08 09:55:35,274:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:35,275:INFO:Initializing create_model()
2024-07-08 09:55:35,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:35,275:INFO:Checking exceptions
2024-07-08 09:55:35,276:INFO:Importing libraries
2024-07-08 09:55:35,276:INFO:Copying training dataset
2024-07-08 09:55:35,291:INFO:Defining folds
2024-07-08 09:55:35,291:INFO:Declaring metric variables
2024-07-08 09:55:35,305:INFO:Importing untrained model
2024-07-08 09:55:35,322:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 09:55:35,357:INFO:Starting cross validation
2024-07-08 09:55:35,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:35,821:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:35,824:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:36,240:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:36,241:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:36,657:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:36,815:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:36,827:INFO:Calculating mean and std
2024-07-08 09:55:36,834:INFO:Creating metrics dataframe
2024-07-08 09:55:36,839:INFO:Uploading results into container
2024-07-08 09:55:36,843:INFO:Uploading model into container now
2024-07-08 09:55:36,844:INFO:_master_model_container: 14
2024-07-08 09:55:36,844:INFO:_display_container: 2
2024-07-08 09:55:36,845:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-08 09:55:36,845:INFO:create_model() successfully completed......................................
2024-07-08 09:55:37,008:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:37,009:INFO:Creating metrics dataframe
2024-07-08 09:55:37,030:INFO:Initializing Dummy Classifier
2024-07-08 09:55:37,035:INFO:Total runtime is 0.37158940235773724 minutes
2024-07-08 09:55:37,049:INFO:SubProcess create_model() called ==================================
2024-07-08 09:55:37,053:INFO:Initializing create_model()
2024-07-08 09:55:37,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a93c3a680>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:37,053:INFO:Checking exceptions
2024-07-08 09:55:37,053:INFO:Importing libraries
2024-07-08 09:55:37,053:INFO:Copying training dataset
2024-07-08 09:55:37,066:INFO:Defining folds
2024-07-08 09:55:37,068:INFO:Declaring metric variables
2024-07-08 09:55:37,082:INFO:Importing untrained model
2024-07-08 09:55:37,097:INFO:Dummy Classifier Imported successfully
2024-07-08 09:55:37,124:INFO:Starting cross validation
2024-07-08 09:55:37,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:55:37,183:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,245:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,282:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,351:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,566:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,613:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-08 09:55:37,640:INFO:Calculating mean and std
2024-07-08 09:55:37,648:INFO:Creating metrics dataframe
2024-07-08 09:55:37,652:INFO:Uploading results into container
2024-07-08 09:55:37,661:INFO:Uploading model into container now
2024-07-08 09:55:37,665:INFO:_master_model_container: 15
2024-07-08 09:55:37,665:INFO:_display_container: 2
2024-07-08 09:55:37,666:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-07-08 09:55:37,666:INFO:create_model() successfully completed......................................
2024-07-08 09:55:37,865:INFO:SubProcess create_model() end ==================================
2024-07-08 09:55:37,865:INFO:Creating metrics dataframe
2024-07-08 09:55:37,928:INFO:Initializing create_model()
2024-07-08 09:55:37,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:55:37,929:INFO:Checking exceptions
2024-07-08 09:55:37,932:INFO:Importing libraries
2024-07-08 09:55:37,932:INFO:Copying training dataset
2024-07-08 09:55:37,943:INFO:Defining folds
2024-07-08 09:55:37,943:INFO:Declaring metric variables
2024-07-08 09:55:37,943:INFO:Importing untrained model
2024-07-08 09:55:37,944:INFO:Declaring custom model
2024-07-08 09:55:37,945:INFO:Extra Trees Classifier Imported successfully
2024-07-08 09:55:37,946:INFO:Cross validation set to False
2024-07-08 09:55:37,946:INFO:Fitting Model
2024-07-08 09:55:38,136:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-08 09:55:38,136:INFO:create_model() successfully completed......................................
2024-07-08 09:55:38,390:INFO:_master_model_container: 15
2024-07-08 09:55:38,395:INFO:_display_container: 2
2024-07-08 09:55:38,396:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-07-08 09:55:38,397:INFO:compare_models() successfully completed......................................
2024-07-08 09:56:24,172:INFO:Initializing create_model()
2024-07-08 09:56:24,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:56:24,173:INFO:Checking exceptions
2024-07-08 09:56:24,209:INFO:Importing libraries
2024-07-08 09:56:24,227:INFO:Copying training dataset
2024-07-08 09:56:24,240:INFO:Defining folds
2024-07-08 09:56:24,240:INFO:Declaring metric variables
2024-07-08 09:56:24,249:INFO:Importing untrained model
2024-07-08 09:56:24,260:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:56:24,285:INFO:Starting cross validation
2024-07-08 09:56:24,287:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:56:26,194:INFO:Calculating mean and std
2024-07-08 09:56:26,196:INFO:Creating metrics dataframe
2024-07-08 09:56:26,213:INFO:Finalizing model
2024-07-08 09:56:26,428:INFO:Uploading results into container
2024-07-08 09:56:26,431:INFO:Uploading model into container now
2024-07-08 09:56:26,454:INFO:_master_model_container: 16
2024-07-08 09:56:26,454:INFO:_display_container: 3
2024-07-08 09:56:26,455:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:56:26,456:INFO:create_model() successfully completed......................................
2024-07-08 09:56:34,255:INFO:Initializing tune_model()
2024-07-08 09:56:34,258:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>)
2024-07-08 09:56:34,258:INFO:Checking exceptions
2024-07-08 09:56:34,310:INFO:Copying training dataset
2024-07-08 09:56:34,321:INFO:Checking base model
2024-07-08 09:56:34,321:INFO:Base model : Random Forest Classifier
2024-07-08 09:56:34,331:INFO:Declaring metric variables
2024-07-08 09:56:34,342:INFO:Defining Hyperparameters
2024-07-08 09:56:34,481:INFO:Tuning with n_jobs=-1
2024-07-08 09:56:34,481:INFO:Initializing RandomizedSearchCV
2024-07-08 09:57:02,059:INFO:best_params: {'actual_estimator__n_estimators': 10, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 2, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2024-07-08 09:57:02,061:INFO:Hyperparameter search completed
2024-07-08 09:57:02,069:INFO:SubProcess create_model() called ==================================
2024-07-08 09:57:02,070:INFO:Initializing create_model()
2024-07-08 09:57:02,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6eab9f00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.1, 'max_features': 'log2', 'max_depth': 2, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2024-07-08 09:57:02,071:INFO:Checking exceptions
2024-07-08 09:57:02,071:INFO:Importing libraries
2024-07-08 09:57:02,071:INFO:Copying training dataset
2024-07-08 09:57:02,083:INFO:Defining folds
2024-07-08 09:57:02,083:INFO:Declaring metric variables
2024-07-08 09:57:02,096:INFO:Importing untrained model
2024-07-08 09:57:02,096:INFO:Declaring custom model
2024-07-08 09:57:02,113:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:57:02,139:INFO:Starting cross validation
2024-07-08 09:57:02,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:57:03,209:INFO:Calculating mean and std
2024-07-08 09:57:03,213:INFO:Creating metrics dataframe
2024-07-08 09:57:03,233:INFO:Finalizing model
2024-07-08 09:57:03,293:INFO:Uploading results into container
2024-07-08 09:57:03,295:INFO:Uploading model into container now
2024-07-08 09:57:03,296:INFO:_master_model_container: 17
2024-07-08 09:57:03,296:INFO:_display_container: 4
2024-07-08 09:57:03,297:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=2, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:03,299:INFO:create_model() successfully completed......................................
2024-07-08 09:57:03,497:INFO:SubProcess create_model() end ==================================
2024-07-08 09:57:03,498:INFO:choose_better activated
2024-07-08 09:57:03,512:INFO:SubProcess create_model() called ==================================
2024-07-08 09:57:03,513:INFO:Initializing create_model()
2024-07-08 09:57:03,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:57:03,513:INFO:Checking exceptions
2024-07-08 09:57:03,516:INFO:Importing libraries
2024-07-08 09:57:03,517:INFO:Copying training dataset
2024-07-08 09:57:03,529:INFO:Defining folds
2024-07-08 09:57:03,529:INFO:Declaring metric variables
2024-07-08 09:57:03,530:INFO:Importing untrained model
2024-07-08 09:57:03,530:INFO:Declaring custom model
2024-07-08 09:57:03,533:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:57:03,540:INFO:Starting cross validation
2024-07-08 09:57:03,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:57:07,101:INFO:Calculating mean and std
2024-07-08 09:57:07,102:INFO:Creating metrics dataframe
2024-07-08 09:57:07,104:INFO:Finalizing model
2024-07-08 09:57:07,301:INFO:Uploading results into container
2024-07-08 09:57:07,302:INFO:Uploading model into container now
2024-07-08 09:57:07,303:INFO:_master_model_container: 18
2024-07-08 09:57:07,303:INFO:_display_container: 5
2024-07-08 09:57:07,304:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:07,304:INFO:create_model() successfully completed......................................
2024-07-08 09:57:07,438:INFO:SubProcess create_model() end ==================================
2024-07-08 09:57:07,440:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9667
2024-07-08 09:57:07,441:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=2, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9667
2024-07-08 09:57:07,441:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-08 09:57:07,442:INFO:choose_better completed
2024-07-08 09:57:07,442:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 09:57:07,460:INFO:_master_model_container: 18
2024-07-08 09:57:07,464:INFO:_display_container: 4
2024-07-08 09:57:07,465:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:07,465:INFO:tune_model() successfully completed......................................
2024-07-08 09:57:07,637:INFO:Initializing tune_model()
2024-07-08 09:57:07,640:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>)
2024-07-08 09:57:07,640:INFO:Checking exceptions
2024-07-08 09:57:07,693:INFO:Copying training dataset
2024-07-08 09:57:07,704:INFO:Checking base model
2024-07-08 09:57:07,705:INFO:Base model : Random Forest Classifier
2024-07-08 09:57:07,729:INFO:Declaring metric variables
2024-07-08 09:57:07,743:INFO:Defining Hyperparameters
2024-07-08 09:57:07,908:INFO:Tuning with n_jobs=-1
2024-07-08 09:57:07,910:INFO:Initializing RandomizedSearchCV
2024-07-08 09:57:38,882:INFO:best_params: {'actual_estimator__n_estimators': 10, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 2, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2024-07-08 09:57:38,886:INFO:Hyperparameter search completed
2024-07-08 09:57:38,886:INFO:SubProcess create_model() called ==================================
2024-07-08 09:57:38,887:INFO:Initializing create_model()
2024-07-08 09:57:38,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a6e95e620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.1, 'max_features': 'log2', 'max_depth': 2, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2024-07-08 09:57:38,888:INFO:Checking exceptions
2024-07-08 09:57:38,888:INFO:Importing libraries
2024-07-08 09:57:38,888:INFO:Copying training dataset
2024-07-08 09:57:38,906:INFO:Defining folds
2024-07-08 09:57:38,906:INFO:Declaring metric variables
2024-07-08 09:57:38,920:INFO:Importing untrained model
2024-07-08 09:57:38,920:INFO:Declaring custom model
2024-07-08 09:57:38,936:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:57:38,964:INFO:Starting cross validation
2024-07-08 09:57:38,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:57:39,791:INFO:Calculating mean and std
2024-07-08 09:57:39,793:INFO:Creating metrics dataframe
2024-07-08 09:57:39,809:INFO:Finalizing model
2024-07-08 09:57:39,858:INFO:Uploading results into container
2024-07-08 09:57:39,860:INFO:Uploading model into container now
2024-07-08 09:57:39,861:INFO:_master_model_container: 19
2024-07-08 09:57:39,861:INFO:_display_container: 5
2024-07-08 09:57:39,862:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=2, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:39,862:INFO:create_model() successfully completed......................................
2024-07-08 09:57:40,001:INFO:SubProcess create_model() end ==================================
2024-07-08 09:57:40,001:INFO:choose_better activated
2024-07-08 09:57:40,013:INFO:SubProcess create_model() called ==================================
2024-07-08 09:57:40,015:INFO:Initializing create_model()
2024-07-08 09:57:40,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 09:57:40,015:INFO:Checking exceptions
2024-07-08 09:57:40,019:INFO:Importing libraries
2024-07-08 09:57:40,019:INFO:Copying training dataset
2024-07-08 09:57:40,026:INFO:Defining folds
2024-07-08 09:57:40,027:INFO:Declaring metric variables
2024-07-08 09:57:40,027:INFO:Importing untrained model
2024-07-08 09:57:40,027:INFO:Declaring custom model
2024-07-08 09:57:40,028:INFO:Random Forest Classifier Imported successfully
2024-07-08 09:57:40,029:INFO:Starting cross validation
2024-07-08 09:57:40,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 09:57:41,861:INFO:Calculating mean and std
2024-07-08 09:57:41,862:INFO:Creating metrics dataframe
2024-07-08 09:57:41,864:INFO:Finalizing model
2024-07-08 09:57:42,063:INFO:Uploading results into container
2024-07-08 09:57:42,064:INFO:Uploading model into container now
2024-07-08 09:57:42,065:INFO:_master_model_container: 20
2024-07-08 09:57:42,065:INFO:_display_container: 6
2024-07-08 09:57:42,065:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:42,066:INFO:create_model() successfully completed......................................
2024-07-08 09:57:42,199:INFO:SubProcess create_model() end ==================================
2024-07-08 09:57:42,200:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9667
2024-07-08 09:57:42,201:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=2, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=3,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.9667
2024-07-08 09:57:42,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2024-07-08 09:57:42,202:INFO:choose_better completed
2024-07-08 09:57:42,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 09:57:42,221:INFO:_master_model_container: 20
2024-07-08 09:57:42,222:INFO:_display_container: 5
2024-07-08 09:57:42,222:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-07-08 09:57:42,223:INFO:tune_model() successfully completed......................................
2024-07-08 09:57:42,426:INFO:Initializing plot_model()
2024-07-08 09:57:42,426:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 09:57:42,427:INFO:Checking exceptions
2024-07-08 09:57:42,460:INFO:Preloading libraries
2024-07-08 09:57:42,472:INFO:Copying training dataset
2024-07-08 09:57:42,472:INFO:Plot type: error
2024-07-08 09:57:42,611:INFO:Fitting Model
2024-07-08 09:57:42,612:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-08 09:57:42,613:INFO:Scoring test/hold-out set
2024-07-08 09:57:43,056:INFO:Visual Rendered Successfully
2024-07-08 09:57:43,195:INFO:plot_model() successfully completed......................................
2024-07-08 09:57:43,204:INFO:Initializing plot_model()
2024-07-08 09:57:43,207:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 09:57:43,207:INFO:Checking exceptions
2024-07-08 09:57:43,237:INFO:Preloading libraries
2024-07-08 09:57:43,247:INFO:Copying training dataset
2024-07-08 09:57:43,247:INFO:Plot type: learning
2024-07-08 09:57:43,364:INFO:Fitting Model
2024-07-08 09:58:05,318:INFO:Visual Rendered Successfully
2024-07-08 09:58:05,454:INFO:plot_model() successfully completed......................................
2024-07-08 09:58:05,464:INFO:Initializing plot_model()
2024-07-08 09:58:05,467:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 09:58:05,467:INFO:Checking exceptions
2024-07-08 09:58:05,498:INFO:Preloading libraries
2024-07-08 09:58:05,509:INFO:Copying training dataset
2024-07-08 09:58:05,510:INFO:Plot type: vc
2024-07-08 09:58:05,511:INFO:Determining param_name
2024-07-08 09:58:05,511:INFO:param_name: max_depth
2024-07-08 09:58:05,635:INFO:Fitting Model
2024-07-08 09:58:29,881:INFO:Visual Rendered Successfully
2024-07-08 09:58:30,023:INFO:plot_model() successfully completed......................................
2024-07-08 09:58:30,033:INFO:Initializing plot_model()
2024-07-08 09:58:30,034:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 09:58:30,035:INFO:Checking exceptions
2024-07-08 09:58:30,067:INFO:Preloading libraries
2024-07-08 09:58:30,079:INFO:Copying training dataset
2024-07-08 09:58:30,079:INFO:Plot type: feature
2024-07-08 09:58:30,080:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 09:58:30,372:INFO:Visual Rendered Successfully
2024-07-08 09:58:30,512:INFO:plot_model() successfully completed......................................
2024-07-08 10:00:37,813:INFO:Initializing create_model()
2024-07-08 10:00:37,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 10:00:37,814:INFO:Checking exceptions
2024-07-08 10:00:37,886:INFO:Importing libraries
2024-07-08 10:00:37,886:INFO:Copying training dataset
2024-07-08 10:00:37,904:INFO:Defining folds
2024-07-08 10:00:37,904:INFO:Declaring metric variables
2024-07-08 10:00:37,922:INFO:Importing untrained model
2024-07-08 10:00:37,936:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 10:00:37,962:INFO:Starting cross validation
2024-07-08 10:00:37,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 10:00:39,979:INFO:Calculating mean and std
2024-07-08 10:00:39,982:INFO:Creating metrics dataframe
2024-07-08 10:00:40,002:INFO:Finalizing model
2024-07-08 10:00:40,173:INFO:Uploading results into container
2024-07-08 10:00:40,174:INFO:Uploading model into container now
2024-07-08 10:00:40,194:INFO:_master_model_container: 21
2024-07-08 10:00:40,195:INFO:_display_container: 6
2024-07-08 10:00:40,196:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:00:40,196:INFO:create_model() successfully completed......................................
2024-07-08 10:00:43,645:INFO:Initializing plot_model()
2024-07-08 10:00:43,649:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:00:43,650:INFO:Checking exceptions
2024-07-08 10:00:43,658:INFO:Preloading libraries
2024-07-08 10:00:43,676:INFO:Copying training dataset
2024-07-08 10:00:43,676:INFO:Plot type: error
2024-07-08 10:00:43,788:INFO:Fitting Model
2024-07-08 10:00:43,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-08 10:00:43,789:INFO:Scoring test/hold-out set
2024-07-08 10:00:44,098:INFO:Visual Rendered Successfully
2024-07-08 10:00:44,230:INFO:plot_model() successfully completed......................................
2024-07-08 10:00:44,256:INFO:Initializing plot_model()
2024-07-08 10:00:44,260:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:00:44,260:INFO:Checking exceptions
2024-07-08 10:00:44,269:INFO:Preloading libraries
2024-07-08 10:00:44,285:INFO:Copying training dataset
2024-07-08 10:00:44,286:INFO:Plot type: learning
2024-07-08 10:00:44,399:INFO:Fitting Model
2024-07-08 10:00:54,469:INFO:Visual Rendered Successfully
2024-07-08 10:00:54,648:INFO:plot_model() successfully completed......................................
2024-07-08 10:00:54,659:INFO:Initializing plot_model()
2024-07-08 10:00:54,660:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:00:54,660:INFO:Checking exceptions
2024-07-08 10:00:54,674:INFO:Preloading libraries
2024-07-08 10:00:54,696:INFO:Copying training dataset
2024-07-08 10:00:54,697:INFO:Plot type: vc
2024-07-08 10:00:54,699:INFO:Determining param_name
2024-07-08 10:00:54,700:INFO:param_name: max_depth
2024-07-08 10:00:54,891:INFO:Fitting Model
2024-07-08 10:01:04,065:INFO:Visual Rendered Successfully
2024-07-08 10:01:04,202:INFO:plot_model() successfully completed......................................
2024-07-08 10:01:04,221:INFO:Initializing plot_model()
2024-07-08 10:01:04,221:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:01:04,222:INFO:Checking exceptions
2024-07-08 10:01:04,230:INFO:Preloading libraries
2024-07-08 10:01:04,240:INFO:Copying training dataset
2024-07-08 10:01:04,240:INFO:Plot type: feature
2024-07-08 10:01:04,242:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 10:01:04,493:INFO:Visual Rendered Successfully
2024-07-08 10:01:04,652:INFO:plot_model() successfully completed......................................
2024-07-08 10:01:04,668:INFO:Initializing plot_model()
2024-07-08 10:01:04,670:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:01:04,671:INFO:Checking exceptions
2024-07-08 10:01:04,679:INFO:Preloading libraries
2024-07-08 10:01:04,694:INFO:Copying training dataset
2024-07-08 10:01:04,695:INFO:Plot type: feature
2024-07-08 10:01:04,696:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 10:01:04,956:INFO:Visual Rendered Successfully
2024-07-08 10:01:05,096:INFO:plot_model() successfully completed......................................
2024-07-08 10:01:39,001:INFO:Initializing tune_model()
2024-07-08 10:01:39,002:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>)
2024-07-08 10:01:39,002:INFO:Checking exceptions
2024-07-08 10:01:39,037:INFO:Copying training dataset
2024-07-08 10:01:39,054:INFO:Checking base model
2024-07-08 10:01:39,055:INFO:Base model : Gradient Boosting Classifier
2024-07-08 10:01:39,071:INFO:Declaring metric variables
2024-07-08 10:01:39,082:INFO:Defining Hyperparameters
2024-07-08 10:01:39,226:INFO:Tuning with n_jobs=-1
2024-07-08 10:01:39,226:INFO:Initializing RandomizedSearchCV
2024-07-08 10:01:53,161:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2024-07-08 10:01:53,163:INFO:Hyperparameter search completed
2024-07-08 10:01:53,163:INFO:SubProcess create_model() called ==================================
2024-07-08 10:01:53,166:INFO:Initializing create_model()
2024-07-08 10:01:53,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a9acee530>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2024-07-08 10:01:53,166:INFO:Checking exceptions
2024-07-08 10:01:53,166:INFO:Importing libraries
2024-07-08 10:01:53,167:INFO:Copying training dataset
2024-07-08 10:01:53,179:INFO:Defining folds
2024-07-08 10:01:53,179:INFO:Declaring metric variables
2024-07-08 10:01:53,189:INFO:Importing untrained model
2024-07-08 10:01:53,189:INFO:Declaring custom model
2024-07-08 10:01:53,201:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 10:01:53,225:INFO:Starting cross validation
2024-07-08 10:01:53,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 10:01:54,668:INFO:Calculating mean and std
2024-07-08 10:01:54,670:INFO:Creating metrics dataframe
2024-07-08 10:01:54,686:INFO:Finalizing model
2024-07-08 10:01:54,854:INFO:Uploading results into container
2024-07-08 10:01:54,857:INFO:Uploading model into container now
2024-07-08 10:01:54,858:INFO:_master_model_container: 22
2024-07-08 10:01:54,858:INFO:_display_container: 7
2024-07-08 10:01:54,859:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:01:54,859:INFO:create_model() successfully completed......................................
2024-07-08 10:01:55,003:INFO:SubProcess create_model() end ==================================
2024-07-08 10:01:55,004:INFO:choose_better activated
2024-07-08 10:01:55,015:INFO:SubProcess create_model() called ==================================
2024-07-08 10:01:55,016:INFO:Initializing create_model()
2024-07-08 10:01:55,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 10:01:55,017:INFO:Checking exceptions
2024-07-08 10:01:55,020:INFO:Importing libraries
2024-07-08 10:01:55,020:INFO:Copying training dataset
2024-07-08 10:01:55,030:INFO:Defining folds
2024-07-08 10:01:55,030:INFO:Declaring metric variables
2024-07-08 10:01:55,031:INFO:Importing untrained model
2024-07-08 10:01:55,031:INFO:Declaring custom model
2024-07-08 10:01:55,032:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 10:01:55,033:INFO:Starting cross validation
2024-07-08 10:01:55,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 10:01:56,111:INFO:Calculating mean and std
2024-07-08 10:01:56,111:INFO:Creating metrics dataframe
2024-07-08 10:01:56,114:INFO:Finalizing model
2024-07-08 10:01:56,237:INFO:Uploading results into container
2024-07-08 10:01:56,238:INFO:Uploading model into container now
2024-07-08 10:01:56,239:INFO:_master_model_container: 23
2024-07-08 10:01:56,239:INFO:_display_container: 8
2024-07-08 10:01:56,240:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:01:56,240:INFO:create_model() successfully completed......................................
2024-07-08 10:01:56,382:INFO:SubProcess create_model() end ==================================
2024-07-08 10:01:56,383:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9667
2024-07-08 10:01:56,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9667
2024-07-08 10:01:56,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-08 10:01:56,385:INFO:choose_better completed
2024-07-08 10:01:56,385:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 10:01:56,404:INFO:_master_model_container: 23
2024-07-08 10:01:56,404:INFO:_display_container: 7
2024-07-08 10:01:56,406:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:01:56,406:INFO:tune_model() successfully completed......................................
2024-07-08 10:01:56,591:INFO:Initializing tune_model()
2024-07-08 10:01:56,592:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>)
2024-07-08 10:01:56,592:INFO:Checking exceptions
2024-07-08 10:01:56,631:INFO:Copying training dataset
2024-07-08 10:01:56,647:INFO:Checking base model
2024-07-08 10:01:56,648:INFO:Base model : Gradient Boosting Classifier
2024-07-08 10:01:56,668:INFO:Declaring metric variables
2024-07-08 10:01:56,685:INFO:Defining Hyperparameters
2024-07-08 10:01:56,849:INFO:Tuning with n_jobs=-1
2024-07-08 10:01:56,849:INFO:Initializing RandomizedSearchCV
2024-07-08 10:02:10,790:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2024-07-08 10:02:10,791:INFO:Hyperparameter search completed
2024-07-08 10:02:10,793:INFO:SubProcess create_model() called ==================================
2024-07-08 10:02:10,798:INFO:Initializing create_model()
2024-07-08 10:02:10,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7c6a90847610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2024-07-08 10:02:10,798:INFO:Checking exceptions
2024-07-08 10:02:10,799:INFO:Importing libraries
2024-07-08 10:02:10,799:INFO:Copying training dataset
2024-07-08 10:02:10,807:INFO:Defining folds
2024-07-08 10:02:10,807:INFO:Declaring metric variables
2024-07-08 10:02:10,816:INFO:Importing untrained model
2024-07-08 10:02:10,817:INFO:Declaring custom model
2024-07-08 10:02:10,829:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 10:02:10,850:INFO:Starting cross validation
2024-07-08 10:02:10,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 10:02:12,291:INFO:Calculating mean and std
2024-07-08 10:02:12,296:INFO:Creating metrics dataframe
2024-07-08 10:02:12,313:INFO:Finalizing model
2024-07-08 10:02:12,479:INFO:Uploading results into container
2024-07-08 10:02:12,481:INFO:Uploading model into container now
2024-07-08 10:02:12,482:INFO:_master_model_container: 24
2024-07-08 10:02:12,482:INFO:_display_container: 8
2024-07-08 10:02:12,483:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:02:12,484:INFO:create_model() successfully completed......................................
2024-07-08 10:02:12,627:INFO:SubProcess create_model() end ==================================
2024-07-08 10:02:12,628:INFO:choose_better activated
2024-07-08 10:02:12,641:INFO:SubProcess create_model() called ==================================
2024-07-08 10:02:12,643:INFO:Initializing create_model()
2024-07-08 10:02:12,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 10:02:12,644:INFO:Checking exceptions
2024-07-08 10:02:12,648:INFO:Importing libraries
2024-07-08 10:02:12,649:INFO:Copying training dataset
2024-07-08 10:02:12,660:INFO:Defining folds
2024-07-08 10:02:12,660:INFO:Declaring metric variables
2024-07-08 10:02:12,661:INFO:Importing untrained model
2024-07-08 10:02:12,661:INFO:Declaring custom model
2024-07-08 10:02:12,662:INFO:Gradient Boosting Classifier Imported successfully
2024-07-08 10:02:12,663:INFO:Starting cross validation
2024-07-08 10:02:12,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 10:02:13,712:INFO:Calculating mean and std
2024-07-08 10:02:13,712:INFO:Creating metrics dataframe
2024-07-08 10:02:13,715:INFO:Finalizing model
2024-07-08 10:02:13,818:INFO:Uploading results into container
2024-07-08 10:02:13,819:INFO:Uploading model into container now
2024-07-08 10:02:13,820:INFO:_master_model_container: 25
2024-07-08 10:02:13,820:INFO:_display_container: 9
2024-07-08 10:02:13,820:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:02:13,821:INFO:create_model() successfully completed......................................
2024-07-08 10:02:13,962:INFO:SubProcess create_model() end ==================================
2024-07-08 10:02:13,963:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9667
2024-07-08 10:02:13,964:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9667
2024-07-08 10:02:13,965:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-08 10:02:13,965:INFO:choose_better completed
2024-07-08 10:02:13,966:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-08 10:02:13,983:INFO:_master_model_container: 25
2024-07-08 10:02:13,983:INFO:_display_container: 8
2024-07-08 10:02:13,984:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-08 10:02:13,984:INFO:tune_model() successfully completed......................................
2024-07-08 10:02:26,170:INFO:Initializing plot_model()
2024-07-08 10:02:26,171:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:02:26,171:INFO:Checking exceptions
2024-07-08 10:02:26,180:INFO:Preloading libraries
2024-07-08 10:02:26,191:INFO:Copying training dataset
2024-07-08 10:02:26,192:INFO:Plot type: error
2024-07-08 10:02:26,318:INFO:Fitting Model
2024-07-08 10:02:26,319:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-08 10:02:26,319:INFO:Scoring test/hold-out set
2024-07-08 10:02:26,669:INFO:Visual Rendered Successfully
2024-07-08 10:02:26,817:INFO:plot_model() successfully completed......................................
2024-07-08 10:02:28,662:INFO:Initializing plot_model()
2024-07-08 10:02:28,663:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:02:28,664:INFO:Checking exceptions
2024-07-08 10:02:28,675:INFO:Preloading libraries
2024-07-08 10:02:28,685:INFO:Copying training dataset
2024-07-08 10:02:28,685:INFO:Plot type: learning
2024-07-08 10:02:28,797:INFO:Fitting Model
2024-07-08 10:02:40,157:INFO:Visual Rendered Successfully
2024-07-08 10:02:40,307:INFO:plot_model() successfully completed......................................
2024-07-08 10:02:40,316:INFO:Initializing plot_model()
2024-07-08 10:02:40,319:INFO:plot_model(plot=vc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:02:40,319:INFO:Checking exceptions
2024-07-08 10:02:40,326:INFO:Preloading libraries
2024-07-08 10:02:40,342:INFO:Copying training dataset
2024-07-08 10:02:40,342:INFO:Plot type: vc
2024-07-08 10:02:40,344:INFO:Determining param_name
2024-07-08 10:02:40,345:INFO:param_name: max_depth
2024-07-08 10:02:40,457:INFO:Fitting Model
2024-07-08 10:02:49,584:INFO:Visual Rendered Successfully
2024-07-08 10:02:49,767:INFO:plot_model() successfully completed......................................
2024-07-08 10:02:49,779:INFO:Initializing plot_model()
2024-07-08 10:02:49,780:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7c6a6e89fd60>, system=True)
2024-07-08 10:02:49,780:INFO:Checking exceptions
2024-07-08 10:02:49,790:INFO:Preloading libraries
2024-07-08 10:02:49,803:INFO:Copying training dataset
2024-07-08 10:02:49,803:INFO:Plot type: feature
2024-07-08 10:02:49,805:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 10:02:50,147:INFO:Visual Rendered Successfully
2024-07-08 10:02:50,351:INFO:plot_model() successfully completed......................................
